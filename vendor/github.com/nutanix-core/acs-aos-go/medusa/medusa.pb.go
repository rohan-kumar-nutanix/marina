// Code generated by protoc-gen-go. DO NOT EDIT.
// source: medusa/medusa.proto

package medusa

import (
	fmt "fmt"
	proto "github.com/golang/protobuf/proto"
	base "github.com/nutanix-core/acs-aos-go/nutanix/util-slbufs/util/sl_bufs/base"
	net "github.com/nutanix-core/acs-aos-go/nutanix/util-slbufs/util/sl_bufs/net"
	math "math"
	stretch_params "github.com/nutanix-core/acs-aos-go/pithos/stretch_params"
	zeus "github.com/nutanix-core/acs-aos-go/zeus"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.ProtoPackageIsVersion3 // please upgrade the proto package

type OplogEpisodeFileType int32

const (
	OplogEpisodeFileType_kMeta      OplogEpisodeFileType = 0
	OplogEpisodeFileType_kData      OplogEpisodeFileType = 1
	OplogEpisodeFileType_kLargeData OplogEpisodeFileType = 2
	OplogEpisodeFileType_kMax       OplogEpisodeFileType = 3
)

var OplogEpisodeFileType_name = map[int32]string{
	0: "kMeta",
	1: "kData",
	2: "kLargeData",
	3: "kMax",
}

var OplogEpisodeFileType_value = map[string]int32{
	"kMeta":      0,
	"kData":      1,
	"kLargeData": 2,
	"kMax":       3,
}

func (x OplogEpisodeFileType) Enum() *OplogEpisodeFileType {
	p := new(OplogEpisodeFileType)
	*p = x
	return p
}

func (x OplogEpisodeFileType) String() string {
	return proto.EnumName(OplogEpisodeFileType_name, int32(x))
}

func (x *OplogEpisodeFileType) UnmarshalJSON(data []byte) error {
	value, err := proto.UnmarshalJSONEnum(OplogEpisodeFileType_value, data, "OplogEpisodeFileType")
	if err != nil {
		return err
	}
	*x = OplogEpisodeFileType(value)
	return nil
}

func (OplogEpisodeFileType) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{0}
}

// State of a Near-sync session and the ConsistencyGroup itself.
type ConsistencyGroupState int32

const (
	// Near-sync is healthy and running for this CG.
	ConsistencyGroupState_kActive ConsistencyGroupState = 0
	// Near-sync is 'disabled' for this CG.
	ConsistencyGroupState_kDisabled ConsistencyGroupState = 1
	// CG is marked for 'deletion'.
	ConsistencyGroupState_kDeleted ConsistencyGroupState = 2
)

var ConsistencyGroupState_name = map[int32]string{
	0: "kActive",
	1: "kDisabled",
	2: "kDeleted",
}

var ConsistencyGroupState_value = map[string]int32{
	"kActive":   0,
	"kDisabled": 1,
	"kDeleted":  2,
}

func (x ConsistencyGroupState) Enum() *ConsistencyGroupState {
	p := new(ConsistencyGroupState)
	*p = x
	return p
}

func (x ConsistencyGroupState) String() string {
	return proto.EnumName(ConsistencyGroupState_name, int32(x))
}

func (x *ConsistencyGroupState) UnmarshalJSON(data []byte) error {
	value, err := proto.UnmarshalJSONEnum(ConsistencyGroupState_value, data, "ConsistencyGroupState")
	if err != nil {
		return err
	}
	*x = ConsistencyGroupState(value)
	return nil
}

func (ConsistencyGroupState) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{1}
}

// Captures the various states of the LWS replication.
type ReplicationState int32

const (
	// If the LWS replication is in progress.
	ReplicationState_kInProgress ReplicationState = 0
	// If the LWS replication is aborted.
	ReplicationState_kAborted ReplicationState = 1
	// If the LWS replication is paused.
	ReplicationState_kPaused ReplicationState = 2
)

var ReplicationState_name = map[int32]string{
	0: "kInProgress",
	1: "kAborted",
	2: "kPaused",
}

var ReplicationState_value = map[string]int32{
	"kInProgress": 0,
	"kAborted":    1,
	"kPaused":     2,
}

func (x ReplicationState) Enum() *ReplicationState {
	p := new(ReplicationState)
	*p = x
	return p
}

func (x ReplicationState) String() string {
	return proto.EnumName(ReplicationState_name, int32(x))
}

func (x *ReplicationState) UnmarshalJSON(data []byte) error {
	value, err := proto.UnmarshalJSONEnum(ReplicationState_value, data, "ReplicationState")
	if err != nil {
		return err
	}
	*x = ReplicationState(value)
	return nil
}

func (ReplicationState) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{2}
}

// The store type an episode would need to be linked from and to.
type EpisodeLinkStoreType int32

const (
	EpisodeLinkStoreType_kOplogToLws EpisodeLinkStoreType = 0
	EpisodeLinkStoreType_kLwsToOplog EpisodeLinkStoreType = 1
	EpisodeLinkStoreType_kMaxStore   EpisodeLinkStoreType = 2
)

var EpisodeLinkStoreType_name = map[int32]string{
	0: "kOplogToLws",
	1: "kLwsToOplog",
	2: "kMaxStore",
}

var EpisodeLinkStoreType_value = map[string]int32{
	"kOplogToLws": 0,
	"kLwsToOplog": 1,
	"kMaxStore":   2,
}

func (x EpisodeLinkStoreType) Enum() *EpisodeLinkStoreType {
	p := new(EpisodeLinkStoreType)
	*p = x
	return p
}

func (x EpisodeLinkStoreType) String() string {
	return proto.EnumName(EpisodeLinkStoreType_name, int32(x))
}

func (x *EpisodeLinkStoreType) UnmarshalJSON(data []byte) error {
	value, err := proto.UnmarshalJSONEnum(EpisodeLinkStoreType_value, data, "EpisodeLinkStoreType")
	if err != nil {
		return err
	}
	*x = EpisodeLinkStoreType(value)
	return nil
}

func (EpisodeLinkStoreType) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{3}
}

type DistributedOplogClientType int32

const (
	DistributedOplogClientType_kVDisk         DistributedOplogClientType = 0
	DistributedOplogClientType_kCGController  DistributedOplogClientType = 1
	DistributedOplogClientType_kClientTypeMax DistributedOplogClientType = 2
)

var DistributedOplogClientType_name = map[int32]string{
	0: "kVDisk",
	1: "kCGController",
	2: "kClientTypeMax",
}

var DistributedOplogClientType_value = map[string]int32{
	"kVDisk":         0,
	"kCGController":  1,
	"kClientTypeMax": 2,
}

func (x DistributedOplogClientType) Enum() *DistributedOplogClientType {
	p := new(DistributedOplogClientType)
	*p = x
	return p
}

func (x DistributedOplogClientType) String() string {
	return proto.EnumName(DistributedOplogClientType_name, int32(x))
}

func (x *DistributedOplogClientType) UnmarshalJSON(data []byte) error {
	value, err := proto.UnmarshalJSONEnum(DistributedOplogClientType_value, data, "DistributedOplogClientType")
	if err != nil {
		return err
	}
	*x = DistributedOplogClientType(value)
	return nil
}

func (DistributedOplogClientType) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{4}
}

// The following explain the reason why the extent group is required to be
// migrated.
type MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason int32

const (
	// The following indicates whether the migration is being done due to ILM
	// purposes.
	MedusaExtentGroupIdMapEntryProto_kILM MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason = 0
	// The following indicates that the migration is being requested to
	// balance disk usage within a storage tier.
	MedusaExtentGroupIdMapEntryProto_kDiskBalancing MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason = 1
	// The following indicates that the migration is being requested to
	// ensure replicas are on different rackable units.
	MedusaExtentGroupIdMapEntryProto_kSeparateRackableUnits MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason = 2
	// (Deprecated) Used by tools (e.g., vdisk_manipulator) to force migration
	// of extent group without honoring the rackable-unit aware placement of
	// replicas. This is used only for testing.
	MedusaExtentGroupIdMapEntryProto_kDeprecatedExperimentalBypassRackableUnitCheck MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason = 3
	// The following indicates that the migration is being requested because
	// one of the replica disk of egroup is full.
	MedusaExtentGroupIdMapEntryProto_kReplicaDiskFull MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason = 4
	// The following indicates that fix extent group task is being requested
	// to force a rebuild of the erasure coded replica.
	MedusaExtentGroupIdMapEntryProto_kRebuildErasureReplica MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason = 5
	// The following indicates that the migration is being requested to
	// ensure replicas are on different racks.
	MedusaExtentGroupIdMapEntryProto_kSeparateRacks MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason = 6
	// (Deprecated) Number of migration reasons. Not a valid type.
	MedusaExtentGroupIdMapEntryProto_kNumReasons MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason = 7
	// The following indicates that a replica with status kMissing residing on
	// a disk being rebuilt was removed. This should only occur if the extent
	// group has marked all replicas as kMissing.
	MedusaExtentGroupIdMapEntryProto_kRebuildAllReplicasMissing MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason = 8
)

var MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason_name = map[int32]string{
	0: "kILM",
	1: "kDiskBalancing",
	2: "kSeparateRackableUnits",
	3: "kDeprecatedExperimentalBypassRackableUnitCheck",
	4: "kReplicaDiskFull",
	5: "kRebuildErasureReplica",
	6: "kSeparateRacks",
	7: "kNumReasons",
	8: "kRebuildAllReplicasMissing",
}

var MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason_value = map[string]int32{
	"kILM":                   0,
	"kDiskBalancing":         1,
	"kSeparateRackableUnits": 2,
	"kDeprecatedExperimentalBypassRackableUnitCheck": 3,
	"kReplicaDiskFull":           4,
	"kRebuildErasureReplica":     5,
	"kSeparateRacks":             6,
	"kNumReasons":                7,
	"kRebuildAllReplicasMissing": 8,
}

func (x MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason) Enum() *MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason {
	p := new(MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason)
	*p = x
	return p
}

func (x MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason) String() string {
	return proto.EnumName(MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason_name, int32(x))
}

func (x *MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason) UnmarshalJSON(data []byte) error {
	value, err := proto.UnmarshalJSONEnum(MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason_value, data, "MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason")
	if err != nil {
		return err
	}
	*x = MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason(value)
	return nil
}

func (MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{1, 0}
}

// Availability status of the replica.
type MedusaExtentGroupIdMapEntryProto_Replica_Status int32

const (
	// Replica is healthy.
	MedusaExtentGroupIdMapEntryProto_Replica_kHealthy MedusaExtentGroupIdMapEntryProto_Replica_Status = 0
	// Replica is corrupt.
	MedusaExtentGroupIdMapEntryProto_Replica_kCorrupt MedusaExtentGroupIdMapEntryProto_Replica_Status = 1
	// Replica is missing.
	MedusaExtentGroupIdMapEntryProto_Replica_kMissing MedusaExtentGroupIdMapEntryProto_Replica_Status = 2
)

var MedusaExtentGroupIdMapEntryProto_Replica_Status_name = map[int32]string{
	0: "kHealthy",
	1: "kCorrupt",
	2: "kMissing",
}

var MedusaExtentGroupIdMapEntryProto_Replica_Status_value = map[string]int32{
	"kHealthy": 0,
	"kCorrupt": 1,
	"kMissing": 2,
}

func (x MedusaExtentGroupIdMapEntryProto_Replica_Status) Enum() *MedusaExtentGroupIdMapEntryProto_Replica_Status {
	p := new(MedusaExtentGroupIdMapEntryProto_Replica_Status)
	*p = x
	return p
}

func (x MedusaExtentGroupIdMapEntryProto_Replica_Status) String() string {
	return proto.EnumName(MedusaExtentGroupIdMapEntryProto_Replica_Status_name, int32(x))
}

func (x *MedusaExtentGroupIdMapEntryProto_Replica_Status) UnmarshalJSON(data []byte) error {
	value, err := proto.UnmarshalJSONEnum(MedusaExtentGroupIdMapEntryProto_Replica_Status_value, data, "MedusaExtentGroupIdMapEntryProto_Replica_Status")
	if err != nil {
		return err
	}
	*x = MedusaExtentGroupIdMapEntryProto_Replica_Status(value)
	return nil
}

func (MedusaExtentGroupIdMapEntryProto_Replica_Status) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{1, 5, 0}
}

// This field contains a collection of boolean properties. The enum type
// BooleanProperty defines bit positions of boolean properties within
// property_bit_flags. The default value of each bit position is zero.
type MedusaExtentGroupIdMapEntryProto_ControlBlock_BooleanProperty int32

const (
	// This extent group is a primary parity assigned to a strip where
	// all extent groups belong to the same vdisk.
	MedusaExtentGroupIdMapEntryProto_ControlBlock_kParitySameVDisk MedusaExtentGroupIdMapEntryProto_ControlBlock_BooleanProperty = 0
	// This extent group's physical metadata is managed by Autonomous Extent
	// Store (AES).
	MedusaExtentGroupIdMapEntryProto_ControlBlock_kManagedByAes MedusaExtentGroupIdMapEntryProto_ControlBlock_BooleanProperty = 1
)

var MedusaExtentGroupIdMapEntryProto_ControlBlock_BooleanProperty_name = map[int32]string{
	0: "kParitySameVDisk",
	1: "kManagedByAes",
}

var MedusaExtentGroupIdMapEntryProto_ControlBlock_BooleanProperty_value = map[string]int32{
	"kParitySameVDisk": 0,
	"kManagedByAes":    1,
}

func (x MedusaExtentGroupIdMapEntryProto_ControlBlock_BooleanProperty) Enum() *MedusaExtentGroupIdMapEntryProto_ControlBlock_BooleanProperty {
	p := new(MedusaExtentGroupIdMapEntryProto_ControlBlock_BooleanProperty)
	*p = x
	return p
}

func (x MedusaExtentGroupIdMapEntryProto_ControlBlock_BooleanProperty) String() string {
	return proto.EnumName(MedusaExtentGroupIdMapEntryProto_ControlBlock_BooleanProperty_name, int32(x))
}

func (x *MedusaExtentGroupIdMapEntryProto_ControlBlock_BooleanProperty) UnmarshalJSON(data []byte) error {
	value, err := proto.UnmarshalJSONEnum(MedusaExtentGroupIdMapEntryProto_ControlBlock_BooleanProperty_value, data, "MedusaExtentGroupIdMapEntryProto_ControlBlock_BooleanProperty")
	if err != nil {
		return err
	}
	*x = MedusaExtentGroupIdMapEntryProto_ControlBlock_BooleanProperty(value)
	return nil
}

func (MedusaExtentGroupIdMapEntryProto_ControlBlock_BooleanProperty) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{1, 6, 0}
}

// The episode version is used to identify how episodes should be stored or
// recovered, to handle behavioral changes across releases.
type MedusaVDiskOplogMapEntryProto_Episode_EpisodeVersion int32

const (
	// For a closed episode, all record except flush records after
	// highest_episode_logical_timestamp should be discarded during recovery.
	MedusaVDiskOplogMapEntryProto_Episode_kVersionLegacy MedusaVDiskOplogMapEntryProto_Episode_EpisodeVersion = 0
	// For a closed episode, all records including flush records after
	// highest_episode_logical_timestamp should be discarded during recovery.
	MedusaVDiskOplogMapEntryProto_Episode_kVersionFlushRecordsCommit MedusaVDiskOplogMapEntryProto_Episode_EpisodeVersion = 1
)

var MedusaVDiskOplogMapEntryProto_Episode_EpisodeVersion_name = map[int32]string{
	0: "kVersionLegacy",
	1: "kVersionFlushRecordsCommit",
}

var MedusaVDiskOplogMapEntryProto_Episode_EpisodeVersion_value = map[string]int32{
	"kVersionLegacy":             0,
	"kVersionFlushRecordsCommit": 1,
}

func (x MedusaVDiskOplogMapEntryProto_Episode_EpisodeVersion) Enum() *MedusaVDiskOplogMapEntryProto_Episode_EpisodeVersion {
	p := new(MedusaVDiskOplogMapEntryProto_Episode_EpisodeVersion)
	*p = x
	return p
}

func (x MedusaVDiskOplogMapEntryProto_Episode_EpisodeVersion) String() string {
	return proto.EnumName(MedusaVDiskOplogMapEntryProto_Episode_EpisodeVersion_name, int32(x))
}

func (x *MedusaVDiskOplogMapEntryProto_Episode_EpisodeVersion) UnmarshalJSON(data []byte) error {
	value, err := proto.UnmarshalJSONEnum(MedusaVDiskOplogMapEntryProto_Episode_EpisodeVersion_value, data, "MedusaVDiskOplogMapEntryProto_Episode_EpisodeVersion")
	if err != nil {
		return err
	}
	*x = MedusaVDiskOplogMapEntryProto_Episode_EpisodeVersion(value)
	return nil
}

func (MedusaVDiskOplogMapEntryProto_Episode_EpisodeVersion) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{2, 1, 0}
}

// Definitions for the various lock types come from
// http://en.wikipedia.org/wiki/Distributed_lock_manager
type Lock_LockType int32

const (
	// Indicates interest in resource, but does not prevent other processes
	// from locking it.
	Lock_kNull Lock_LockType = 0
	// Indicates desire to read resource, allows other processes to read or
	// update the resource but prevents others from having exclusive access to
	// it.
	Lock_kConcurrentRead Lock_LockType = 1
	// Indicates desire to read and update resource, allows other processes to
	// read or update the resource but prevents others from having exclusive
	// access to it.
	Lock_kConcurrentWrite Lock_LockType = 2
	// Indicates desire to read resource and other processes can read it but
	// prevents them from updating it.
	Lock_kProtectedRead Lock_LockType = 3
	// Indicates desire to read and update resource and other processes can
	// read it but prevents them from updating it.
	Lock_kProtectedWrite Lock_LockType = 4
	// Allows read and update access to the resource and prevents others from
	// having any access to it.
	Lock_kExclusive Lock_LockType = 5
)

var Lock_LockType_name = map[int32]string{
	0: "kNull",
	1: "kConcurrentRead",
	2: "kConcurrentWrite",
	3: "kProtectedRead",
	4: "kProtectedWrite",
	5: "kExclusive",
}

var Lock_LockType_value = map[string]int32{
	"kNull":            0,
	"kConcurrentRead":  1,
	"kConcurrentWrite": 2,
	"kProtectedRead":   3,
	"kProtectedWrite":  4,
	"kExclusive":       5,
}

func (x Lock_LockType) Enum() *Lock_LockType {
	p := new(Lock_LockType)
	*p = x
	return p
}

func (x Lock_LockType) String() string {
	return proto.EnumName(Lock_LockType_name, int32(x))
}

func (x *Lock_LockType) UnmarshalJSON(data []byte) error {
	value, err := proto.UnmarshalJSONEnum(Lock_LockType_value, data, "Lock_LockType")
	if err != nil {
		return err
	}
	*x = Lock_LockType(value)
	return nil
}

func (Lock_LockType) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{3, 0}
}

// Smb file states.
type MedusaNFSAttrProto_SmbOpenState_SmbFileState int32

const (
	// This state means the file does not have any deletion flag like
	// DOC or DP set on it.
	MedusaNFSAttrProto_SmbOpenState_kSmbOpen MedusaNFSAttrProto_SmbOpenState_SmbFileState = 0
	// This state means there is an open which has specified DOC. This can
	// be set only if the existing opens allow it by specifying SHARE_DELETE
	// sharing mode.
	MedusaNFSAttrProto_SmbOpenState_kSmbDeleteOnClose MedusaNFSAttrProto_SmbOpenState_SmbFileState = 1
	// This state means the file will be deleted when the last open is
	// closed. This can happen when an open with DOC is closed or an
	// explicit DP was set via a SMB SETINFO request. New opens will not
	// be allowed for the file in this state.
	MedusaNFSAttrProto_SmbOpenState_kSmbDeletePending MedusaNFSAttrProto_SmbOpenState_SmbFileState = 2
)

var MedusaNFSAttrProto_SmbOpenState_SmbFileState_name = map[int32]string{
	0: "kSmbOpen",
	1: "kSmbDeleteOnClose",
	2: "kSmbDeletePending",
}

var MedusaNFSAttrProto_SmbOpenState_SmbFileState_value = map[string]int32{
	"kSmbOpen":          0,
	"kSmbDeleteOnClose": 1,
	"kSmbDeletePending": 2,
}

func (x MedusaNFSAttrProto_SmbOpenState_SmbFileState) Enum() *MedusaNFSAttrProto_SmbOpenState_SmbFileState {
	p := new(MedusaNFSAttrProto_SmbOpenState_SmbFileState)
	*p = x
	return p
}

func (x MedusaNFSAttrProto_SmbOpenState_SmbFileState) String() string {
	return proto.EnumName(MedusaNFSAttrProto_SmbOpenState_SmbFileState_name, int32(x))
}

func (x *MedusaNFSAttrProto_SmbOpenState_SmbFileState) UnmarshalJSON(data []byte) error {
	value, err := proto.UnmarshalJSONEnum(MedusaNFSAttrProto_SmbOpenState_SmbFileState_value, data, "MedusaNFSAttrProto_SmbOpenState_SmbFileState")
	if err != nil {
		return err
	}
	*x = MedusaNFSAttrProto_SmbOpenState_SmbFileState(value)
	return nil
}

func (MedusaNFSAttrProto_SmbOpenState_SmbFileState) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{6, 0, 0}
}

// The oplog type used by the CG.
type MedusaNearSyncConsistencyGroupMapEntryProto_CGOplogType int32

const (
	// Legacy vdisk oplog.
	MedusaNearSyncConsistencyGroupMapEntryProto_kVDiskOplog MedusaNearSyncConsistencyGroupMapEntryProto_CGOplogType = 0
	// Distributed oplog.
	MedusaNearSyncConsistencyGroupMapEntryProto_kDistributedOplog MedusaNearSyncConsistencyGroupMapEntryProto_CGOplogType = 1
)

var MedusaNearSyncConsistencyGroupMapEntryProto_CGOplogType_name = map[int32]string{
	0: "kVDiskOplog",
	1: "kDistributedOplog",
}

var MedusaNearSyncConsistencyGroupMapEntryProto_CGOplogType_value = map[string]int32{
	"kVDiskOplog":       0,
	"kDistributedOplog": 1,
}

func (x MedusaNearSyncConsistencyGroupMapEntryProto_CGOplogType) Enum() *MedusaNearSyncConsistencyGroupMapEntryProto_CGOplogType {
	p := new(MedusaNearSyncConsistencyGroupMapEntryProto_CGOplogType)
	*p = x
	return p
}

func (x MedusaNearSyncConsistencyGroupMapEntryProto_CGOplogType) String() string {
	return proto.EnumName(MedusaNearSyncConsistencyGroupMapEntryProto_CGOplogType_name, int32(x))
}

func (x *MedusaNearSyncConsistencyGroupMapEntryProto_CGOplogType) UnmarshalJSON(data []byte) error {
	value, err := proto.UnmarshalJSONEnum(MedusaNearSyncConsistencyGroupMapEntryProto_CGOplogType_value, data, "MedusaNearSyncConsistencyGroupMapEntryProto_CGOplogType")
	if err != nil {
		return err
	}
	*x = MedusaNearSyncConsistencyGroupMapEntryProto_CGOplogType(value)
	return nil
}

func (MedusaNearSyncConsistencyGroupMapEntryProto_CGOplogType) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{12, 0}
}

// Indicates the autonomous mode of a CG.
type MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_AutonomousMode int32

const (
	// Stargate can only respond to a finalize from Cerebro.
	MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_kDisabled MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_AutonomousMode = 0
	// Stargate can drive finalize schedules autonomously.
	MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_kEnabled MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_AutonomousMode = 1
	// Stargate can drive finalize schedules, but the LWSs will be marked
	// invalid.
	MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_kDegraded MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_AutonomousMode = 2
)

var MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_AutonomousMode_name = map[int32]string{
	0: "kDisabled",
	1: "kEnabled",
	2: "kDegraded",
}

var MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_AutonomousMode_value = map[string]int32{
	"kDisabled": 0,
	"kEnabled":  1,
	"kDegraded": 2,
}

func (x MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_AutonomousMode) Enum() *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_AutonomousMode {
	p := new(MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_AutonomousMode)
	*p = x
	return p
}

func (x MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_AutonomousMode) String() string {
	return proto.EnumName(MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_AutonomousMode_name, int32(x))
}

func (x *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_AutonomousMode) UnmarshalJSON(data []byte) error {
	value, err := proto.UnmarshalJSONEnum(MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_AutonomousMode_value, data, "MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_AutonomousMode")
	if err != nil {
		return err
	}
	*x = MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_AutonomousMode(value)
	return nil
}

func (MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_AutonomousMode) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{12, 3, 0}
}

// Definition of snapshot states.
type MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState int32

const (
	// This state indicates that all the vdisks and their ancestor vdisks
	// are complete. The snapshot is ready to be consumed by Cerebro.
	MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_kReady MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState = 0
	// This state indicates that one or more vdisks in the snapshot are
	// still seeding.
	MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_kSeeding MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState = 1
	// This state indicates that all the vdisks corresponding to the
	// snapshot are complete, but one or more vdisks have incomplete
	// ancestors. The vdisks with incomplete ancestors have dummy vdisk
	// config params which need to be fixed by the snapshot notification op
	// when their ancestor vdisks are marked as complete.
	MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_kNeedsFixing MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState = 2
)

var MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState_name = map[int32]string{
	0: "kReady",
	1: "kSeeding",
	2: "kNeedsFixing",
}

var MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState_value = map[string]int32{
	"kReady":       0,
	"kSeeding":     1,
	"kNeedsFixing": 2,
}

func (x MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState) Enum() *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState {
	p := new(MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState)
	*p = x
	return p
}

func (x MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState) String() string {
	return proto.EnumName(MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState_name, int32(x))
}

func (x *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState) UnmarshalJSON(data []byte) error {
	value, err := proto.UnmarshalJSONEnum(MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState_value, data, "MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState")
	if err != nil {
		return err
	}
	*x = MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState(value)
	return nil
}

func (MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{12, 3, 1, 0}
}

// Definition for various types of ops that can operate on the staging
// area.
type MedusaNearSyncStagingAreaMapEntryProto_LWSStagingAreaOps int32

const (
	// This value indicates that no operation is currently being carried out
	// on the staging area.
	MedusaNearSyncStagingAreaMapEntryProto_kIdle MedusaNearSyncStagingAreaMapEntryProto_LWSStagingAreaOps = 0
	// This value indicates that an apply operation is currently in progress.
	MedusaNearSyncStagingAreaMapEntryProto_kApplyLwsOp MedusaNearSyncStagingAreaMapEntryProto_LWSStagingAreaOps = 1
	// This value indicates that clear of staging area is currently in
	// progress.
	MedusaNearSyncStagingAreaMapEntryProto_kClearStagingAreaOp MedusaNearSyncStagingAreaMapEntryProto_LWSStagingAreaOps = 2
)

var MedusaNearSyncStagingAreaMapEntryProto_LWSStagingAreaOps_name = map[int32]string{
	0: "kIdle",
	1: "kApplyLwsOp",
	2: "kClearStagingAreaOp",
}

var MedusaNearSyncStagingAreaMapEntryProto_LWSStagingAreaOps_value = map[string]int32{
	"kIdle":               0,
	"kApplyLwsOp":         1,
	"kClearStagingAreaOp": 2,
}

func (x MedusaNearSyncStagingAreaMapEntryProto_LWSStagingAreaOps) Enum() *MedusaNearSyncStagingAreaMapEntryProto_LWSStagingAreaOps {
	p := new(MedusaNearSyncStagingAreaMapEntryProto_LWSStagingAreaOps)
	*p = x
	return p
}

func (x MedusaNearSyncStagingAreaMapEntryProto_LWSStagingAreaOps) String() string {
	return proto.EnumName(MedusaNearSyncStagingAreaMapEntryProto_LWSStagingAreaOps_name, int32(x))
}

func (x *MedusaNearSyncStagingAreaMapEntryProto_LWSStagingAreaOps) UnmarshalJSON(data []byte) error {
	value, err := proto.UnmarshalJSONEnum(MedusaNearSyncStagingAreaMapEntryProto_LWSStagingAreaOps_value, data, "MedusaNearSyncStagingAreaMapEntryProto_LWSStagingAreaOps")
	if err != nil {
		return err
	}
	*x = MedusaNearSyncStagingAreaMapEntryProto_LWSStagingAreaOps(value)
	return nil
}

func (MedusaNearSyncStagingAreaMapEntryProto_LWSStagingAreaOps) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{15, 0}
}

// Definition for various phases of the LWS apply.
type MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage int32

const (
	// This value indicates that no LWS apply operation is being carried
	// out in this staging area.
	MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_kIdle MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage = 0
	// This value indicates that the LWS apply op is in the file deletion
	// phase.
	MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_kDeleteFiles MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage = 1
	// This value indicates that the LWS apply op is in the file rename
	// phase. Additional state should be present in 'file_rename_records'.
	MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_kRenameFiles MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage = 2
	// This value indicates that the LWS apply op is in the process of
	// converting small files to large files.
	MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_kConvertFiles MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage = 3
	// This value indicates that the LWS apply op is in the file addition
	// phase in the LWS apply staging area.
	MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_kAddNewFiles MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage = 4
	// This value indicates that the LWS apply op is in the process of
	// applying the updated NFS attributes for the files in the LWS apply
	// staging area.
	MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_kApplyNfsAttrs MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage = 5
	// This value indicates that the LWS apply op is in the process of
	// writing the data shards for small files in the LWS apply staging
	// area.
	MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_kApplyShadowInodes MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage = 6
)

var MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage_name = map[int32]string{
	0: "kIdle",
	1: "kDeleteFiles",
	2: "kRenameFiles",
	3: "kConvertFiles",
	4: "kAddNewFiles",
	5: "kApplyNfsAttrs",
	6: "kApplyShadowInodes",
}

var MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage_value = map[string]int32{
	"kIdle":              0,
	"kDeleteFiles":       1,
	"kRenameFiles":       2,
	"kConvertFiles":      3,
	"kAddNewFiles":       4,
	"kApplyNfsAttrs":     5,
	"kApplyShadowInodes": 6,
}

func (x MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage) Enum() *MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage {
	p := new(MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage)
	*p = x
	return p
}

func (x MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage) String() string {
	return proto.EnumName(MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage_name, int32(x))
}

func (x *MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage) UnmarshalJSON(data []byte) error {
	value, err := proto.UnmarshalJSONEnum(MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage_value, data, "MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage")
	if err != nil {
		return err
	}
	*x = MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage(value)
	return nil
}

func (MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{15, 1, 0}
}

// The episode version is used to identify how episodes should be stored or
// recovered, to handle behavioral changes across releases.
type MedusaDistributedOplogMapEntryProto_Episode_EpisodeVersion int32

const (
	// For a closed episode, all records after the record corresponding to
	// highest_episode_logical_timestamp should be discarded during recovery.
	MedusaDistributedOplogMapEntryProto_Episode_kVersionInitial MedusaDistributedOplogMapEntryProto_Episode_EpisodeVersion = 0
)

var MedusaDistributedOplogMapEntryProto_Episode_EpisodeVersion_name = map[int32]string{
	0: "kVersionInitial",
}

var MedusaDistributedOplogMapEntryProto_Episode_EpisodeVersion_value = map[string]int32{
	"kVersionInitial": 0,
}

func (x MedusaDistributedOplogMapEntryProto_Episode_EpisodeVersion) Enum() *MedusaDistributedOplogMapEntryProto_Episode_EpisodeVersion {
	p := new(MedusaDistributedOplogMapEntryProto_Episode_EpisodeVersion)
	*p = x
	return p
}

func (x MedusaDistributedOplogMapEntryProto_Episode_EpisodeVersion) String() string {
	return proto.EnumName(MedusaDistributedOplogMapEntryProto_Episode_EpisodeVersion_name, int32(x))
}

func (x *MedusaDistributedOplogMapEntryProto_Episode_EpisodeVersion) UnmarshalJSON(data []byte) error {
	value, err := proto.UnmarshalJSONEnum(MedusaDistributedOplogMapEntryProto_Episode_EpisodeVersion_value, data, "MedusaDistributedOplogMapEntryProto_Episode_EpisodeVersion")
	if err != nil {
		return err
	}
	*x = MedusaDistributedOplogMapEntryProto_Episode_EpisodeVersion(value)
	return nil
}

func (MedusaDistributedOplogMapEntryProto_Episode_EpisodeVersion) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{21, 1, 0}
}

// Entry in the Extent ID map in Medusa. This map provides the following
// mapping:
//   extentId -> extentGroupId
type MedusaExtentIdMapEntryProto struct {
	// If the extent group id is not set, then this is a 'zombie' entry - which
	// should be treated effectively as a negative cache entry. A zombie entry
	// can be deleted by the curator as long as the locs indicate that all
	// operations working on it are dead.
	ExtentGroupId *int64 `protobuf:"varint,1,opt,name=extent_group_id,json=extentGroupId,def=-1" json:"extent_group_id,omitempty"`
	// Vector of logical operation clocks that corresponds to potentially
	// ongoing operations that last modified this entry.
	Locs []*zeus.LogicalOperationClock `protobuf:"bytes,2,rep,name=locs" json:"locs,omitempty"`
	// Marker to indicate if the corresponding extent id has been marked for
	// deletion. Currently this field is used only for dedup extents and is set
	// to true by Curator if an extent does not have any references from vblock
	// map. This field is cleared by Stargate if a new reference is added for
	// this extent. Curator may also clear this field, if a new reference is
	// added just before 'to_delete' is set and 'to_delete' is set later.
	ToDelete *bool `protobuf:"varint,3,opt,name=to_delete,json=toDelete" json:"to_delete,omitempty"`
	// If Map2-based dedup is enabled, then this Extent ID map entry may contain
	// list of regions which are mapped to dedup extents. For each such region,
	// the corresponding data must be read from the dedup extent as that region
	// may not be valid in above 'extent_group_id'.
	Regions              []*MedusaVDiskBlockMapEntryProto_Region `protobuf:"bytes,4,rep,name=regions" json:"regions,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                                `json:"-"`
	XXX_unrecognized     []byte                                  `json:"-"`
	XXX_sizecache        int32                                   `json:"-"`
}

func (m *MedusaExtentIdMapEntryProto) Reset()         { *m = MedusaExtentIdMapEntryProto{} }
func (m *MedusaExtentIdMapEntryProto) String() string { return proto.CompactTextString(m) }
func (*MedusaExtentIdMapEntryProto) ProtoMessage()    {}
func (*MedusaExtentIdMapEntryProto) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{0}
}

func (m *MedusaExtentIdMapEntryProto) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaExtentIdMapEntryProto.Unmarshal(m, b)
}
func (m *MedusaExtentIdMapEntryProto) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaExtentIdMapEntryProto.Marshal(b, m, deterministic)
}
func (m *MedusaExtentIdMapEntryProto) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaExtentIdMapEntryProto.Merge(m, src)
}
func (m *MedusaExtentIdMapEntryProto) XXX_Size() int {
	return xxx_messageInfo_MedusaExtentIdMapEntryProto.Size(m)
}
func (m *MedusaExtentIdMapEntryProto) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaExtentIdMapEntryProto.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaExtentIdMapEntryProto proto.InternalMessageInfo

const Default_MedusaExtentIdMapEntryProto_ExtentGroupId int64 = -1

func (m *MedusaExtentIdMapEntryProto) GetExtentGroupId() int64 {
	if m != nil && m.ExtentGroupId != nil {
		return *m.ExtentGroupId
	}
	return Default_MedusaExtentIdMapEntryProto_ExtentGroupId
}

func (m *MedusaExtentIdMapEntryProto) GetLocs() []*zeus.LogicalOperationClock {
	if m != nil {
		return m.Locs
	}
	return nil
}

func (m *MedusaExtentIdMapEntryProto) GetToDelete() bool {
	if m != nil && m.ToDelete != nil {
		return *m.ToDelete
	}
	return false
}

func (m *MedusaExtentIdMapEntryProto) GetRegions() []*MedusaVDiskBlockMapEntryProto_Region {
	if m != nil {
		return m.Regions
	}
	return nil
}

// Entry in the Extent Group ID map in Medusa. This map provides the following
// mapping:
//   extentGroupId -> Information about what's contained in the extent group
//                    along with information about its replicas.
type MedusaExtentGroupIdMapEntryProto struct {
	ControlBlock *MedusaExtentGroupIdMapEntryProto_ControlBlock `protobuf:"bytes,1,opt,name=control_block,json=controlBlock" json:"control_block,omitempty"`
	// All the extent ids that are known to be present in all the replicas inside
	// the control block.
	Extents []*MedusaExtentGroupIdMapEntryProto_ExtentState `protobuf:"bytes,2,rep,name=extents" json:"extents,omitempty"`
	// Information about all the slices in this extent group.
	Slices               []*MedusaExtentGroupIdMapEntryProto_SliceState `protobuf:"bytes,3,rep,name=slices" json:"slices,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                                       `json:"-"`
	XXX_unrecognized     []byte                                         `json:"-"`
	XXX_sizecache        int32                                          `json:"-"`
}

func (m *MedusaExtentGroupIdMapEntryProto) Reset()         { *m = MedusaExtentGroupIdMapEntryProto{} }
func (m *MedusaExtentGroupIdMapEntryProto) String() string { return proto.CompactTextString(m) }
func (*MedusaExtentGroupIdMapEntryProto) ProtoMessage()    {}
func (*MedusaExtentGroupIdMapEntryProto) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{1}
}

func (m *MedusaExtentGroupIdMapEntryProto) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto.Unmarshal(m, b)
}
func (m *MedusaExtentGroupIdMapEntryProto) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto.Marshal(b, m, deterministic)
}
func (m *MedusaExtentGroupIdMapEntryProto) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaExtentGroupIdMapEntryProto.Merge(m, src)
}
func (m *MedusaExtentGroupIdMapEntryProto) XXX_Size() int {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto.Size(m)
}
func (m *MedusaExtentGroupIdMapEntryProto) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaExtentGroupIdMapEntryProto.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaExtentGroupIdMapEntryProto proto.InternalMessageInfo

func (m *MedusaExtentGroupIdMapEntryProto) GetControlBlock() *MedusaExtentGroupIdMapEntryProto_ControlBlock {
	if m != nil {
		return m.ControlBlock
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto) GetExtents() []*MedusaExtentGroupIdMapEntryProto_ExtentState {
	if m != nil {
		return m.Extents
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto) GetSlices() []*MedusaExtentGroupIdMapEntryProto_SliceState {
	if m != nil {
		return m.Slices
	}
	return nil
}

// A slice is a contiguous region of an extent group. It may contain data
// from one or more extents. It may also contain partial data from an extent
// (i.e., an extent might span multiple slices). A slice is a unit of
// transformation - e.g., a complete slice is compressed and encrypted as
// a whole.
type MedusaExtentGroupIdMapEntryProto_SliceState struct {
	// The unique id assigned to this slice.
	SliceId *int32 `protobuf:"varint,1,req,name=slice_id,json=sliceId" json:"slice_id,omitempty"`
	// The untransformed length of the slice.
	UntransformedLength *int32 `protobuf:"varint,2,opt,name=untransformed_length,json=untransformedLength" json:"untransformed_length,omitempty"`
	// The offset in the extent group where this slice starts. This is
	// after the transformation has been applied - i.e., it is the actual
	// offset on disk.
	ExtentGroupOffset *int32 `protobuf:"varint,3,opt,name=extent_group_offset,json=extentGroupOffset" json:"extent_group_offset,omitempty"`
	// The length of the transformed slice. This gives the number of bytes the
	// slice actually takes up on disk.
	TransformedLength *int32 `protobuf:"varint,4,opt,name=transformed_length,json=transformedLength" json:"transformed_length,omitempty"`
	// Cushion kept after the transformed slice to allow the slice to expand
	// into in case of re-transformation (e.g., if compressed data is updated
	// and the resulting compressed size is larger).
	// Note that transformed_length does not include this cushion.
	Cushion *int32 `protobuf:"varint,5,opt,name=cushion" json:"cushion,omitempty"`
	// The checksum values for subregions in a slice. Only set if
	// extent_group_offset is set.
	Checksum []uint32 `protobuf:"varint,6,rep,name=checksum" json:"checksum,omitempty"`
	// Optional SHA1 fingerprints. These are used for read-path dedup in
	// memory. This field is populated only for large sequential writes.
	// For random writes, this field is cleared. We enforce (via an assert)
	// that the slice size is a clean multiple of the dedup chunk size, and for
	// every chunk in this slice, a 20 byte SHA1 fingerprint is kept in this
	// field. For example, for a slice size of 32k and chunk size of 4k, we
	// would store 8 SHA1s here.
	Fingerprints []byte `protobuf:"bytes,7,opt,name=fingerprints" json:"fingerprints,omitempty"`
	// The logical checksum values for subregions in a slice. At present,
	// this is only set if deduplication is enabled and the slice is
	// compressed. It will not be set on slices that are encrypted but not
	// compressed in order to limit metadata bloat. It will will not be set on
	// slices created before upgrade or even during upgrade if an older
	// Stargate is involved in the write. For non-transformed slices, the
	// 'checksum' field represents both physical and logical checksum and
	// therefore an explicit 'logical_checksum' value is not needed.
	LogicalChecksum []uint32 `protobuf:"varint,8,rep,name=logical_checksum,json=logicalChecksum" json:"logical_checksum,omitempty"`
	// Set to true for slices which are marked for deletion.
	MarkedForDeletion    *bool    `protobuf:"varint,9,opt,name=marked_for_deletion,json=markedForDeletion" json:"marked_for_deletion,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaExtentGroupIdMapEntryProto_SliceState) Reset() {
	*m = MedusaExtentGroupIdMapEntryProto_SliceState{}
}
func (m *MedusaExtentGroupIdMapEntryProto_SliceState) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaExtentGroupIdMapEntryProto_SliceState) ProtoMessage() {}
func (*MedusaExtentGroupIdMapEntryProto_SliceState) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{1, 0}
}

func (m *MedusaExtentGroupIdMapEntryProto_SliceState) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_SliceState.Unmarshal(m, b)
}
func (m *MedusaExtentGroupIdMapEntryProto_SliceState) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_SliceState.Marshal(b, m, deterministic)
}
func (m *MedusaExtentGroupIdMapEntryProto_SliceState) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_SliceState.Merge(m, src)
}
func (m *MedusaExtentGroupIdMapEntryProto_SliceState) XXX_Size() int {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_SliceState.Size(m)
}
func (m *MedusaExtentGroupIdMapEntryProto_SliceState) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_SliceState.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_SliceState proto.InternalMessageInfo

func (m *MedusaExtentGroupIdMapEntryProto_SliceState) GetSliceId() int32 {
	if m != nil && m.SliceId != nil {
		return *m.SliceId
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_SliceState) GetUntransformedLength() int32 {
	if m != nil && m.UntransformedLength != nil {
		return *m.UntransformedLength
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_SliceState) GetExtentGroupOffset() int32 {
	if m != nil && m.ExtentGroupOffset != nil {
		return *m.ExtentGroupOffset
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_SliceState) GetTransformedLength() int32 {
	if m != nil && m.TransformedLength != nil {
		return *m.TransformedLength
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_SliceState) GetCushion() int32 {
	if m != nil && m.Cushion != nil {
		return *m.Cushion
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_SliceState) GetChecksum() []uint32 {
	if m != nil {
		return m.Checksum
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_SliceState) GetFingerprints() []byte {
	if m != nil {
		return m.Fingerprints
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_SliceState) GetLogicalChecksum() []uint32 {
	if m != nil {
		return m.LogicalChecksum
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_SliceState) GetMarkedForDeletion() bool {
	if m != nil && m.MarkedForDeletion != nil {
		return *m.MarkedForDeletion
	}
	return false
}

// Vector of SliceState's that will be stored as one column by Medusa in the
// backend.
type MedusaExtentGroupIdMapEntryProto_SliceStateVec struct {
	Slices               []*MedusaExtentGroupIdMapEntryProto_SliceState `protobuf:"bytes,1,rep,name=slices" json:"slices,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                                       `json:"-"`
	XXX_unrecognized     []byte                                         `json:"-"`
	XXX_sizecache        int32                                          `json:"-"`
}

func (m *MedusaExtentGroupIdMapEntryProto_SliceStateVec) Reset() {
	*m = MedusaExtentGroupIdMapEntryProto_SliceStateVec{}
}
func (m *MedusaExtentGroupIdMapEntryProto_SliceStateVec) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaExtentGroupIdMapEntryProto_SliceStateVec) ProtoMessage() {}
func (*MedusaExtentGroupIdMapEntryProto_SliceStateVec) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{1, 1}
}

func (m *MedusaExtentGroupIdMapEntryProto_SliceStateVec) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_SliceStateVec.Unmarshal(m, b)
}
func (m *MedusaExtentGroupIdMapEntryProto_SliceStateVec) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_SliceStateVec.Marshal(b, m, deterministic)
}
func (m *MedusaExtentGroupIdMapEntryProto_SliceStateVec) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_SliceStateVec.Merge(m, src)
}
func (m *MedusaExtentGroupIdMapEntryProto_SliceStateVec) XXX_Size() int {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_SliceStateVec.Size(m)
}
func (m *MedusaExtentGroupIdMapEntryProto_SliceStateVec) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_SliceStateVec.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_SliceStateVec proto.InternalMessageInfo

func (m *MedusaExtentGroupIdMapEntryProto_SliceStateVec) GetSlices() []*MedusaExtentGroupIdMapEntryProto_SliceState {
	if m != nil {
		return m.Slices
	}
	return nil
}

type MedusaExtentGroupIdMapEntryProto_ExtentState struct {
	// If Medusa keeps the ExtentState in a column in the backend, then the
	// column key would identify the extent_id. In that case, extent_id can
	// be removed by Medusa before actually storing the ExtentState. However,
	// Medusa consumers will always see the canonicalized extent_id - it'll be
	// filled by the Medusa library.
	ExtentId *ExtentIdProto `protobuf:"bytes,1,opt,name=extent_id,json=extentId" json:"extent_id,omitempty"`
	// The id's of the various slices that contain the extent data. Byte 0 of
	// the extent lives in the first slice. It extends to the end of the
	// untransformed slice (unless the extent is shorter), then it continues
	// from the beginning of the next slice.
	SliceIds []int32 `protobuf:"varint,2,rep,name=slice_ids,json=sliceIds" json:"slice_ids,omitempty"`
	// Offset within the first untransformed slice where byte 0 of the extent
	// starts.
	FirstSliceOffset *int32 `protobuf:"varint,3,opt,name=first_slice_offset,json=firstSliceOffset" json:"first_slice_offset,omitempty"`
	// Refcount for this extent id. Every reference from any vdisk block map
	// entry to this extent id contributes a reference. Due to races, the value
	// contained here may be more than the actual refcount, but it cannot be
	// less. Thus, when the refcount falls to zero, one can safely assume that
	// this extent is no longer used by anyone.
	//
	// Note that one vdisk block map entry contributes at most one reference.
	// Thus, if an extent is referred to multiple times within a vdisk block,
	// then that still contributes 1 to the refcount.
	Refcount *int32 `protobuf:"varint,4,opt,name=refcount,def=1" json:"refcount,omitempty"`
	// Bitset indicating which slice indices in the extent are not allocated.
	// Each bit, starting at the least significant bit, represents a slice
	// index. A value of 1 at a given but indicates that the slice at that
	// index is not allocated. A value of 0 at a given bit indicates that the
	// slice is allocated.
	// If this is not set, all the slices in the extent have a corresponding
	// slice state set in the proto on disk.
	// This will only be used if the number of slice indices per extent is less
	// than or equal to 64.
	UnallocatedSlicesBitset *uint64 `protobuf:"varint,5,opt,name=unallocated_slices_bitset,json=unallocatedSlicesBitset" json:"unallocated_slices_bitset,omitempty"`
	// The slice index corresponding to the slice ids in 'slice_ids'. This is
	// only used for AES extent groups to represent a sparse extent state when
	// relaying the physical extent group state using this entry.
	SliceIndices []int32 `protobuf:"varint,6,rep,name=slice_indices,json=sliceIndices" json:"slice_indices,omitempty"`
	// If Map3-based dedup is enabled, then this Extent Group ID map entry may
	// contain list of regions which are mapped to dedup extents. For each
	// such region, the corresponding data must be read from the dedup extent
	// as that region will not be valid in this extent group.
	Regions              []*MedusaVDiskBlockMapEntryProto_Region `protobuf:"bytes,7,rep,name=regions" json:"regions,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                                `json:"-"`
	XXX_unrecognized     []byte                                  `json:"-"`
	XXX_sizecache        int32                                   `json:"-"`
}

func (m *MedusaExtentGroupIdMapEntryProto_ExtentState) Reset() {
	*m = MedusaExtentGroupIdMapEntryProto_ExtentState{}
}
func (m *MedusaExtentGroupIdMapEntryProto_ExtentState) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaExtentGroupIdMapEntryProto_ExtentState) ProtoMessage() {}
func (*MedusaExtentGroupIdMapEntryProto_ExtentState) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{1, 2}
}

func (m *MedusaExtentGroupIdMapEntryProto_ExtentState) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_ExtentState.Unmarshal(m, b)
}
func (m *MedusaExtentGroupIdMapEntryProto_ExtentState) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_ExtentState.Marshal(b, m, deterministic)
}
func (m *MedusaExtentGroupIdMapEntryProto_ExtentState) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_ExtentState.Merge(m, src)
}
func (m *MedusaExtentGroupIdMapEntryProto_ExtentState) XXX_Size() int {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_ExtentState.Size(m)
}
func (m *MedusaExtentGroupIdMapEntryProto_ExtentState) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_ExtentState.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_ExtentState proto.InternalMessageInfo

const Default_MedusaExtentGroupIdMapEntryProto_ExtentState_Refcount int32 = 1

func (m *MedusaExtentGroupIdMapEntryProto_ExtentState) GetExtentId() *ExtentIdProto {
	if m != nil {
		return m.ExtentId
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_ExtentState) GetSliceIds() []int32 {
	if m != nil {
		return m.SliceIds
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_ExtentState) GetFirstSliceOffset() int32 {
	if m != nil && m.FirstSliceOffset != nil {
		return *m.FirstSliceOffset
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_ExtentState) GetRefcount() int32 {
	if m != nil && m.Refcount != nil {
		return *m.Refcount
	}
	return Default_MedusaExtentGroupIdMapEntryProto_ExtentState_Refcount
}

func (m *MedusaExtentGroupIdMapEntryProto_ExtentState) GetUnallocatedSlicesBitset() uint64 {
	if m != nil && m.UnallocatedSlicesBitset != nil {
		return *m.UnallocatedSlicesBitset
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_ExtentState) GetSliceIndices() []int32 {
	if m != nil {
		return m.SliceIndices
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_ExtentState) GetRegions() []*MedusaVDiskBlockMapEntryProto_Region {
	if m != nil {
		return m.Regions
	}
	return nil
}

// Vector of ExtentState's that will be stored as one column by Medusa in the
// backend.
type MedusaExtentGroupIdMapEntryProto_ExtentStateVec struct {
	Extents              []*MedusaExtentGroupIdMapEntryProto_ExtentState `protobuf:"bytes,1,rep,name=extents" json:"extents,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                                        `json:"-"`
	XXX_unrecognized     []byte                                          `json:"-"`
	XXX_sizecache        int32                                           `json:"-"`
}

func (m *MedusaExtentGroupIdMapEntryProto_ExtentStateVec) Reset() {
	*m = MedusaExtentGroupIdMapEntryProto_ExtentStateVec{}
}
func (m *MedusaExtentGroupIdMapEntryProto_ExtentStateVec) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaExtentGroupIdMapEntryProto_ExtentStateVec) ProtoMessage() {}
func (*MedusaExtentGroupIdMapEntryProto_ExtentStateVec) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{1, 3}
}

func (m *MedusaExtentGroupIdMapEntryProto_ExtentStateVec) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_ExtentStateVec.Unmarshal(m, b)
}
func (m *MedusaExtentGroupIdMapEntryProto_ExtentStateVec) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_ExtentStateVec.Marshal(b, m, deterministic)
}
func (m *MedusaExtentGroupIdMapEntryProto_ExtentStateVec) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_ExtentStateVec.Merge(m, src)
}
func (m *MedusaExtentGroupIdMapEntryProto_ExtentStateVec) XXX_Size() int {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_ExtentStateVec.Size(m)
}
func (m *MedusaExtentGroupIdMapEntryProto_ExtentStateVec) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_ExtentStateVec.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_ExtentStateVec proto.InternalMessageInfo

func (m *MedusaExtentGroupIdMapEntryProto_ExtentStateVec) GetExtents() []*MedusaExtentGroupIdMapEntryProto_ExtentState {
	if m != nil {
		return m.Extents
	}
	return nil
}

// A tentative update describes an intent to modify either the control block
// or an individual replica of the extent group. A tentative update may or
// may not succeed - i.e., it could either be rolled forward or rolled back
// by an op in the future after verifying whether the intended update
// actually took place or not. If the op intends to roll the tentative update
// back, then it should also ensure that any inflight requests for the update
// are denied. For example, one writeop may put a tentative update and then
// issue an RPC to change an extent group replica. Another simultaneous op
// that wishes to roll the tentative update back must ensure that the RPC
// by the first op hasn't been applied, and will never be applied by the
// extent store in the future before it can actually roll back the tentative
// update.
//
// In some cases, tentative updates may just partially roll forward. For
// example, a tentative update is put on the control block whenever an op
// intends to remove an extent id from it (either to decrement its refcount
// to 0 or to migrate it to some other extent group). Such a tentative update
// might contain a batch of multiple such extents. Ultimately (due to races),
// only some of these extents might actually get removed.
type MedusaExtentGroupIdMapEntryProto_TentativeUpdate struct {
	// Intent sequence associated with this tentative update.
	IntentSequence *int64 `protobuf:"varint,1,req,name=intent_sequence,json=intentSequence" json:"intent_sequence,omitempty"`
	// The extent ids that this tentative update is
	// adding/updating/deleting. As indicated above, the Medusa library may
	// uncanonicalize the extent_id before writing it to the backend. However,
	// consumers of the Medusa library always see canonicalized extents.
	ExtentId []*ExtentIdProto `protobuf:"bytes,2,rep,name=extent_id,json=extentId" json:"extent_id,omitempty"`
	// The refcount of the above extent ids after the tentative update is
	// applied. If 0, then the corresponding extent id is being deleted from
	// this extent group.
	Refcount []int32 `protobuf:"varint,3,rep,name=refcount" json:"refcount,omitempty"`
	// The following field is set when all the above extent ids are being
	// converted to the form where their field egroup_mapping_in_eid_map is
	// going to be set if the tentative update is rolled forward. These
	// extent ids should already be present in the extent group and should not
	// already have the egroup_mapping_in_eid_map field set.
	MoveEgroupMappingToEidMap *bool `protobuf:"varint,4,opt,name=move_egroup_mapping_to_eid_map,json=moveEgroupMappingToEidMap" json:"move_egroup_mapping_to_eid_map,omitempty"`
	// If this tentative update is due to replication, then the following
	// describes the source replica. In this case, the above extent_id and
	// refcount fields not set - they can be inferred from the source replica.
	//
	// The source replica shouldn't have any tentative update outstanding on it
	// if it is acting as the source of replication.
	ReplicationSourceDiskId *int64 `protobuf:"varint,5,opt,name=replication_source_disk_id,json=replicationSourceDiskId" json:"replication_source_disk_id,omitempty"`
	// This field is set in the tentative update on the primary parity extent
	// group while erasure coding is in progress. It contains replicas that
	// will not be removed after erasure coding. This field may only be set
	// for tentative updates on primary parity extent groups.
	ErasureReplicaDiskId []int64 `protobuf:"varint,6,rep,name=erasure_replica_disk_id,json=erasureReplicaDiskId" json:"erasure_replica_disk_id,omitempty"`
	// This field identifies the replacement extent group id for the replace
	// operation in progress. It is set in the tentative update on the primary
	// parity extent group of the original strip. The new strip will be given
	// a new primary parity extent group.
	ErasureReplacementEgroupId *int64 `protobuf:"varint,7,opt,name=erasure_replacement_egroup_id,json=erasureReplacementEgroupId" json:"erasure_replacement_egroup_id,omitempty"`
	// This field identifies parity egroup ids of the old strip in the
	// tentative update on the primary parity of the new strip during
	// the replace operation. It is used to restore the old strip if
	// the replacement op is incomplete and must be rolled back.
	ErasureReplacementOldParityEgroupIds []int64 `protobuf:"varint,8,rep,name=erasure_replacement_old_parity_egroup_ids,json=erasureReplacementOldParityEgroupIds" json:"erasure_replacement_old_parity_egroup_ids,omitempty"`
	// This field is set in the tentative update on the primary parity extent
	// group while erasure coding is in progress. It specifies the strip
	// position where replacement takes place. The old and new strips have
	// different primary parity extent groups. This field is set in both
	// primary parity extent groups.
	ErasureReplacementPosition *int32 `protobuf:"varint,9,opt,name=erasure_replacement_position,json=erasureReplacementPosition" json:"erasure_replacement_position,omitempty"`
	// This field is set in the tentative update on the primary parity extent
	// group when the strip and all extent groups in it are being completely
	// removed.
	ErasureDeleteStrip *bool `protobuf:"varint,10,opt,name=erasure_delete_strip,json=erasureDeleteStrip" json:"erasure_delete_strip,omitempty"`
	// This field is set in the tentative update on the primary parity extent
	// group when the strip is being undone. This action is only performed if
	// the strip members can no longer be placed on distinct cluster nodes.
	ErasureUnstrip *bool `protobuf:"varint,11,opt,name=erasure_unstrip,json=erasureUnstrip" json:"erasure_unstrip,omitempty"`
	// This field is set in the tentative update on the primary parity extent
	// group when decoded extent groups are written to new replicas.
	ErasureDecode *bool `protobuf:"varint,12,opt,name=erasure_decode,json=erasureDecode" json:"erasure_decode,omitempty"`
	// This field is set in the tentative update on the primary parity extent
	// group when an erasure coded strip is being re-encoded.
	ErasureRecode *bool `protobuf:"varint,13,opt,name=erasure_recode,json=erasureRecode" json:"erasure_recode,omitempty"`
	// This field is set in the recode tentative update. It is the number of
	// info egroups in the new strip. It is always set in a recode tentative
	// update.
	NewErasureStripSizeInfo *int32 `protobuf:"varint,14,opt,name=new_erasure_strip_size_info,json=newErasureStripSizeInfo" json:"new_erasure_strip_size_info,omitempty"`
	// This field is set in the recode tentative update. It stores the parity
	// extent group ids of the new strip. This field is optional and will not
	// be set if we are only removing the secondary parity egroup from the
	// current strip. If we are changing the number of info egroups, this
	// field stores all the new parity extent group ids of the new strip.
	// If we are only adding a new secondary parity, this field only stores
	// the new secondary parity extent group id while the same primary parity
	// extent group will remain in the new strip.
	NewParityEgroupIds []int64 `protobuf:"varint,15,rep,name=new_parity_egroup_ids,json=newParityEgroupIds" json:"new_parity_egroup_ids,omitempty"`
	// This field is set in the recode tentative update. If we are increasing
	// the number of info egroups in the strip, this field stores the new
	// info egroups that will be added to the current strip. If we are
	// decreasing the number of info egroups in the strip, this field stores
	// the extent group ids that we have selected to remove from the current
	// strip.
	ToRemoveOrAddEgroupIds []int64 `protobuf:"varint,16,rep,name=to_remove_or_add_egroup_ids,json=toRemoveOrAddEgroupIds" json:"to_remove_or_add_egroup_ids,omitempty"`
	// This field is set in the tentative update on the primary parity extent
	// group of the new strip which is built by a child encode op fired by a
	// parent recode op when the number of info egroups has changed. It is
	// used to restore the old strip if the recode op is incomplete and must
	// be rolled back.
	// This field is neither set nor used if we are only adding a new
	// secondary parity egroup to the existing strip because it is not needed
	// for that case.
	ErasureRecodeOldParityEgroupIds []int64 `protobuf:"varint,17,rep,name=erasure_recode_old_parity_egroup_ids,json=erasureRecodeOldParityEgroupIds" json:"erasure_recode_old_parity_egroup_ids,omitempty"`
	// This field is set in the tentative update on the primary parity extent
	// group and in the info extent group's replica tentative update when an
	// info egroup in the erasure strip is overwritten. It indicates the info
	// egroup being overwritten.
	ErasureOverwriteInfoEgroup *int64 `protobuf:"varint,18,opt,name=erasure_overwrite_info_egroup,json=erasureOverwriteInfoEgroup" json:"erasure_overwrite_info_egroup,omitempty"`
	// This field is populated when we are overwriting an erasure coded egroup
	// and is set in the primary parity extent group's tentative update and
	// indicates the desired intent sequence of the write to the info and
	// parity egroups.
	EgroupDesiredIntentSequences []int64 `protobuf:"varint,19,rep,name=egroup_desired_intent_sequences,json=egroupDesiredIntentSequences" json:"egroup_desired_intent_sequences,omitempty"`
	// This field is populated when we are overwriting an erasure coded egroup
	// and is set in the primary parity extent group's replica tentative update
	// and indicates the intent sequence of the info and parity egroups before
	// the write.
	EgroupCurrentIntentSequences []int64 `protobuf:"varint,20,rep,name=egroup_current_intent_sequences,json=egroupCurrentIntentSequences" json:"egroup_current_intent_sequences,omitempty"`
	// This field is set in the tentative update on the primary parity extent
	// egroup of the new strip when the number of info egroups has changed. It
	// is used to restore the old strip if the recode op didn't succeed and must
	// be rolled back. It is set to 'true' if the recode op is trying to
	// increase the number of info egroups in the strip. 'false' if the recode
	// op is trying to decrease the number of info egroups in the strip.
	// This field is not used if we are adding a new secondary parity egroup to
	// the existing strip.
	RecodeAddNewInfoEgroups *bool `protobuf:"varint,21,opt,name=recode_add_new_info_egroups,json=recodeAddNewInfoEgroups" json:"recode_add_new_info_egroups,omitempty"`
	// With Map3 deduplication project, deduplication of non-dedup extent first
	// adds a tentative update on the egroup storing non-dedup extent,
	// specifying which extent is undergoing deduplication. In the subsequent
	// phases of deduplication, once dedup regionMap is updated in the extent
	// state, this tentative update shall be cleared. This tentative update is
	// required to maintain integrity of reads on mutable extents stored in AES
	// managed extent groups. Specifically, in the absence of this tentative
	// update, deduplication of a mutable extent stored in AES managed extent
	// group, racing with concurrent writes on the mutable extent post crash of
	// earlier stargate hosting the corresponding vdisk can lead to a
	// corruption.
	EgidMapDedupProcessing *bool    `protobuf:"varint,22,opt,name=egid_map_dedup_processing,json=egidMapDedupProcessing" json:"egid_map_dedup_processing,omitempty"`
	XXX_NoUnkeyedLiteral   struct{} `json:"-"`
	XXX_unrecognized       []byte   `json:"-"`
	XXX_sizecache          int32    `json:"-"`
}

func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) Reset() {
	*m = MedusaExtentGroupIdMapEntryProto_TentativeUpdate{}
}
func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaExtentGroupIdMapEntryProto_TentativeUpdate) ProtoMessage() {}
func (*MedusaExtentGroupIdMapEntryProto_TentativeUpdate) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{1, 4}
}

func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_TentativeUpdate.Unmarshal(m, b)
}
func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_TentativeUpdate.Marshal(b, m, deterministic)
}
func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_TentativeUpdate.Merge(m, src)
}
func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) XXX_Size() int {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_TentativeUpdate.Size(m)
}
func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_TentativeUpdate.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_TentativeUpdate proto.InternalMessageInfo

func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) GetIntentSequence() int64 {
	if m != nil && m.IntentSequence != nil {
		return *m.IntentSequence
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) GetExtentId() []*ExtentIdProto {
	if m != nil {
		return m.ExtentId
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) GetRefcount() []int32 {
	if m != nil {
		return m.Refcount
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) GetMoveEgroupMappingToEidMap() bool {
	if m != nil && m.MoveEgroupMappingToEidMap != nil {
		return *m.MoveEgroupMappingToEidMap
	}
	return false
}

func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) GetReplicationSourceDiskId() int64 {
	if m != nil && m.ReplicationSourceDiskId != nil {
		return *m.ReplicationSourceDiskId
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) GetErasureReplicaDiskId() []int64 {
	if m != nil {
		return m.ErasureReplicaDiskId
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) GetErasureReplacementEgroupId() int64 {
	if m != nil && m.ErasureReplacementEgroupId != nil {
		return *m.ErasureReplacementEgroupId
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) GetErasureReplacementOldParityEgroupIds() []int64 {
	if m != nil {
		return m.ErasureReplacementOldParityEgroupIds
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) GetErasureReplacementPosition() int32 {
	if m != nil && m.ErasureReplacementPosition != nil {
		return *m.ErasureReplacementPosition
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) GetErasureDeleteStrip() bool {
	if m != nil && m.ErasureDeleteStrip != nil {
		return *m.ErasureDeleteStrip
	}
	return false
}

func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) GetErasureUnstrip() bool {
	if m != nil && m.ErasureUnstrip != nil {
		return *m.ErasureUnstrip
	}
	return false
}

func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) GetErasureDecode() bool {
	if m != nil && m.ErasureDecode != nil {
		return *m.ErasureDecode
	}
	return false
}

func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) GetErasureRecode() bool {
	if m != nil && m.ErasureRecode != nil {
		return *m.ErasureRecode
	}
	return false
}

func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) GetNewErasureStripSizeInfo() int32 {
	if m != nil && m.NewErasureStripSizeInfo != nil {
		return *m.NewErasureStripSizeInfo
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) GetNewParityEgroupIds() []int64 {
	if m != nil {
		return m.NewParityEgroupIds
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) GetToRemoveOrAddEgroupIds() []int64 {
	if m != nil {
		return m.ToRemoveOrAddEgroupIds
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) GetErasureRecodeOldParityEgroupIds() []int64 {
	if m != nil {
		return m.ErasureRecodeOldParityEgroupIds
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) GetErasureOverwriteInfoEgroup() int64 {
	if m != nil && m.ErasureOverwriteInfoEgroup != nil {
		return *m.ErasureOverwriteInfoEgroup
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) GetEgroupDesiredIntentSequences() []int64 {
	if m != nil {
		return m.EgroupDesiredIntentSequences
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) GetEgroupCurrentIntentSequences() []int64 {
	if m != nil {
		return m.EgroupCurrentIntentSequences
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) GetRecodeAddNewInfoEgroups() bool {
	if m != nil && m.RecodeAddNewInfoEgroups != nil {
		return *m.RecodeAddNewInfoEgroups
	}
	return false
}

func (m *MedusaExtentGroupIdMapEntryProto_TentativeUpdate) GetEgidMapDedupProcessing() bool {
	if m != nil && m.EgidMapDedupProcessing != nil {
		return *m.EgidMapDedupProcessing
	}
	return false
}

type MedusaExtentGroupIdMapEntryProto_Replica struct {
	// The intent sequence on the last successful tentative update. This field
	// is typically always set (unless the replica is just being created and no
	// tentative update has been successful yet).
	//
	// The intent sequence serves as a replica version.
	IntentSequence *int64 `protobuf:"varint,1,opt,name=intent_sequence,json=intentSequence,def=-1" json:"intent_sequence,omitempty"`
	// The disk id where the replica resides.
	DiskId *int64 `protobuf:"varint,2,req,name=disk_id,json=diskId" json:"disk_id,omitempty"`
	// List of outstanding tentative updates on this replica.
	TentativeUpdates []*MedusaExtentGroupIdMapEntryProto_TentativeUpdate `protobuf:"bytes,3,rep,name=tentative_updates,json=tentativeUpdates" json:"tentative_updates,omitempty"`
	//
	// The following diffs correspond to tentative updates that are known to
	// have been successful, but it is not known whether they were successful
	// on all the replicas. These diffs update the global extents and slices
	// for this extent group that are known to be common to all replicas.
	//
	// These fields are cleared once the extent group metadata is "fixed" so
	// as to equate all the replicas. Once that happens, this information is
	// merged into the global extents and slices for this extent group.
	//
	// Note for dedup extent id or one with egroup_mapping_in_eid_map set:
	//   If such an extent id is present in diff_extents, then before it can
	//   be moved to the global extents, the extent id map needs to be updated
	//   to contain the mapping of that extent id to this extent group.
	DiffSlices           []*MedusaExtentGroupIdMapEntryProto_SliceState   `protobuf:"bytes,4,rep,name=diff_slices,json=diffSlices" json:"diff_slices,omitempty"`
	DiffExtents          []*MedusaExtentGroupIdMapEntryProto_ExtentState  `protobuf:"bytes,5,rep,name=diff_extents,json=diffExtents" json:"diff_extents,omitempty"`
	Status               *MedusaExtentGroupIdMapEntryProto_Replica_Status `protobuf:"varint,6,opt,name=status,enum=nutanix.medusa.MedusaExtentGroupIdMapEntryProto_Replica_Status,def=0" json:"status,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                                         `json:"-"`
	XXX_unrecognized     []byte                                           `json:"-"`
	XXX_sizecache        int32                                            `json:"-"`
}

func (m *MedusaExtentGroupIdMapEntryProto_Replica) Reset() {
	*m = MedusaExtentGroupIdMapEntryProto_Replica{}
}
func (m *MedusaExtentGroupIdMapEntryProto_Replica) String() string { return proto.CompactTextString(m) }
func (*MedusaExtentGroupIdMapEntryProto_Replica) ProtoMessage()    {}
func (*MedusaExtentGroupIdMapEntryProto_Replica) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{1, 5}
}

func (m *MedusaExtentGroupIdMapEntryProto_Replica) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_Replica.Unmarshal(m, b)
}
func (m *MedusaExtentGroupIdMapEntryProto_Replica) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_Replica.Marshal(b, m, deterministic)
}
func (m *MedusaExtentGroupIdMapEntryProto_Replica) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_Replica.Merge(m, src)
}
func (m *MedusaExtentGroupIdMapEntryProto_Replica) XXX_Size() int {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_Replica.Size(m)
}
func (m *MedusaExtentGroupIdMapEntryProto_Replica) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_Replica.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_Replica proto.InternalMessageInfo

const Default_MedusaExtentGroupIdMapEntryProto_Replica_IntentSequence int64 = -1
const Default_MedusaExtentGroupIdMapEntryProto_Replica_Status MedusaExtentGroupIdMapEntryProto_Replica_Status = MedusaExtentGroupIdMapEntryProto_Replica_kHealthy

func (m *MedusaExtentGroupIdMapEntryProto_Replica) GetIntentSequence() int64 {
	if m != nil && m.IntentSequence != nil {
		return *m.IntentSequence
	}
	return Default_MedusaExtentGroupIdMapEntryProto_Replica_IntentSequence
}

func (m *MedusaExtentGroupIdMapEntryProto_Replica) GetDiskId() int64 {
	if m != nil && m.DiskId != nil {
		return *m.DiskId
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_Replica) GetTentativeUpdates() []*MedusaExtentGroupIdMapEntryProto_TentativeUpdate {
	if m != nil {
		return m.TentativeUpdates
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_Replica) GetDiffSlices() []*MedusaExtentGroupIdMapEntryProto_SliceState {
	if m != nil {
		return m.DiffSlices
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_Replica) GetDiffExtents() []*MedusaExtentGroupIdMapEntryProto_ExtentState {
	if m != nil {
		return m.DiffExtents
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_Replica) GetStatus() MedusaExtentGroupIdMapEntryProto_Replica_Status {
	if m != nil && m.Status != nil {
		return *m.Status
	}
	return Default_MedusaExtentGroupIdMapEntryProto_Replica_Status
}

type MedusaExtentGroupIdMapEntryProto_ControlBlock struct {
	// Which vdisk's controller owns this extent group. An extent group's
	// contents can only be modified by that vdisk controller.
	OwnerVdiskId *int64 `protobuf:"varint,1,req,name=owner_vdisk_id,json=ownerVdiskId" json:"owner_vdisk_id,omitempty"`
	// The transformation type. A transformation describes how the original
	// data is morphed into the form that is stored on disk. For example, a
	// transformation may be an identity function, or it could be a number of
	// functions like compression, encryption etc that are applied one after
	// the other.  All data stored in an extent group is of a given
	// transformation type.  A transformation is represented as a string -
	// e.g., "c=high,e=weak" which denotes high compression and weak
	// encryption. The empty string represents the identity transformation.
	//
	// Note that transformation_type is deprecated and new functionalities like
	// uncompressed slices in compressed extent groups and encryption are
	// implemented using 'transformation_type_list'.
	TransformationType *string `protobuf:"bytes,2,opt,name=transformation_type,json=transformationType" json:"transformation_type,omitempty"`
	// Information about all the replicas.
	Replicas []*MedusaExtentGroupIdMapEntryProto_Replica `protobuf:"bytes,3,rep,name=replicas" json:"replicas,omitempty"`
	// Latest intent sequence that has been used on any tentative update
	// (either one that is outstanding or one that has been applied). This
	// value is always >= 0 - even when the extent group metadata is created
	// for the first time in Medusa (as the very first creation must
	// necessarily contain a tentative update to write something on the
	// replicas).
	LatestIntentSequence *int64 `protobuf:"varint,4,req,name=latest_intent_sequence,json=latestIntentSequence" json:"latest_intent_sequence,omitempty"`
	// Vector of logical operation clocks that corresponds to potentially
	// ongoing operations that last modified this entry.
	Locs []*zeus.LogicalOperationClock `protobuf:"bytes,5,rep,name=locs" json:"locs,omitempty"`
	// If any tentative updates are outstanding (on the control block or on any
	// of the replicas), then the following give the (component_id,
	// incarnation_id) of the component that made all those tentative
	// updates. This is because at any time, all tentative updates have to be
	// from a specific incarnation of one component. If anyone else attempts to
	// make tentative updates, they need to first resolve the old tentative
	// updates first. Note that 'loc' may not correspond to these - the 'loc'
	// might belong to a component that's trying to resolve tentative updates
	// made by another component.
	TentativeUpdateComponentId   *int64 `protobuf:"varint,6,opt,name=tentative_update_component_id,json=tentativeUpdateComponentId" json:"tentative_update_component_id,omitempty"`
	TentativeUpdateIncarnationId *int64 `protobuf:"varint,7,opt,name=tentative_update_incarnation_id,json=tentativeUpdateIncarnationId" json:"tentative_update_incarnation_id,omitempty"`
	// Any tentative update outstanding on this control block.
	TentativeUpdate *MedusaExtentGroupIdMapEntryProto_TentativeUpdate `protobuf:"bytes,8,opt,name=tentative_update,json=tentativeUpdate" json:"tentative_update,omitempty"`
	// Last time this extent group was migrated from one storage tier to
	// another due to ILM reasons.
	IlmMigrationTimeUsecs *int64 `protobuf:"varint,9,opt,name=ilm_migration_time_usecs,json=ilmMigrationTimeUsecs" json:"ilm_migration_time_usecs,omitempty"`
	// Which container owns this extent group. If the vdisk specified by
	// owner_vdisk_id no longer exists in the Zeus config, the extent group's
	// data is immutable. At that point, any vdisk controller for any vdisk in
	// the container owner_container_id can be used to perform operations
	// (e.g., refcount updates, replication) on this extent group.
	OwnerContainerId *int64 `protobuf:"varint,10,req,name=owner_container_id,json=ownerContainerId" json:"owner_container_id,omitempty"`
	// The offset in the extent group file where the next new slice will be
	// allocated. This is a hint and could be stale.
	NextSliceAllocationOffsetHint *int32 `protobuf:"varint,11,opt,name=next_slice_allocation_offset_hint,json=nextSliceAllocationOffsetHint" json:"next_slice_allocation_offset_hint,omitempty"`
	// For an uncompressed extent group, if set, this field indicates that the
	// extent group contains data that is not compressible, and we will wait
	// for the specified number of bytes to be written to this extent group
	// before we retry compression.
	//
	// For a mixed compression extent group, if set to > 0, this field
	// indicates the amount of data needs to be written to the uncompressed
	// slices before we retry compressing the extent group. If set to 0, this
	// field indicates we should retry compressing the extent group.
	//
	// For a non-mixed compression extent group, this should not be set.
	// This field is not set for extent groups managed by AES. For AES egroups,
	// a similar field is set in the extent group physical state map.
	BytesToWriteBeforeRetryingCompression *int32 `protobuf:"varint,12,opt,name=bytes_to_write_before_retrying_compression,json=bytesToWriteBeforeRetryingCompression" json:"bytes_to_write_before_retrying_compression,omitempty"`
	// If present, this represents the logical timestamp for the intent to
	// delete this extent group.
	DeleteIntentLogicalTimestamp *int64 `protobuf:"varint,13,opt,name=delete_intent_logical_timestamp,json=deleteIntentLogicalTimestamp" json:"delete_intent_logical_timestamp,omitempty"`
	// Time when this extent group was last updated (in absolute usecs).
	WriteTimeUsecs *int64 `protobuf:"varint,14,opt,name=write_time_usecs,json=writeTimeUsecs" json:"write_time_usecs,omitempty"`
	// The parity extent group ids of an erasure coding strip. The order of ids
	// in this repeated field is determined by the erasure coding method.
	// The first extent group is considered primary. The field is only set in
	// erasure coded information extent groups and parity extent groups.
	ErasureCodeParityEgroupIds []int64 `protobuf:"varint,15,rep,name=erasure_code_parity_egroup_ids,json=erasureCodeParityEgroupIds" json:"erasure_code_parity_egroup_ids,omitempty"`
	// The information extent groups ids of an erasure coding strip. This
	// field is only set in the control block of primary parity extent group.
	// All other extent groups on an erasure strip must only set
	// 'erasure_code_parity_egroup_ids'.
	ErasureCodeInfoEgroupIds []int64 `protobuf:"varint,16,rep,name=erasure_code_info_egroup_ids,json=erasureCodeInfoEgroupIds" json:"erasure_code_info_egroup_ids,omitempty"`
	// The slice size used to compress state states. If this field is set
	// then one or more slices in the slice state vector are compressed.
	DefaultSliceSize *int32  `protobuf:"varint,17,opt,name=default_slice_size,json=defaultSliceSize" json:"default_slice_size,omitempty"`
	PropertyBitFlags *uint32 `protobuf:"varint,18,opt,name=property_bit_flags,json=propertyBitFlags" json:"property_bit_flags,omitempty"`
	// The transformation applied on the slices in this extent group.
	// The transformation describes how the original data is morphed into the
	// form that is stored on disk. For example, the transformation may be an
	// identity function, or a number of functions like compression,
	// encryption, etc., that are applied one after the other. All data stored
	// in an extent group has the same transformation. The exceptions to this
	// rule are slices which do not have 'transformed_length' set do not have
	// any transformation applied. The order in the repeated field specifies
	// the order in which the transformation types are applied. For example:
	// [kCompressionX, kEncryptionY] means compression X is applied before
	// encryption Y.
	// Note: 'transformation_type_list' is the newer way to set the
	// transformation types compared to the string 'transformation_type' above.
	// New functionalities like uncompressed slices in a compressed extent
	// group and prepending compressed size in the slice are only available
	// when this field is set.
	TransformationTypeList []base.DataTransformation_Type `protobuf:"varint,19,rep,name=transformation_type_list,json=transformationTypeList,enum=nutanix.DataTransformation_Type" json:"transformation_type_list,omitempty"`
	// History of last few extent group movements. To prevent metadata
	// bloat up, this grows to a fixed size after which, oldest entry is
	// replaced with the new entry.
	EgroupMovementHistory []*MedusaExtentGroupIdMapEntryProto_ControlBlock_EgroupMovementHistory `protobuf:"bytes,20,rep,name=egroup_movement_history,json=egroupMovementHistory" json:"egroup_movement_history,omitempty"`
	// Cipher key UUID used to lookup cipher key in Mantle.
	CipherKeyId []byte `protobuf:"bytes,21,opt,name=cipher_key_id,json=cipherKeyId" json:"cipher_key_id,omitempty"`
	// Last value of the ilm migration multiplier. This value serves as a
	// feedback mechanism to prevent egroup thrashing between tiers.
	MigrationCooldownMultiplier *float64 `protobuf:"fixed64,22,opt,name=migration_cooldown_multiplier,json=migrationCooldownMultiplier,def=1" json:"migration_cooldown_multiplier,omitempty"`
	// This indicates if the slices stored in the below group have been grouped
	// by their slice ids. If false, the slices in the group will be positioned
	// based on their slice index in the extent. The slice group key will
	// contain the extent id in this case.
	SlicesStoredById *bool `protobuf:"varint,23,opt,name=slices_stored_by_id,json=slicesStoredById" json:"slices_stored_by_id,omitempty"`
	// If this egroup is managed by AES, the following provides the size of the
	// slice group in which the slice information will be stored in the
	// physical state map. Storing this value here allows us to issue a single
	// lookup for both the control block and extent state/slice group during a
	// read or write operation in the extent store. Otherwise, we would have to
	// first lookup the physical state control block and then issue another
	// lookup for the appropriate keys to get the extent state.
	SliceGroupSize *int32 `protobuf:"varint,24,opt,name=slice_group_size,json=sliceGroupSize,def=32" json:"slice_group_size,omitempty"`
	// This field is in parallel with 'erasure_code_info_egroup_ids'. It
	// indicates whether the corresponding information extent group is empty.
	// This field is only set in the control block of primary parity extent
	// group.
	IsErasureCodeInfoEgroupEmpty []bool   `protobuf:"varint,25,rep,name=is_erasure_code_info_egroup_empty,json=isErasureCodeInfoEgroupEmpty" json:"is_erasure_code_info_egroup_empty,omitempty"`
	XXX_NoUnkeyedLiteral         struct{} `json:"-"`
	XXX_unrecognized             []byte   `json:"-"`
	XXX_sizecache                int32    `json:"-"`
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) Reset() {
	*m = MedusaExtentGroupIdMapEntryProto_ControlBlock{}
}
func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaExtentGroupIdMapEntryProto_ControlBlock) ProtoMessage() {}
func (*MedusaExtentGroupIdMapEntryProto_ControlBlock) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{1, 6}
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_ControlBlock.Unmarshal(m, b)
}
func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_ControlBlock.Marshal(b, m, deterministic)
}
func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_ControlBlock.Merge(m, src)
}
func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) XXX_Size() int {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_ControlBlock.Size(m)
}
func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_ControlBlock.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_ControlBlock proto.InternalMessageInfo

const Default_MedusaExtentGroupIdMapEntryProto_ControlBlock_MigrationCooldownMultiplier float64 = 1
const Default_MedusaExtentGroupIdMapEntryProto_ControlBlock_SliceGroupSize int32 = 32

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) GetOwnerVdiskId() int64 {
	if m != nil && m.OwnerVdiskId != nil {
		return *m.OwnerVdiskId
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) GetTransformationType() string {
	if m != nil && m.TransformationType != nil {
		return *m.TransformationType
	}
	return ""
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) GetReplicas() []*MedusaExtentGroupIdMapEntryProto_Replica {
	if m != nil {
		return m.Replicas
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) GetLatestIntentSequence() int64 {
	if m != nil && m.LatestIntentSequence != nil {
		return *m.LatestIntentSequence
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) GetLocs() []*zeus.LogicalOperationClock {
	if m != nil {
		return m.Locs
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) GetTentativeUpdateComponentId() int64 {
	if m != nil && m.TentativeUpdateComponentId != nil {
		return *m.TentativeUpdateComponentId
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) GetTentativeUpdateIncarnationId() int64 {
	if m != nil && m.TentativeUpdateIncarnationId != nil {
		return *m.TentativeUpdateIncarnationId
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) GetTentativeUpdate() *MedusaExtentGroupIdMapEntryProto_TentativeUpdate {
	if m != nil {
		return m.TentativeUpdate
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) GetIlmMigrationTimeUsecs() int64 {
	if m != nil && m.IlmMigrationTimeUsecs != nil {
		return *m.IlmMigrationTimeUsecs
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) GetOwnerContainerId() int64 {
	if m != nil && m.OwnerContainerId != nil {
		return *m.OwnerContainerId
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) GetNextSliceAllocationOffsetHint() int32 {
	if m != nil && m.NextSliceAllocationOffsetHint != nil {
		return *m.NextSliceAllocationOffsetHint
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) GetBytesToWriteBeforeRetryingCompression() int32 {
	if m != nil && m.BytesToWriteBeforeRetryingCompression != nil {
		return *m.BytesToWriteBeforeRetryingCompression
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) GetDeleteIntentLogicalTimestamp() int64 {
	if m != nil && m.DeleteIntentLogicalTimestamp != nil {
		return *m.DeleteIntentLogicalTimestamp
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) GetWriteTimeUsecs() int64 {
	if m != nil && m.WriteTimeUsecs != nil {
		return *m.WriteTimeUsecs
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) GetErasureCodeParityEgroupIds() []int64 {
	if m != nil {
		return m.ErasureCodeParityEgroupIds
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) GetErasureCodeInfoEgroupIds() []int64 {
	if m != nil {
		return m.ErasureCodeInfoEgroupIds
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) GetDefaultSliceSize() int32 {
	if m != nil && m.DefaultSliceSize != nil {
		return *m.DefaultSliceSize
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) GetPropertyBitFlags() uint32 {
	if m != nil && m.PropertyBitFlags != nil {
		return *m.PropertyBitFlags
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) GetTransformationTypeList() []base.DataTransformation_Type {
	if m != nil {
		return m.TransformationTypeList
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) GetEgroupMovementHistory() []*MedusaExtentGroupIdMapEntryProto_ControlBlock_EgroupMovementHistory {
	if m != nil {
		return m.EgroupMovementHistory
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) GetCipherKeyId() []byte {
	if m != nil {
		return m.CipherKeyId
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) GetMigrationCooldownMultiplier() float64 {
	if m != nil && m.MigrationCooldownMultiplier != nil {
		return *m.MigrationCooldownMultiplier
	}
	return Default_MedusaExtentGroupIdMapEntryProto_ControlBlock_MigrationCooldownMultiplier
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) GetSlicesStoredById() bool {
	if m != nil && m.SlicesStoredById != nil {
		return *m.SlicesStoredById
	}
	return false
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) GetSliceGroupSize() int32 {
	if m != nil && m.SliceGroupSize != nil {
		return *m.SliceGroupSize
	}
	return Default_MedusaExtentGroupIdMapEntryProto_ControlBlock_SliceGroupSize
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock) GetIsErasureCodeInfoEgroupEmpty() []bool {
	if m != nil {
		return m.IsErasureCodeInfoEgroupEmpty
	}
	return nil
}

// This provides the egroup data movement history.
type MedusaExtentGroupIdMapEntryProto_ControlBlock_EgroupMovementHistory struct {
	// Time when this egroup was last migrated.
	EgroupTimestampSecs *int64 `protobuf:"varint,1,opt,name=egroup_timestamp_secs,json=egroupTimestampSecs" json:"egroup_timestamp_secs,omitempty"`
	// Replica disk IDs from where this egroup was migrated.
	ReplicaDiskIdList []int64 `protobuf:"varint,2,rep,name=replica_disk_id_list,json=replicaDiskIdList" json:"replica_disk_id_list,omitempty"`
	// Reason why this egroup was migrated.
	DataMovementReason   *MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason `protobuf:"varint,3,opt,name=data_movement_reason,json=dataMovementReason,enum=nutanix.medusa.MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason" json:"data_movement_reason,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                                                     `json:"-"`
	XXX_unrecognized     []byte                                                       `json:"-"`
	XXX_sizecache        int32                                                        `json:"-"`
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock_EgroupMovementHistory) Reset() {
	*m = MedusaExtentGroupIdMapEntryProto_ControlBlock_EgroupMovementHistory{}
}
func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock_EgroupMovementHistory) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaExtentGroupIdMapEntryProto_ControlBlock_EgroupMovementHistory) ProtoMessage() {}
func (*MedusaExtentGroupIdMapEntryProto_ControlBlock_EgroupMovementHistory) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{1, 6, 0}
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock_EgroupMovementHistory) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_ControlBlock_EgroupMovementHistory.Unmarshal(m, b)
}
func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock_EgroupMovementHistory) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_ControlBlock_EgroupMovementHistory.Marshal(b, m, deterministic)
}
func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock_EgroupMovementHistory) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_ControlBlock_EgroupMovementHistory.Merge(m, src)
}
func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock_EgroupMovementHistory) XXX_Size() int {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_ControlBlock_EgroupMovementHistory.Size(m)
}
func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock_EgroupMovementHistory) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_ControlBlock_EgroupMovementHistory.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_ControlBlock_EgroupMovementHistory proto.InternalMessageInfo

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock_EgroupMovementHistory) GetEgroupTimestampSecs() int64 {
	if m != nil && m.EgroupTimestampSecs != nil {
		return *m.EgroupTimestampSecs
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock_EgroupMovementHistory) GetReplicaDiskIdList() []int64 {
	if m != nil {
		return m.ReplicaDiskIdList
	}
	return nil
}

func (m *MedusaExtentGroupIdMapEntryProto_ControlBlock_EgroupMovementHistory) GetDataMovementReason() MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason {
	if m != nil && m.DataMovementReason != nil {
		return *m.DataMovementReason
	}
	return MedusaExtentGroupIdMapEntryProto_kILM
}

type MedusaExtentGroupIdMapEntryProto_AccessData struct {
	// Time when this extent group was last accessed (in absolute usecs).
	AccessTimeUsecs *int64 `protobuf:"varint,1,opt,name=access_time_usecs,json=accessTimeUsecs" json:"access_time_usecs,omitempty"`
	// Which vdisk's controller owns this extent group.
	OwnerVdiskId         *int64   `protobuf:"varint,2,opt,name=owner_vdisk_id,json=ownerVdiskId" json:"owner_vdisk_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaExtentGroupIdMapEntryProto_AccessData) Reset() {
	*m = MedusaExtentGroupIdMapEntryProto_AccessData{}
}
func (m *MedusaExtentGroupIdMapEntryProto_AccessData) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaExtentGroupIdMapEntryProto_AccessData) ProtoMessage() {}
func (*MedusaExtentGroupIdMapEntryProto_AccessData) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{1, 7}
}

func (m *MedusaExtentGroupIdMapEntryProto_AccessData) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_AccessData.Unmarshal(m, b)
}
func (m *MedusaExtentGroupIdMapEntryProto_AccessData) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_AccessData.Marshal(b, m, deterministic)
}
func (m *MedusaExtentGroupIdMapEntryProto_AccessData) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_AccessData.Merge(m, src)
}
func (m *MedusaExtentGroupIdMapEntryProto_AccessData) XXX_Size() int {
	return xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_AccessData.Size(m)
}
func (m *MedusaExtentGroupIdMapEntryProto_AccessData) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_AccessData.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaExtentGroupIdMapEntryProto_AccessData proto.InternalMessageInfo

func (m *MedusaExtentGroupIdMapEntryProto_AccessData) GetAccessTimeUsecs() int64 {
	if m != nil && m.AccessTimeUsecs != nil {
		return *m.AccessTimeUsecs
	}
	return 0
}

func (m *MedusaExtentGroupIdMapEntryProto_AccessData) GetOwnerVdiskId() int64 {
	if m != nil && m.OwnerVdiskId != nil {
		return *m.OwnerVdiskId
	}
	return 0
}

//-----------------------------------------------------------------------------
// Entry in the vdisk oplog map in Medusa. This map provides the following
// information:
//   vdisk id -> Medusa state maintained for the vdisk's oplog
type MedusaVDiskOplogMapEntryProto struct {
	Episodes        []*MedusaVDiskOplogMapEntryProto_Episode       `protobuf:"bytes,1,rep,name=episodes" json:"episodes,omitempty"`
	TentativeUpdate *MedusaVDiskOplogMapEntryProto_TentativeUpdate `protobuf:"bytes,2,opt,name=tentative_update,json=tentativeUpdate" json:"tentative_update,omitempty"`
	StretchedState  *MedusaVDiskOplogMapEntryProto_StretchedState  `protobuf:"bytes,3,opt,name=stretched_state,json=stretchedState" json:"stretched_state,omitempty"`
	NearSyncState   *MedusaVDiskOplogMapEntryProto_NearSyncState   `protobuf:"bytes,4,opt,name=near_sync_state,json=nearSyncState" json:"near_sync_state,omitempty"`
	// The highest global logical timestamp that has been committed on the
	// cluster. This is only updated when an episode is closed, and therefore it
	// doesn't take into account records committed in the current non-tentative
	// open episode.
	HighestCommittedGlobalLogicalTimestamp *int64 `protobuf:"varint,5,opt,name=highest_committed_global_logical_timestamp,json=highestCommittedGlobalLogicalTimestamp,def=-1" json:"highest_committed_global_logical_timestamp,omitempty"`
	// Consistency group id that is associated with the last LWS that is
	// successfully applied on this VDisk.
	AppliedCgId *ConsistencyGroupIdProto `protobuf:"bytes,6,opt,name=applied_cg_id,json=appliedCgId" json:"applied_cg_id,omitempty"`
	// LWS Id that is successfully applied on the VDisk.
	AppliedLwsId            *int64                                                 `protobuf:"varint,7,opt,name=applied_lws_id,json=appliedLwsId" json:"applied_lws_id,omitempty"`
	LwsApplyTentativeUpdate *MedusaVDiskOplogMapEntryProto_LwsApplyTentativeUpdate `protobuf:"bytes,8,opt,name=lws_apply_tentative_update,json=lwsApplyTentativeUpdate" json:"lws_apply_tentative_update,omitempty"`
	// We start tracking oplog logical bytes after a vdisk is added to a nearsync
	// cg, and it remains sticky thereafter, even if nearsync is disabled for the
	// vdisk. If the vdisk or any of it's ancestors were ever added to a nearsync
	// cg, then the byte offset in the oplog stream for the last byte of the
	// record corresponding to 'highest_committed_global_logical_timestamp'.
	HighestCommittedGlobalLogicalBytes *int64 `protobuf:"varint,9,opt,name=highest_committed_global_logical_bytes,json=highestCommittedGlobalLogicalBytes,def=-1" json:"highest_committed_global_logical_bytes,omitempty"`
	// Highest episode sequence oplog master ever assigned to any episode.
	HighestUsedEpisodeSequence *int64   `protobuf:"varint,10,opt,name=highest_used_episode_sequence,json=highestUsedEpisodeSequence,def=-1" json:"highest_used_episode_sequence,omitempty"`
	XXX_NoUnkeyedLiteral       struct{} `json:"-"`
	XXX_unrecognized           []byte   `json:"-"`
	XXX_sizecache              int32    `json:"-"`
}

func (m *MedusaVDiskOplogMapEntryProto) Reset()         { *m = MedusaVDiskOplogMapEntryProto{} }
func (m *MedusaVDiskOplogMapEntryProto) String() string { return proto.CompactTextString(m) }
func (*MedusaVDiskOplogMapEntryProto) ProtoMessage()    {}
func (*MedusaVDiskOplogMapEntryProto) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{2}
}

func (m *MedusaVDiskOplogMapEntryProto) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaVDiskOplogMapEntryProto.Unmarshal(m, b)
}
func (m *MedusaVDiskOplogMapEntryProto) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaVDiskOplogMapEntryProto.Marshal(b, m, deterministic)
}
func (m *MedusaVDiskOplogMapEntryProto) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaVDiskOplogMapEntryProto.Merge(m, src)
}
func (m *MedusaVDiskOplogMapEntryProto) XXX_Size() int {
	return xxx_messageInfo_MedusaVDiskOplogMapEntryProto.Size(m)
}
func (m *MedusaVDiskOplogMapEntryProto) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaVDiskOplogMapEntryProto.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaVDiskOplogMapEntryProto proto.InternalMessageInfo

const Default_MedusaVDiskOplogMapEntryProto_HighestCommittedGlobalLogicalTimestamp int64 = -1
const Default_MedusaVDiskOplogMapEntryProto_HighestCommittedGlobalLogicalBytes int64 = -1
const Default_MedusaVDiskOplogMapEntryProto_HighestUsedEpisodeSequence int64 = -1

func (m *MedusaVDiskOplogMapEntryProto) GetEpisodes() []*MedusaVDiskOplogMapEntryProto_Episode {
	if m != nil {
		return m.Episodes
	}
	return nil
}

func (m *MedusaVDiskOplogMapEntryProto) GetTentativeUpdate() *MedusaVDiskOplogMapEntryProto_TentativeUpdate {
	if m != nil {
		return m.TentativeUpdate
	}
	return nil
}

func (m *MedusaVDiskOplogMapEntryProto) GetStretchedState() *MedusaVDiskOplogMapEntryProto_StretchedState {
	if m != nil {
		return m.StretchedState
	}
	return nil
}

func (m *MedusaVDiskOplogMapEntryProto) GetNearSyncState() *MedusaVDiskOplogMapEntryProto_NearSyncState {
	if m != nil {
		return m.NearSyncState
	}
	return nil
}

func (m *MedusaVDiskOplogMapEntryProto) GetHighestCommittedGlobalLogicalTimestamp() int64 {
	if m != nil && m.HighestCommittedGlobalLogicalTimestamp != nil {
		return *m.HighestCommittedGlobalLogicalTimestamp
	}
	return Default_MedusaVDiskOplogMapEntryProto_HighestCommittedGlobalLogicalTimestamp
}

func (m *MedusaVDiskOplogMapEntryProto) GetAppliedCgId() *ConsistencyGroupIdProto {
	if m != nil {
		return m.AppliedCgId
	}
	return nil
}

func (m *MedusaVDiskOplogMapEntryProto) GetAppliedLwsId() int64 {
	if m != nil && m.AppliedLwsId != nil {
		return *m.AppliedLwsId
	}
	return 0
}

func (m *MedusaVDiskOplogMapEntryProto) GetLwsApplyTentativeUpdate() *MedusaVDiskOplogMapEntryProto_LwsApplyTentativeUpdate {
	if m != nil {
		return m.LwsApplyTentativeUpdate
	}
	return nil
}

func (m *MedusaVDiskOplogMapEntryProto) GetHighestCommittedGlobalLogicalBytes() int64 {
	if m != nil && m.HighestCommittedGlobalLogicalBytes != nil {
		return *m.HighestCommittedGlobalLogicalBytes
	}
	return Default_MedusaVDiskOplogMapEntryProto_HighestCommittedGlobalLogicalBytes
}

func (m *MedusaVDiskOplogMapEntryProto) GetHighestUsedEpisodeSequence() int64 {
	if m != nil && m.HighestUsedEpisodeSequence != nil {
		return *m.HighestUsedEpisodeSequence
	}
	return Default_MedusaVDiskOplogMapEntryProto_HighestUsedEpisodeSequence
}

// Secondary replicas used in one stripe. The number of replicas in this
// stripe is one less than the replication factor used in the oplog (as the
// primary replica is not contained in the stripe). Thus, if the replication
// factor is 3, a stripe will have 2 replicas. Any update will be written to
// the primary, and if it happens to be written to this stripe, then it'll
// be written to all the replicas in this stripe.
type MedusaVDiskOplogMapEntryProto_Stripe struct {
	// The SVM ids of the replicas. This field will be deprecated in future
	// releases. Field replica_disks will be used instead.
	Replicas []int64 `protobuf:"varint,1,rep,name=replicas" json:"replicas,omitempty"` // Deprecated: Do not use.
	// The disk ids of the replicas. During upgrade to multi disk oplog
	// version, episodes created by upgraded nodes will have both 'replicas'
	// and 'replica_disks' set. Once all nodes have upgraded to multi disk
	// oplog version only 'replica_disks' will be set.
	ReplicaDisks []int64 `protobuf:"varint,2,rep,name=replica_disks,json=replicaDisks" json:"replica_disks,omitempty"`
	// In order to support near-sync we will also allocate a sibling hdd disk
	// for each ssd replica disk in 'replica_disks'. At episode allocation time
	// the sibling ssd and hdd disks will be selected on the same service vm.
	// The disk ids of the sibling disks corresponding to the ssds in
	// 'replica_disks'.
	ReplicaHddDisks      []int64  `protobuf:"varint,3,rep,name=replica_hdd_disks,json=replicaHddDisks" json:"replica_hdd_disks,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaVDiskOplogMapEntryProto_Stripe) Reset()         { *m = MedusaVDiskOplogMapEntryProto_Stripe{} }
func (m *MedusaVDiskOplogMapEntryProto_Stripe) String() string { return proto.CompactTextString(m) }
func (*MedusaVDiskOplogMapEntryProto_Stripe) ProtoMessage()    {}
func (*MedusaVDiskOplogMapEntryProto_Stripe) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{2, 0}
}

func (m *MedusaVDiskOplogMapEntryProto_Stripe) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaVDiskOplogMapEntryProto_Stripe.Unmarshal(m, b)
}
func (m *MedusaVDiskOplogMapEntryProto_Stripe) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaVDiskOplogMapEntryProto_Stripe.Marshal(b, m, deterministic)
}
func (m *MedusaVDiskOplogMapEntryProto_Stripe) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaVDiskOplogMapEntryProto_Stripe.Merge(m, src)
}
func (m *MedusaVDiskOplogMapEntryProto_Stripe) XXX_Size() int {
	return xxx_messageInfo_MedusaVDiskOplogMapEntryProto_Stripe.Size(m)
}
func (m *MedusaVDiskOplogMapEntryProto_Stripe) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaVDiskOplogMapEntryProto_Stripe.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaVDiskOplogMapEntryProto_Stripe proto.InternalMessageInfo

// Deprecated: Do not use.
func (m *MedusaVDiskOplogMapEntryProto_Stripe) GetReplicas() []int64 {
	if m != nil {
		return m.Replicas
	}
	return nil
}

func (m *MedusaVDiskOplogMapEntryProto_Stripe) GetReplicaDisks() []int64 {
	if m != nil {
		return m.ReplicaDisks
	}
	return nil
}

func (m *MedusaVDiskOplogMapEntryProto_Stripe) GetReplicaHddDisks() []int64 {
	if m != nil {
		return m.ReplicaHddDisks
	}
	return nil
}

type MedusaVDiskOplogMapEntryProto_Episode struct {
	// Unique sequence assigned to this episode. Episode sequences are
	// monotonically increasing. However, consecutive episodes in Medusa may
	// not have consecutive sequences (i.e., at times we may skip adding some
	// episodes to Medusa metadata). This happens when an episode has no valid
	// records.
	EpisodeSequence *int64 `protobuf:"varint,1,req,name=episode_sequence,json=episodeSequence" json:"episode_sequence,omitempty"`
	// SVM id of the primary used for this episode. Not specified if
	// clean_episode is set. Otherwise, it is always set. This field will be
	// deprecated in future releases. Field primary_disk will be used instead.
	Primary *int64 `protobuf:"varint,2,opt,name=primary" json:"primary,omitempty"` // Deprecated: Do not use.
	// Stripes of the secondary replicas. Each stripe would have the same
	// number of secondary replicas (equal to one less than the replication
	// factor). The number of stripes should ideally be equal to more than
	// the number of NICs bonded together (as stripes are used to give the
	// full bandwidth during bonding).
	//
	// The index of a stripe within secondary_stripes provides an id of that
	// stripe. Each oplog record has a logical timestamp attached to it -
	// the stripe on which it is written is determined by mod'ing the
	// logical timestamp by the total number of stripes.
	SecondaryStripes []*MedusaVDiskOplogMapEntryProto_Stripe `protobuf:"bytes,3,rep,name=secondary_stripes,json=secondaryStripes" json:"secondary_stripes,omitempty"`
	// The first record in every episode is given a logical timestamp of 0.
	// Thus, any record is uniquely identified by the pair
	// (episode_sequence, logical_timestamp).
	//
	// For verification purposes, every episode other than the latest one also
	// has a logical timestamp that must be found in that episode. This
	// corresponds to the logical timestamp of the latest record of type
	// DistributedOplogRecordMetadata::AddDataTentative that is known to have
	// committed in that episode. Note that AddDataTentative records with
	// higher logical timestamps may exist in that episode, but the data in
	// such records may not have been copied to later episodes. This happens
	// when the master recovers from a replica that hasn't written these
	// extra AddDataTentative records. If on a subsequent recovery the other
	// replica is examined, the master may find these extra AddDataTentative
	// records. Thus, for every episode other than the latest one, the master
	// recovery should ignore any AddDataTentative records whose logical
	// timestamp exceeds highest_episode_logical_timestamp (if such records
	// really committed, they'll be found again in the next episode).
	//
	// While recovering, if the records seen do not show all the logical
	// timestamps from 0 to this number, then there is some data missing
	// from this episode. Note that we can afford to lose DataRangeFlushed
	// records - we can just write the data all over again to extent store.
	// Thus we don't care about tracking such records.
	HighestEpisodeLogicalTimestamp *int64 `protobuf:"varint,4,opt,name=highest_episode_logical_timestamp,json=highestEpisodeLogicalTimestamp,def=-1" json:"highest_episode_logical_timestamp,omitempty"`
	// The following is set when the sole purpose for creating the episode is
	// to indicate that the oplog has no unflushed data to be flushed to the
	// extent store. Such an episode will be the lone episode in this Medusa
	// entry. The primary consumer of this field is the curator. The curator
	// scans for unhosted vdisks that have unflushed oplog data - the curator
	// will force hosting of such vdisks so that the data can be flushed from
	// the oplog.
	CleanEpisode *bool `protobuf:"varint,5,opt,name=clean_episode,json=cleanEpisode" json:"clean_episode,omitempty"`
	// A tentative episode is one that is temporary in nature. Recovery should
	// not recover from records in a tentative episode. It just serves to
	// indicate that the episode sequence should not be re-used in subsequent
	// master restarts. Once a tentative episode is finalized, all previous
	// tentative episodes will be removed.
	TentativeEpisode *bool `protobuf:"varint,6,opt,name=tentative_episode,json=tentativeEpisode" json:"tentative_episode,omitempty"`
	// Disk id of the primary used for this episode. Not specified if
	// clean_episode is set or if the episode metadata was created by versions
	// of software that didn't support multiple oplog disks. During upgrade to
	// multi disk oplog version, episodes created by upgraded nodes will have
	// both 'primary' and 'primary_disk' set. Once all nodes have upgraded
	// to multi disk oplog version only 'primary_disk' will be set.
	PrimaryDisk *int64 `protobuf:"varint,7,opt,name=primary_disk,json=primaryDisk" json:"primary_disk,omitempty"`
	// The cluster wide unique id assigned to this episode. This id is used by
	// the oplog store to ensure that the data read from an fallocated file
	// indeed belongs to this episode.
	EpisodeUid *int64 `protobuf:"varint,8,opt,name=episode_uid,json=episodeUid" json:"episode_uid,omitempty"`
	// The file size of the episode metadata file on primary.
	PrimaryMetadataFileSize *int64 `protobuf:"varint,9,opt,name=primary_metadata_file_size,json=primaryMetadataFileSize" json:"primary_metadata_file_size,omitempty"`
	// The file size of the episide data file on primary.
	PrimaryDataFileSize *int64                                                `protobuf:"varint,10,opt,name=primary_data_file_size,json=primaryDataFileSize" json:"primary_data_file_size,omitempty"`
	Version             *MedusaVDiskOplogMapEntryProto_Episode_EpisodeVersion `protobuf:"varint,11,opt,name=version,enum=nutanix.medusa.MedusaVDiskOplogMapEntryProto_Episode_EpisodeVersion,def=0" json:"version,omitempty"`
	// Lowest valid logical timestamp in the episode.
	LowestEpisodeLogicalTimestamp *int64 `protobuf:"varint,12,opt,name=lowest_episode_logical_timestamp,json=lowestEpisodeLogicalTimestamp,def=0" json:"lowest_episode_logical_timestamp,omitempty"`
	// Metadata file offset from which to start recovering the episode.
	StartPrimaryMetadataFileOffset *int64 `protobuf:"varint,13,opt,name=start_primary_metadata_file_offset,json=startPrimaryMetadataFileOffset,def=0" json:"start_primary_metadata_file_offset,omitempty"`
	// The file size of the episode data file containing large user writes on
	// primary.
	PrimaryLargeWritesDataFileSize *int64 `protobuf:"varint,14,opt,name=primary_large_writes_data_file_size,json=primaryLargeWritesDataFileSize" json:"primary_large_writes_data_file_size,omitempty"`
	// The global oplog logical timestamp of the lowest committed
	// 'AddDataTentative' record in the episode.
	LowestExpectedGlobalLogicalTimestamp *int64 `protobuf:"varint,15,opt,name=lowest_expected_global_logical_timestamp,json=lowestExpectedGlobalLogicalTimestamp,def=-1" json:"lowest_expected_global_logical_timestamp,omitempty"`
	// The global oplog logical timestamp of the highest committed
	// 'AddDataTentative' record in the episode.
	HighestExpectedGlobalLogicalTimestamp *int64 `protobuf:"varint,16,opt,name=highest_expected_global_logical_timestamp,json=highestExpectedGlobalLogicalTimestamp,def=-1" json:"highest_expected_global_logical_timestamp,omitempty"`
	// In order to support near-sync we will also allocate a sibling hdd disk
	// for the ssd disk specified by 'primary_disk'. At episode allocation time
	// the sibling ssd and hdd disks will be selected on the same service vm.
	// The disk id of the sibling disk corresponding to 'primary_disk'.
	PrimaryHddDisk *int64 `protobuf:"varint,17,opt,name=primary_hdd_disk,json=primaryHddDisk,def=-1" json:"primary_hdd_disk,omitempty"`
	// Whether the episode's metadata file is on hdd.
	MetadataFileOnHdd *bool `protobuf:"varint,18,opt,name=metadata_file_on_hdd,json=metadataFileOnHdd" json:"metadata_file_on_hdd,omitempty"`
	// Whether the episode's data file containing small user writes is on hdd.
	DataFileOnHdd *bool `protobuf:"varint,19,opt,name=data_file_on_hdd,json=dataFileOnHdd" json:"data_file_on_hdd,omitempty"`
	// Whether the episode's data file containing large user writes is on hdd.
	LargeWritesDataFileOnHdd *bool `protobuf:"varint,20,opt,name=large_writes_data_file_on_hdd,json=largeWritesDataFileOnHdd" json:"large_writes_data_file_on_hdd,omitempty"`
	// Whether the episode is formed by applying an LWS episode to the VDisk.
	AppliedFromLws *bool `protobuf:"varint,21,opt,name=applied_from_lws,json=appliedFromLws,def=0" json:"applied_from_lws,omitempty"`
	// The transformations applied on the records in this episode. The
	// transformations describe how the original data is morphed into the form
	// that is stored on disk. For example, the transformation may be an
	// identity function, or a number of functions like compression, encryption
	// etc., that are applied one after another. All transformed data records
	// stored in the episode have the same transformation. The order in the
	// repeated field specifies the order in which the transformation types are
	// applied. For example: [kCompressionX, kEncryptionY] means compression X
	// is applied before encryption Y. Note that not all records in the episode
	// need to be transformed especially when the transformation is not
	// required and if it does not yield any significant benefits for example
	// when the only transformation required is compression and when applied,
	// results in negative compression.
	TransformationTypeList []base.DataTransformation_Type `protobuf:"varint,22,rep,name=transformation_type_list,json=transformationTypeList,enum=nutanix.DataTransformation_Type" json:"transformation_type_list,omitempty"`
	// The byte offset in the oplog stream for the first byte of the record
	// corresponding to 'lowest_expected_global_logical_timestamp'.
	LowestExpectedGlobalLogicalBytes *int64 `protobuf:"varint,23,opt,name=lowest_expected_global_logical_bytes,json=lowestExpectedGlobalLogicalBytes,def=-1" json:"lowest_expected_global_logical_bytes,omitempty"`
	// The byte offset in the oplog stream for the last byte of the record
	// corresponding to 'highest_expected_global_logical_timestamp'.
	HighestExpectedGlobalLogicalBytes *int64 `protobuf:"varint,24,opt,name=highest_expected_global_logical_bytes,json=highestExpectedGlobalLogicalBytes,def=-1" json:"highest_expected_global_logical_bytes,omitempty"`
	// When an episode gets replicated as a part of near-sync session,
	// 'replication_session_lws_id' contains a value of first LWS in the
	// session.
	ReplicationSessionLwsId *int64 `protobuf:"varint,25,opt,name=replication_session_lws_id,json=replicationSessionLwsId,def=-1" json:"replication_session_lws_id,omitempty"`
	// Cipher key UUID used to lookup cipher key in Mantle.
	CipherKeyId []byte `protobuf:"bytes,26,opt,name=cipher_key_id,json=cipherKeyId" json:"cipher_key_id,omitempty"`
	// Adler32 checksum of the cipher key.
	CipherKeyChecksum *uint32 `protobuf:"varint,27,opt,name=cipher_key_checksum,json=cipherKeyChecksum" json:"cipher_key_checksum,omitempty"`
	// LWS-Id, in context of which, this episode was added to this VDisk's
	// oplog.
	LwsId *int64 `protobuf:"varint,28,opt,name=lws_id,json=lwsId,def=-1" json:"lws_id,omitempty"`
	// Corresponding LWSStore episode sequence, from which this oplog episode
	// was derived.
	LwsEpisodeSequence *int64 `protobuf:"varint,29,opt,name=lws_episode_sequence,json=lwsEpisodeSequence,def=-1" json:"lws_episode_sequence,omitempty"`
	// Whether ingestion of this oplog episode is still pending. Here ingestion
	// means oplog_index reflecting ranges from this episode.
	LwsApplyTentative    *bool    `protobuf:"varint,30,opt,name=lws_apply_tentative,json=lwsApplyTentative,def=0" json:"lws_apply_tentative,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) Reset()         { *m = MedusaVDiskOplogMapEntryProto_Episode{} }
func (m *MedusaVDiskOplogMapEntryProto_Episode) String() string { return proto.CompactTextString(m) }
func (*MedusaVDiskOplogMapEntryProto_Episode) ProtoMessage()    {}
func (*MedusaVDiskOplogMapEntryProto_Episode) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{2, 1}
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaVDiskOplogMapEntryProto_Episode.Unmarshal(m, b)
}
func (m *MedusaVDiskOplogMapEntryProto_Episode) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaVDiskOplogMapEntryProto_Episode.Marshal(b, m, deterministic)
}
func (m *MedusaVDiskOplogMapEntryProto_Episode) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaVDiskOplogMapEntryProto_Episode.Merge(m, src)
}
func (m *MedusaVDiskOplogMapEntryProto_Episode) XXX_Size() int {
	return xxx_messageInfo_MedusaVDiskOplogMapEntryProto_Episode.Size(m)
}
func (m *MedusaVDiskOplogMapEntryProto_Episode) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaVDiskOplogMapEntryProto_Episode.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaVDiskOplogMapEntryProto_Episode proto.InternalMessageInfo

const Default_MedusaVDiskOplogMapEntryProto_Episode_HighestEpisodeLogicalTimestamp int64 = -1
const Default_MedusaVDiskOplogMapEntryProto_Episode_Version MedusaVDiskOplogMapEntryProto_Episode_EpisodeVersion = MedusaVDiskOplogMapEntryProto_Episode_kVersionLegacy
const Default_MedusaVDiskOplogMapEntryProto_Episode_LowestEpisodeLogicalTimestamp int64 = 0
const Default_MedusaVDiskOplogMapEntryProto_Episode_StartPrimaryMetadataFileOffset int64 = 0
const Default_MedusaVDiskOplogMapEntryProto_Episode_LowestExpectedGlobalLogicalTimestamp int64 = -1
const Default_MedusaVDiskOplogMapEntryProto_Episode_HighestExpectedGlobalLogicalTimestamp int64 = -1
const Default_MedusaVDiskOplogMapEntryProto_Episode_PrimaryHddDisk int64 = -1
const Default_MedusaVDiskOplogMapEntryProto_Episode_AppliedFromLws bool = false
const Default_MedusaVDiskOplogMapEntryProto_Episode_LowestExpectedGlobalLogicalBytes int64 = -1
const Default_MedusaVDiskOplogMapEntryProto_Episode_HighestExpectedGlobalLogicalBytes int64 = -1
const Default_MedusaVDiskOplogMapEntryProto_Episode_ReplicationSessionLwsId int64 = -1
const Default_MedusaVDiskOplogMapEntryProto_Episode_LwsId int64 = -1
const Default_MedusaVDiskOplogMapEntryProto_Episode_LwsEpisodeSequence int64 = -1
const Default_MedusaVDiskOplogMapEntryProto_Episode_LwsApplyTentative bool = false

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetEpisodeSequence() int64 {
	if m != nil && m.EpisodeSequence != nil {
		return *m.EpisodeSequence
	}
	return 0
}

// Deprecated: Do not use.
func (m *MedusaVDiskOplogMapEntryProto_Episode) GetPrimary() int64 {
	if m != nil && m.Primary != nil {
		return *m.Primary
	}
	return 0
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetSecondaryStripes() []*MedusaVDiskOplogMapEntryProto_Stripe {
	if m != nil {
		return m.SecondaryStripes
	}
	return nil
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetHighestEpisodeLogicalTimestamp() int64 {
	if m != nil && m.HighestEpisodeLogicalTimestamp != nil {
		return *m.HighestEpisodeLogicalTimestamp
	}
	return Default_MedusaVDiskOplogMapEntryProto_Episode_HighestEpisodeLogicalTimestamp
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetCleanEpisode() bool {
	if m != nil && m.CleanEpisode != nil {
		return *m.CleanEpisode
	}
	return false
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetTentativeEpisode() bool {
	if m != nil && m.TentativeEpisode != nil {
		return *m.TentativeEpisode
	}
	return false
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetPrimaryDisk() int64 {
	if m != nil && m.PrimaryDisk != nil {
		return *m.PrimaryDisk
	}
	return 0
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetEpisodeUid() int64 {
	if m != nil && m.EpisodeUid != nil {
		return *m.EpisodeUid
	}
	return 0
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetPrimaryMetadataFileSize() int64 {
	if m != nil && m.PrimaryMetadataFileSize != nil {
		return *m.PrimaryMetadataFileSize
	}
	return 0
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetPrimaryDataFileSize() int64 {
	if m != nil && m.PrimaryDataFileSize != nil {
		return *m.PrimaryDataFileSize
	}
	return 0
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetVersion() MedusaVDiskOplogMapEntryProto_Episode_EpisodeVersion {
	if m != nil && m.Version != nil {
		return *m.Version
	}
	return Default_MedusaVDiskOplogMapEntryProto_Episode_Version
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetLowestEpisodeLogicalTimestamp() int64 {
	if m != nil && m.LowestEpisodeLogicalTimestamp != nil {
		return *m.LowestEpisodeLogicalTimestamp
	}
	return Default_MedusaVDiskOplogMapEntryProto_Episode_LowestEpisodeLogicalTimestamp
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetStartPrimaryMetadataFileOffset() int64 {
	if m != nil && m.StartPrimaryMetadataFileOffset != nil {
		return *m.StartPrimaryMetadataFileOffset
	}
	return Default_MedusaVDiskOplogMapEntryProto_Episode_StartPrimaryMetadataFileOffset
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetPrimaryLargeWritesDataFileSize() int64 {
	if m != nil && m.PrimaryLargeWritesDataFileSize != nil {
		return *m.PrimaryLargeWritesDataFileSize
	}
	return 0
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetLowestExpectedGlobalLogicalTimestamp() int64 {
	if m != nil && m.LowestExpectedGlobalLogicalTimestamp != nil {
		return *m.LowestExpectedGlobalLogicalTimestamp
	}
	return Default_MedusaVDiskOplogMapEntryProto_Episode_LowestExpectedGlobalLogicalTimestamp
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetHighestExpectedGlobalLogicalTimestamp() int64 {
	if m != nil && m.HighestExpectedGlobalLogicalTimestamp != nil {
		return *m.HighestExpectedGlobalLogicalTimestamp
	}
	return Default_MedusaVDiskOplogMapEntryProto_Episode_HighestExpectedGlobalLogicalTimestamp
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetPrimaryHddDisk() int64 {
	if m != nil && m.PrimaryHddDisk != nil {
		return *m.PrimaryHddDisk
	}
	return Default_MedusaVDiskOplogMapEntryProto_Episode_PrimaryHddDisk
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetMetadataFileOnHdd() bool {
	if m != nil && m.MetadataFileOnHdd != nil {
		return *m.MetadataFileOnHdd
	}
	return false
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetDataFileOnHdd() bool {
	if m != nil && m.DataFileOnHdd != nil {
		return *m.DataFileOnHdd
	}
	return false
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetLargeWritesDataFileOnHdd() bool {
	if m != nil && m.LargeWritesDataFileOnHdd != nil {
		return *m.LargeWritesDataFileOnHdd
	}
	return false
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetAppliedFromLws() bool {
	if m != nil && m.AppliedFromLws != nil {
		return *m.AppliedFromLws
	}
	return Default_MedusaVDiskOplogMapEntryProto_Episode_AppliedFromLws
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetTransformationTypeList() []base.DataTransformation_Type {
	if m != nil {
		return m.TransformationTypeList
	}
	return nil
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetLowestExpectedGlobalLogicalBytes() int64 {
	if m != nil && m.LowestExpectedGlobalLogicalBytes != nil {
		return *m.LowestExpectedGlobalLogicalBytes
	}
	return Default_MedusaVDiskOplogMapEntryProto_Episode_LowestExpectedGlobalLogicalBytes
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetHighestExpectedGlobalLogicalBytes() int64 {
	if m != nil && m.HighestExpectedGlobalLogicalBytes != nil {
		return *m.HighestExpectedGlobalLogicalBytes
	}
	return Default_MedusaVDiskOplogMapEntryProto_Episode_HighestExpectedGlobalLogicalBytes
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetReplicationSessionLwsId() int64 {
	if m != nil && m.ReplicationSessionLwsId != nil {
		return *m.ReplicationSessionLwsId
	}
	return Default_MedusaVDiskOplogMapEntryProto_Episode_ReplicationSessionLwsId
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetCipherKeyId() []byte {
	if m != nil {
		return m.CipherKeyId
	}
	return nil
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetCipherKeyChecksum() uint32 {
	if m != nil && m.CipherKeyChecksum != nil {
		return *m.CipherKeyChecksum
	}
	return 0
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetLwsId() int64 {
	if m != nil && m.LwsId != nil {
		return *m.LwsId
	}
	return Default_MedusaVDiskOplogMapEntryProto_Episode_LwsId
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetLwsEpisodeSequence() int64 {
	if m != nil && m.LwsEpisodeSequence != nil {
		return *m.LwsEpisodeSequence
	}
	return Default_MedusaVDiskOplogMapEntryProto_Episode_LwsEpisodeSequence
}

func (m *MedusaVDiskOplogMapEntryProto_Episode) GetLwsApplyTentative() bool {
	if m != nil && m.LwsApplyTentative != nil {
		return *m.LwsApplyTentative
	}
	return Default_MedusaVDiskOplogMapEntryProto_Episode_LwsApplyTentative
}

// While taking vdisk snapshots, the parent vdisk's oplog metadata is copied
// to the child and marked as tentative. Similarly, the tentative update is
// added in the parent vdisk's oplog metadata which includes the child vdisk
// ids that are going to be created by the ongoing snapshot operation. This
// allows the vdisk controller to detect a pre-empted snapshot during oplog
// recovery, and take the required actions to either roll forward or roll
// back the oplog map entry for the vdisks. The oplog map entries for parent
// and child vdisks are finalized once snapshot operation is complete.
type MedusaVDiskOplogMapEntryProto_TentativeUpdate struct {
	ChildVdiskIds        []int64  `protobuf:"varint,1,rep,name=child_vdisk_ids,json=childVdiskIds" json:"child_vdisk_ids,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaVDiskOplogMapEntryProto_TentativeUpdate) Reset() {
	*m = MedusaVDiskOplogMapEntryProto_TentativeUpdate{}
}
func (m *MedusaVDiskOplogMapEntryProto_TentativeUpdate) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaVDiskOplogMapEntryProto_TentativeUpdate) ProtoMessage() {}
func (*MedusaVDiskOplogMapEntryProto_TentativeUpdate) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{2, 2}
}

func (m *MedusaVDiskOplogMapEntryProto_TentativeUpdate) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaVDiskOplogMapEntryProto_TentativeUpdate.Unmarshal(m, b)
}
func (m *MedusaVDiskOplogMapEntryProto_TentativeUpdate) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaVDiskOplogMapEntryProto_TentativeUpdate.Marshal(b, m, deterministic)
}
func (m *MedusaVDiskOplogMapEntryProto_TentativeUpdate) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaVDiskOplogMapEntryProto_TentativeUpdate.Merge(m, src)
}
func (m *MedusaVDiskOplogMapEntryProto_TentativeUpdate) XXX_Size() int {
	return xxx_messageInfo_MedusaVDiskOplogMapEntryProto_TentativeUpdate.Size(m)
}
func (m *MedusaVDiskOplogMapEntryProto_TentativeUpdate) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaVDiskOplogMapEntryProto_TentativeUpdate.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaVDiskOplogMapEntryProto_TentativeUpdate proto.InternalMessageInfo

func (m *MedusaVDiskOplogMapEntryProto_TentativeUpdate) GetChildVdiskIds() []int64 {
	if m != nil {
		return m.ChildVdiskIds
	}
	return nil
}

// The following fields are only set if the vdisk is stretched and oplog is
// marked clean.
type MedusaVDiskOplogMapEntryProto_StretchedState struct {
	// The highest committed logical timestamp seen by this cluster.
	HighestCommittedStretchedLogicalTimestamp *int64 `protobuf:"varint,1,opt,name=highest_committed_stretched_logical_timestamp,json=highestCommittedStretchedLogicalTimestamp" json:"highest_committed_stretched_logical_timestamp,omitempty"`
	// The highest logical timestamp seen by this cluster. In a stretched
	// cluster, data from oplog for a stretched vdisk is only flushed when the
	// write is committed. So the oplog can only be marked as clean if there is
	// no write record after the last commit record. This mean the below
	// timestamp should be the logical timestamp of the last commit record.
	HighestSeenStretchedLogicalTimestamp *int64 `protobuf:"varint,2,opt,name=highest_seen_stretched_logical_timestamp,json=highestSeenStretchedLogicalTimestamp" json:"highest_seen_stretched_logical_timestamp,omitempty"`
	// This is used as a virtual session identifier between stretch primary and
	// stretch secondary. On stretch primary, it is incremented whenever vdisk
	// is hosted and sent on every request to stretch secondary. On stretch
	// secondary, all requests having lesser stretch_session_id would be
	// discarded as stale request. This is also persisted on stretch secondary
	// oplog metadata to handle stargate restart on stretch secondary.
	StretchSessionId             *int64                                                                       `protobuf:"varint,3,opt,name=stretch_session_id,json=stretchSessionId" json:"stretch_session_id,omitempty"`
	DrainedEpisodeRecordMetadata []*MedusaVDiskOplogMapEntryProto_StretchedState_DrainedEpisodeRecordMetadata `protobuf:"bytes,4,rep,name=drained_episode_record_metadata,json=drainedEpisodeRecordMetadata" json:"drained_episode_record_metadata,omitempty"`
	XXX_NoUnkeyedLiteral         struct{}                                                                     `json:"-"`
	XXX_unrecognized             []byte                                                                       `json:"-"`
	XXX_sizecache                int32                                                                        `json:"-"`
}

func (m *MedusaVDiskOplogMapEntryProto_StretchedState) Reset() {
	*m = MedusaVDiskOplogMapEntryProto_StretchedState{}
}
func (m *MedusaVDiskOplogMapEntryProto_StretchedState) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaVDiskOplogMapEntryProto_StretchedState) ProtoMessage() {}
func (*MedusaVDiskOplogMapEntryProto_StretchedState) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{2, 3}
}

func (m *MedusaVDiskOplogMapEntryProto_StretchedState) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaVDiskOplogMapEntryProto_StretchedState.Unmarshal(m, b)
}
func (m *MedusaVDiskOplogMapEntryProto_StretchedState) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaVDiskOplogMapEntryProto_StretchedState.Marshal(b, m, deterministic)
}
func (m *MedusaVDiskOplogMapEntryProto_StretchedState) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaVDiskOplogMapEntryProto_StretchedState.Merge(m, src)
}
func (m *MedusaVDiskOplogMapEntryProto_StretchedState) XXX_Size() int {
	return xxx_messageInfo_MedusaVDiskOplogMapEntryProto_StretchedState.Size(m)
}
func (m *MedusaVDiskOplogMapEntryProto_StretchedState) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaVDiskOplogMapEntryProto_StretchedState.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaVDiskOplogMapEntryProto_StretchedState proto.InternalMessageInfo

func (m *MedusaVDiskOplogMapEntryProto_StretchedState) GetHighestCommittedStretchedLogicalTimestamp() int64 {
	if m != nil && m.HighestCommittedStretchedLogicalTimestamp != nil {
		return *m.HighestCommittedStretchedLogicalTimestamp
	}
	return 0
}

func (m *MedusaVDiskOplogMapEntryProto_StretchedState) GetHighestSeenStretchedLogicalTimestamp() int64 {
	if m != nil && m.HighestSeenStretchedLogicalTimestamp != nil {
		return *m.HighestSeenStretchedLogicalTimestamp
	}
	return 0
}

func (m *MedusaVDiskOplogMapEntryProto_StretchedState) GetStretchSessionId() int64 {
	if m != nil && m.StretchSessionId != nil {
		return *m.StretchSessionId
	}
	return 0
}

func (m *MedusaVDiskOplogMapEntryProto_StretchedState) GetDrainedEpisodeRecordMetadata() []*MedusaVDiskOplogMapEntryProto_StretchedState_DrainedEpisodeRecordMetadata {
	if m != nil {
		return m.DrainedEpisodeRecordMetadata
	}
	return nil
}

// Metadata of all the write records which are yet to be acknowledged by
// the other side in a stretch cluster. These records have been drained to
// extent store and corresponding episodes have been checkpointed. The data
// for these records should be read from extent store if required during
// stretch recovery.
type MedusaVDiskOplogMapEntryProto_StretchedState_DrainedEpisodeRecordMetadata struct {
	// The epsidoe sequence of the episode being drained.
	EpisodeSequence *int64 `protobuf:"varint,1,opt,name=episode_sequence,json=episodeSequence" json:"episode_sequence,omitempty"`
	// The logical timestamp of the record for a stretched relationship.
	// Each record written is given a monotonically increasing logical
	// timestamp.
	StretchedLogicalTimestamp *int64 `protobuf:"varint,2,opt,name=stretched_logical_timestamp,json=stretchedLogicalTimestamp" json:"stretched_logical_timestamp,omitempty"`
	// Beginning offset in the vdisk address space that the data in this
	// record refers to.
	VdiskOffset *int64 `protobuf:"varint,3,opt,name=vdisk_offset,json=vdiskOffset" json:"vdisk_offset,omitempty"`
	// Size of the contiguous range covered by this record.
	Size *int64 `protobuf:"varint,4,opt,name=size" json:"size,omitempty"`
	// Whether the data covered by this record is all zeros.
	ZeroData             *bool    `protobuf:"varint,5,opt,name=zero_data,json=zeroData" json:"zero_data,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaVDiskOplogMapEntryProto_StretchedState_DrainedEpisodeRecordMetadata) Reset() {
	*m = MedusaVDiskOplogMapEntryProto_StretchedState_DrainedEpisodeRecordMetadata{}
}
func (m *MedusaVDiskOplogMapEntryProto_StretchedState_DrainedEpisodeRecordMetadata) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaVDiskOplogMapEntryProto_StretchedState_DrainedEpisodeRecordMetadata) ProtoMessage() {}
func (*MedusaVDiskOplogMapEntryProto_StretchedState_DrainedEpisodeRecordMetadata) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{2, 3, 0}
}

func (m *MedusaVDiskOplogMapEntryProto_StretchedState_DrainedEpisodeRecordMetadata) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaVDiskOplogMapEntryProto_StretchedState_DrainedEpisodeRecordMetadata.Unmarshal(m, b)
}
func (m *MedusaVDiskOplogMapEntryProto_StretchedState_DrainedEpisodeRecordMetadata) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaVDiskOplogMapEntryProto_StretchedState_DrainedEpisodeRecordMetadata.Marshal(b, m, deterministic)
}
func (m *MedusaVDiskOplogMapEntryProto_StretchedState_DrainedEpisodeRecordMetadata) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaVDiskOplogMapEntryProto_StretchedState_DrainedEpisodeRecordMetadata.Merge(m, src)
}
func (m *MedusaVDiskOplogMapEntryProto_StretchedState_DrainedEpisodeRecordMetadata) XXX_Size() int {
	return xxx_messageInfo_MedusaVDiskOplogMapEntryProto_StretchedState_DrainedEpisodeRecordMetadata.Size(m)
}
func (m *MedusaVDiskOplogMapEntryProto_StretchedState_DrainedEpisodeRecordMetadata) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaVDiskOplogMapEntryProto_StretchedState_DrainedEpisodeRecordMetadata.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaVDiskOplogMapEntryProto_StretchedState_DrainedEpisodeRecordMetadata proto.InternalMessageInfo

func (m *MedusaVDiskOplogMapEntryProto_StretchedState_DrainedEpisodeRecordMetadata) GetEpisodeSequence() int64 {
	if m != nil && m.EpisodeSequence != nil {
		return *m.EpisodeSequence
	}
	return 0
}

func (m *MedusaVDiskOplogMapEntryProto_StretchedState_DrainedEpisodeRecordMetadata) GetStretchedLogicalTimestamp() int64 {
	if m != nil && m.StretchedLogicalTimestamp != nil {
		return *m.StretchedLogicalTimestamp
	}
	return 0
}

func (m *MedusaVDiskOplogMapEntryProto_StretchedState_DrainedEpisodeRecordMetadata) GetVdiskOffset() int64 {
	if m != nil && m.VdiskOffset != nil {
		return *m.VdiskOffset
	}
	return 0
}

func (m *MedusaVDiskOplogMapEntryProto_StretchedState_DrainedEpisodeRecordMetadata) GetSize() int64 {
	if m != nil && m.Size != nil {
		return *m.Size
	}
	return 0
}

func (m *MedusaVDiskOplogMapEntryProto_StretchedState_DrainedEpisodeRecordMetadata) GetZeroData() bool {
	if m != nil && m.ZeroData != nil {
		return *m.ZeroData
	}
	return false
}

// The following fields are only set if the vdisk is part of a CG with
// near-sync enabled.
// Contains flushed but untransferred oplog episodes.
type MedusaVDiskOplogMapEntryProto_NearSyncState struct {
	Episodes             []*MedusaVDiskOplogMapEntryProto_Episode `protobuf:"bytes,1,rep,name=episodes" json:"episodes,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                                 `json:"-"`
	XXX_unrecognized     []byte                                   `json:"-"`
	XXX_sizecache        int32                                    `json:"-"`
}

func (m *MedusaVDiskOplogMapEntryProto_NearSyncState) Reset() {
	*m = MedusaVDiskOplogMapEntryProto_NearSyncState{}
}
func (m *MedusaVDiskOplogMapEntryProto_NearSyncState) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaVDiskOplogMapEntryProto_NearSyncState) ProtoMessage() {}
func (*MedusaVDiskOplogMapEntryProto_NearSyncState) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{2, 4}
}

func (m *MedusaVDiskOplogMapEntryProto_NearSyncState) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaVDiskOplogMapEntryProto_NearSyncState.Unmarshal(m, b)
}
func (m *MedusaVDiskOplogMapEntryProto_NearSyncState) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaVDiskOplogMapEntryProto_NearSyncState.Marshal(b, m, deterministic)
}
func (m *MedusaVDiskOplogMapEntryProto_NearSyncState) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaVDiskOplogMapEntryProto_NearSyncState.Merge(m, src)
}
func (m *MedusaVDiskOplogMapEntryProto_NearSyncState) XXX_Size() int {
	return xxx_messageInfo_MedusaVDiskOplogMapEntryProto_NearSyncState.Size(m)
}
func (m *MedusaVDiskOplogMapEntryProto_NearSyncState) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaVDiskOplogMapEntryProto_NearSyncState.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaVDiskOplogMapEntryProto_NearSyncState proto.InternalMessageInfo

func (m *MedusaVDiskOplogMapEntryProto_NearSyncState) GetEpisodes() []*MedusaVDiskOplogMapEntryProto_Episode {
	if m != nil {
		return m.Episodes
	}
	return nil
}

// Tentative update indicating LWS application.
type MedusaVDiskOplogMapEntryProto_LwsApplyTentativeUpdate struct {
	// Consistency group id and lws id that is being applied.
	AppliedCgId          *ConsistencyGroupIdProto `protobuf:"bytes,1,opt,name=applied_cg_id,json=appliedCgId" json:"applied_cg_id,omitempty"`
	AppliedLwsId         *int64                   `protobuf:"varint,2,opt,name=applied_lws_id,json=appliedLwsId" json:"applied_lws_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                 `json:"-"`
	XXX_unrecognized     []byte                   `json:"-"`
	XXX_sizecache        int32                    `json:"-"`
}

func (m *MedusaVDiskOplogMapEntryProto_LwsApplyTentativeUpdate) Reset() {
	*m = MedusaVDiskOplogMapEntryProto_LwsApplyTentativeUpdate{}
}
func (m *MedusaVDiskOplogMapEntryProto_LwsApplyTentativeUpdate) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaVDiskOplogMapEntryProto_LwsApplyTentativeUpdate) ProtoMessage() {}
func (*MedusaVDiskOplogMapEntryProto_LwsApplyTentativeUpdate) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{2, 5}
}

func (m *MedusaVDiskOplogMapEntryProto_LwsApplyTentativeUpdate) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaVDiskOplogMapEntryProto_LwsApplyTentativeUpdate.Unmarshal(m, b)
}
func (m *MedusaVDiskOplogMapEntryProto_LwsApplyTentativeUpdate) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaVDiskOplogMapEntryProto_LwsApplyTentativeUpdate.Marshal(b, m, deterministic)
}
func (m *MedusaVDiskOplogMapEntryProto_LwsApplyTentativeUpdate) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaVDiskOplogMapEntryProto_LwsApplyTentativeUpdate.Merge(m, src)
}
func (m *MedusaVDiskOplogMapEntryProto_LwsApplyTentativeUpdate) XXX_Size() int {
	return xxx_messageInfo_MedusaVDiskOplogMapEntryProto_LwsApplyTentativeUpdate.Size(m)
}
func (m *MedusaVDiskOplogMapEntryProto_LwsApplyTentativeUpdate) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaVDiskOplogMapEntryProto_LwsApplyTentativeUpdate.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaVDiskOplogMapEntryProto_LwsApplyTentativeUpdate proto.InternalMessageInfo

func (m *MedusaVDiskOplogMapEntryProto_LwsApplyTentativeUpdate) GetAppliedCgId() *ConsistencyGroupIdProto {
	if m != nil {
		return m.AppliedCgId
	}
	return nil
}

func (m *MedusaVDiskOplogMapEntryProto_LwsApplyTentativeUpdate) GetAppliedLwsId() int64 {
	if m != nil && m.AppliedLwsId != nil {
		return *m.AppliedLwsId
	}
	return 0
}

// Entry which keeps track of which clients have acquired locks on a file
// (which includes byte ranges).
type Lock struct {
	// Required. Type of lock that is being applied.
	LockType *Lock_LockType `protobuf:"varint,1,opt,name=lock_type,json=lockType,enum=nutanix.medusa.Lock_LockType" json:"lock_type,omitempty"`
	// Optional. List of regions in the file to which the lock is applied. If
	// empty, then the entire file must be treated as the region.
	ByteRanges []*Lock_ByteRange `protobuf:"bytes,2,rep,name=byte_ranges,json=byteRanges" json:"byte_ranges,omitempty"`
	// Optional. List of clients who have acquired this lock on the file ranges.
	Clients              []*net.LockClientIdentifier `protobuf:"bytes,3,rep,name=clients" json:"clients,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                    `json:"-"`
	XXX_unrecognized     []byte                      `json:"-"`
	XXX_sizecache        int32                       `json:"-"`
}

func (m *Lock) Reset()         { *m = Lock{} }
func (m *Lock) String() string { return proto.CompactTextString(m) }
func (*Lock) ProtoMessage()    {}
func (*Lock) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{3}
}

func (m *Lock) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_Lock.Unmarshal(m, b)
}
func (m *Lock) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_Lock.Marshal(b, m, deterministic)
}
func (m *Lock) XXX_Merge(src proto.Message) {
	xxx_messageInfo_Lock.Merge(m, src)
}
func (m *Lock) XXX_Size() int {
	return xxx_messageInfo_Lock.Size(m)
}
func (m *Lock) XXX_DiscardUnknown() {
	xxx_messageInfo_Lock.DiscardUnknown(m)
}

var xxx_messageInfo_Lock proto.InternalMessageInfo

func (m *Lock) GetLockType() Lock_LockType {
	if m != nil && m.LockType != nil {
		return *m.LockType
	}
	return Lock_kNull
}

func (m *Lock) GetByteRanges() []*Lock_ByteRange {
	if m != nil {
		return m.ByteRanges
	}
	return nil
}

func (m *Lock) GetClients() []*net.LockClientIdentifier {
	if m != nil {
		return m.Clients
	}
	return nil
}

// Specifies contiguous region within the file for which the lock is applied.
type Lock_ByteRange struct {
	// Required. Offset within the file where the byte-range begins.
	Offset *int64 `protobuf:"varint,1,opt,name=offset" json:"offset,omitempty"`
	// Required. Size of the byte-range in bytes.
	Length               *int64   `protobuf:"varint,2,opt,name=length" json:"length,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *Lock_ByteRange) Reset()         { *m = Lock_ByteRange{} }
func (m *Lock_ByteRange) String() string { return proto.CompactTextString(m) }
func (*Lock_ByteRange) ProtoMessage()    {}
func (*Lock_ByteRange) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{3, 0}
}

func (m *Lock_ByteRange) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_Lock_ByteRange.Unmarshal(m, b)
}
func (m *Lock_ByteRange) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_Lock_ByteRange.Marshal(b, m, deterministic)
}
func (m *Lock_ByteRange) XXX_Merge(src proto.Message) {
	xxx_messageInfo_Lock_ByteRange.Merge(m, src)
}
func (m *Lock_ByteRange) XXX_Size() int {
	return xxx_messageInfo_Lock_ByteRange.Size(m)
}
func (m *Lock_ByteRange) XXX_DiscardUnknown() {
	xxx_messageInfo_Lock_ByteRange.DiscardUnknown(m)
}

var xxx_messageInfo_Lock_ByteRange proto.InternalMessageInfo

func (m *Lock_ByteRange) GetOffset() int64 {
	if m != nil && m.Offset != nil {
		return *m.Offset
	}
	return 0
}

func (m *Lock_ByteRange) GetLength() int64 {
	if m != nil && m.Length != nil {
		return *m.Length
	}
	return 0
}

// Entry which lists iSCSI-specific metadata on a file. This message is only
// used for files backed by vdisks that are iSCSI targets.
type IscsiMetadata struct {
	// Optional. Logical unit-specific counter that needs to be returned for SCSI
	// PERSISTENT RESERVE IN commands. Reference: "6.11.2 READ KEYS service
	// action in SPC-3".
	PrGeneration *uint32 `protobuf:"varint,1,opt,name=pr_generation,json=prGeneration" json:"pr_generation,omitempty"`
	// Optional. List of clients who have registered their keys as a part of
	// persistent reservations.
	Registrations []*net.IscsiLockClientIdentifier `protobuf:"bytes,2,rep,name=registrations" json:"registrations,omitempty"`
	// Whether the reservation present is a REGISTRANTS-ONLY reservation or an
	// ALL-REGISTRANTS reservation. If this value is true, then there need not be
	// a reservation present as every registrant can be considered to be the
	// reservation holder.
	AllRegistrants *bool `protobuf:"varint,3,opt,name=all_registrants,json=allRegistrants,def=0" json:"all_registrants,omitempty"`
	// Optional. Specifies the type of lock if all_registrants is true.
	AllRegistrantsLock   *Lock    `protobuf:"bytes,4,opt,name=all_registrants_lock,json=allRegistrantsLock" json:"all_registrants_lock,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *IscsiMetadata) Reset()         { *m = IscsiMetadata{} }
func (m *IscsiMetadata) String() string { return proto.CompactTextString(m) }
func (*IscsiMetadata) ProtoMessage()    {}
func (*IscsiMetadata) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{4}
}

func (m *IscsiMetadata) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_IscsiMetadata.Unmarshal(m, b)
}
func (m *IscsiMetadata) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_IscsiMetadata.Marshal(b, m, deterministic)
}
func (m *IscsiMetadata) XXX_Merge(src proto.Message) {
	xxx_messageInfo_IscsiMetadata.Merge(m, src)
}
func (m *IscsiMetadata) XXX_Size() int {
	return xxx_messageInfo_IscsiMetadata.Size(m)
}
func (m *IscsiMetadata) XXX_DiscardUnknown() {
	xxx_messageInfo_IscsiMetadata.DiscardUnknown(m)
}

var xxx_messageInfo_IscsiMetadata proto.InternalMessageInfo

const Default_IscsiMetadata_AllRegistrants bool = false

func (m *IscsiMetadata) GetPrGeneration() uint32 {
	if m != nil && m.PrGeneration != nil {
		return *m.PrGeneration
	}
	return 0
}

func (m *IscsiMetadata) GetRegistrations() []*net.IscsiLockClientIdentifier {
	if m != nil {
		return m.Registrations
	}
	return nil
}

func (m *IscsiMetadata) GetAllRegistrants() bool {
	if m != nil && m.AllRegistrants != nil {
		return *m.AllRegistrants
	}
	return Default_IscsiMetadata_AllRegistrants
}

func (m *IscsiMetadata) GetAllRegistrantsLock() *Lock {
	if m != nil {
		return m.AllRegistrantsLock
	}
	return nil
}

// Entry which lists SMB-specific metadata on a file.
// (Deprecated in favour of the newer SmbOpenState)
type SmbMetadata struct {
	// Optional. This tracks the number of opens for this particular NFS file.
	// For each open, we add its durable id to this list. The file can be
	// deleted if this list has no entries.
	DurableFileIds []uint64 `protobuf:"varint,1,rep,name=durable_file_ids,json=durableFileIds" json:"durable_file_ids,omitempty"`
	// Optional. The desired access flags of the opens.
	DesiredAccess *uint32 `protobuf:"varint,2,opt,name=desired_access,json=desiredAccess" json:"desired_access,omitempty"`
	// Optional. The share mode flags of the  opens.
	ShareMode            *uint32  `protobuf:"varint,3,opt,name=share_mode,json=shareMode" json:"share_mode,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *SmbMetadata) Reset()         { *m = SmbMetadata{} }
func (m *SmbMetadata) String() string { return proto.CompactTextString(m) }
func (*SmbMetadata) ProtoMessage()    {}
func (*SmbMetadata) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{5}
}

func (m *SmbMetadata) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_SmbMetadata.Unmarshal(m, b)
}
func (m *SmbMetadata) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_SmbMetadata.Marshal(b, m, deterministic)
}
func (m *SmbMetadata) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SmbMetadata.Merge(m, src)
}
func (m *SmbMetadata) XXX_Size() int {
	return xxx_messageInfo_SmbMetadata.Size(m)
}
func (m *SmbMetadata) XXX_DiscardUnknown() {
	xxx_messageInfo_SmbMetadata.DiscardUnknown(m)
}

var xxx_messageInfo_SmbMetadata proto.InternalMessageInfo

func (m *SmbMetadata) GetDurableFileIds() []uint64 {
	if m != nil {
		return m.DurableFileIds
	}
	return nil
}

func (m *SmbMetadata) GetDesiredAccess() uint32 {
	if m != nil && m.DesiredAccess != nil {
		return *m.DesiredAccess
	}
	return 0
}

func (m *SmbMetadata) GetShareMode() uint32 {
	if m != nil && m.ShareMode != nil {
		return *m.ShareMode
	}
	return 0
}

// NOTE: While modifying 'MedusaNFSAttrProto', update the following files.
//       - stargate/nfs_adapter/master_WAL_printer.cc
type MedusaNFSAttrProto struct {
	// The type of this inode. This reflects enum ftype3 in NFSv3 spec.
	Ftype *int32 `protobuf:"varint,1,req,name=ftype" json:"ftype,omitempty"`
	// File permission bits.
	Mode *uint32 `protobuf:"varint,2,req,name=mode" json:"mode,omitempty"`
	// Inodes of each of the parents. The number of entries serves as the number
	// of hardlinks. Directories can only have one entry. For the directories
	// corresponding to the container inodes, the parent is the container
	// inode itself (we don't allow traversal to '/').
	ParentInodeId []*NfsInodeIdProto `protobuf:"bytes,3,rep,name=parent_inode_id,json=parentInodeId" json:"parent_inode_id,omitempty"`
	// File user id (owner).
	Uid *uint32 `protobuf:"varint,4,req,name=uid" json:"uid,omitempty"`
	// File group id.
	Gid *uint32 `protobuf:"varint,5,req,name=gid" json:"gid,omitempty"`
	// Size of the file.
	Fsize *uint64 `protobuf:"varint,6,opt,name=fsize" json:"fsize,omitempty"`
	// Device information (corresponds to the rdev field in fattr3).
	MajorDevice *int32 `protobuf:"varint,7,opt,name=major_device,json=majorDevice" json:"major_device,omitempty"`
	MinorDevice *int32 `protobuf:"varint,8,opt,name=minor_device,json=minorDevice" json:"minor_device,omitempty"`
	// Inode id corresponding to this file/dir.
	InodeId *NfsInodeIdProto `protobuf:"bytes,9,req,name=inode_id,json=inodeId" json:"inode_id,omitempty"`
	// Last time the data was modified.
	Mtime *int64 `protobuf:"varint,10,req,name=mtime" json:"mtime,omitempty"`
	// Last time the attributes were modified.
	Ctime *int64 `protobuf:"varint,11,req,name=ctime" json:"ctime,omitempty"`
	// Logical operation clocks that correspond to potentially ongoing
	// operations that last modified this entry.
	Locs []*zeus.LogicalOperationClock `protobuf:"bytes,12,rep,name=locs" json:"locs,omitempty"`
	// The number of data shards maintained in Medusa for this inode. In the
	// case of a directory, if there are too many names, the data may be
	// spread across multiple shards. For files we typically only use one
	// shard and if the data gets bigger, we'll just offload it to a vdisk.
	//
	// Entry names in a directory are hashed to a number and mod'd with
	// num_data_shards to determine which shard they'd go into. Note that
	// "." and ".." are not maintained in the data shards.
	//
	// Symlinks maintain their data in one shard too.
	NumDataShards *int32 `protobuf:"varint,13,opt,name=num_data_shards,json=numDataShards" json:"num_data_shards,omitempty"`
	// The following is set in the case of directories with data shards.
	// It contains the sum total of all entries across all data shards.
	// It does not include the implicit "." and ".." directories in the first
	// data shard.
	TotalDataShardEntries *int32 `protobuf:"varint,14,opt,name=total_data_shard_entries,json=totalDataShardEntries" json:"total_data_shard_entries,omitempty"`
	// If the data is contained in a vdisk, the following provides the vdisk
	// name. In this case, num_data_shards would be 0. Since vdisk names need
	// to be unique across all vdisks in the system, we'll name NFS vdisks as
	// "NFS:<inode_id>".
	VdiskName *string `protobuf:"bytes,15,opt,name=vdisk_name,json=vdiskName" json:"vdisk_name,omitempty"`
	// The following stores the name of the file in the NFS namespace when this
	// file is first created. If this is a regular file, this permits us to later
	// put this name in the vdisk if one is created later. This field also allows
	// us to optimistically lookup just one shard in parent inode, where this
	// file name is mapped, while finding child inode's entry. Note that the name
	// might change (e.g., when one hard links a file and then deletes the
	// original or when one renames a file) - we don't track the latest name.
	FileName *string `protobuf:"bytes,16,opt,name=file_name,json=fileName" json:"file_name,omitempty"`
	// The container id associated with this inode.
	ContainerId *int64 `protobuf:"varint,17,opt,name=container_id,json=containerId" json:"container_id,omitempty"`
	// Optional. If the NFS file is backed by a vdisk that is an iSCSI target,
	// this field specifies the iSCSI-specific metadata for the target.
	IscsiMetadata *IscsiMetadata `protobuf:"bytes,18,opt,name=iscsi_metadata,json=iscsiMetadata" json:"iscsi_metadata,omitempty"`
	// Optional. List of locks associated with this inode.
	Locks []*Lock `protobuf:"bytes,19,rep,name=locks" json:"locks,omitempty"`
	// If the inode is a snapshot, this field has the inode id of the source
	// inode of which it is a snapshot.
	ReferenceInodeId *NfsInodeIdProto `protobuf:"bytes,20,opt,name=reference_inode_id,json=referenceInodeId" json:"reference_inode_id,omitempty"`
	// The NFS Master wal-id which modified this inode last. If the inode is
	// modified without going through the WAL, 'wal_id' is set to -1. Examples
	// of inode getting modified without going through the WAL are:
	//
	//   - Slaves directly modifying the timestamps for a regular file.
	//
	//   - NFS master doing the setattr without going through a WAL record.
	WalId *int64 `protobuf:"varint,21,opt,name=wal_id,json=walId,def=-1" json:"wal_id,omitempty"`
	// The previous NFS Master wal-id which modified this inode before
	// the current wal-id. This is useful for two purposes:
	//
	// - It provides better debuggability by ensuring that we have not
	//   missed any update to the inode.
	//
	// - To handle scenarios where the inode gets modified without the WAL.
	//   For such cases the 'wal_id' field becomes -1, however the wal-id
	//   which modified the inode through the WAL previously moves down to the
	//   'prev_wal_id'. While replaying the WAL record corresponding to the
	//   'prev_wal_id' we can safely skip replay based on this field. If there
	//   are multiple writes to the inode without WAL, 'wal_id' stays at -1 and
	//   'prev_wal_id' represents the last wal-record which modified the inode
	//   through the WAL.
	PrevWalId *int64 `protobuf:"varint,22,opt,name=prev_wal_id,json=prevWalId,def=-1" json:"prev_wal_id,omitempty"`
	// Whether this inode has been deleted. This is used to mark a tombstone
	// which is later deleted from medusa once all the transactions referring
	// to this inode have been marked as done.
	Tombstone *bool `protobuf:"varint,23,opt,name=tombstone,def=0" json:"tombstone,omitempty"`
	// Optional. This metadata is specific to NFS file that is opened via smb
	// open. (Deprecated in favour of the newer SmbOpenState).
	SmbMetadata *SmbMetadata `protobuf:"bytes,24,opt,name=smb_metadata,json=smbMetadata" json:"smb_metadata,omitempty"`
	// Optional: The Light Weight Snapshot (LWS) id that created this inode.
	LwsId *LWSIdProto `protobuf:"bytes,25,opt,name=lws_id,json=lwsId" json:"lws_id,omitempty"`
	// The mvalue epoch and timestamp of the small-file at the time the shadow
	// inode was created.
	MvalueEpoch     *int64 `protobuf:"varint,26,opt,name=mvalue_epoch,json=mvalueEpoch" json:"mvalue_epoch,omitempty"`
	MvalueTimestamp *int64 `protobuf:"varint,27,opt,name=mvalue_timestamp,json=mvalueTimestamp" json:"mvalue_timestamp,omitempty"`
	// Whether this inode is being created for the purposes of LWS apply.
	IsLwsApply   *bool                            `protobuf:"varint,28,opt,name=is_lws_apply,json=isLwsApply" json:"is_lws_apply,omitempty"`
	SmbOpenState *MedusaNFSAttrProto_SmbOpenState `protobuf:"bytes,29,opt,name=smb_open_state,json=smbOpenState" json:"smb_open_state,omitempty"`
	// Whether metadata updates to Medusa are performed synchronously on writes
	// or not. This affects only vdisk-based files where Stargate typically
	// flushes metadata lazily to Medusa. The default is false (lazy metadata
	// updates). Setting this value to true causes metadata to be flushed to
	// Medusa before writes are acknowledged.
	SynchronousMetadataUpdates *bool `protobuf:"varint,30,opt,name=synchronous_metadata_updates,json=synchronousMetadataUpdates,def=0" json:"synchronous_metadata_updates,omitempty"`
	// Version of the data and ctime/mtime/fsize update. On non-stretched
	// container this value is bumped up on every medusa update. This field is
	// useful for stretched containers to ensure that out of order requests on
	// stretch secondary can be failed with appropriate error. The field will be
	// bumped up with following logic on stretch secondary.
	// 1. If the inode is at data_version V, and incoming write is for version
	//    V+1, we allow the write.
	// 2. If the inode is at data_version V, and incoming write is for version
	//    <= V, we fail the write. This must be re-transmitted or out of order
	//    request. Stretch secondary will return CAS error for this request.
	// 3. If the inode is at data_version V, and incoming write is for version
	//    > V+1, we only allow the write to proceed if the write is for
	//    re-replication of the inode (i.e., RPC contains the entire data shard (
	//    if present), and all the attributes in the request.)
	// For stretched primary, this value is bumped up on every normal write.
	// However when the inode replicas are diverged, the value is set as
	// following.
	// 1. If the inode is at data_version V, and stretch replication on secondary
	//    succeeds, we don't bump up the version. This also includes the case
	//    where a full replication from primary to secondary was performed at
	//    version V. Note that this will only happen if stretch secondary's
	//    data_version V' < V before the operation.
	// 2. If the inode is at data_version V, and stretch replication on secondary
	//    fails with CAS error at data_version V' (where V' >= V), we set the
	//    primary's data_version to V'+1.
	// The data_version field's new value can never be smaller than it's
	// persisted value.
	DataVersion *int64 `protobuf:"varint,31,opt,name=data_version,json=dataVersion" json:"data_version,omitempty"`
	// Version number that tracks link, unlink, and rename operations. Every time
	// one of these operations is performed that affects the inode, this version
	// counter is bumped up. This version is used for path-to-inode caching
	// purposes so that we can tell if a given path still refers to the same
	// inode it did when it was first cached. If the version number differs, the
	// cache is stale and needs to be refreshed.
	// 'path_version' defaults to zero to handle upgrade from previous versions
	// where 'path_version' does not exist. Future link, unlink, and rename
	// operations will add it and increment it from zero.
	PathVersion *int64 `protobuf:"varint,32,opt,name=path_version,json=pathVersion,def=0" json:"path_version,omitempty"`
	// 'stretch_params_id' of the stretch relationship this inode is a part of.
	// Entity Centric Stretch can stretch on a per file granularity. Hence we
	// need to maintain 'stretch_params_id' per inode.
	StretchParamsId *stretch_params.StretchParams_UniversalId `protobuf:"bytes,33,opt,name=stretch_params_id,json=stretchParamsId" json:"stretch_params_id,omitempty"`
	// If true, this flag indicates that the file is in recycle bin.
	InRecycleBin *bool `protobuf:"varint,34,opt,name=in_recycle_bin,json=inRecycleBin,def=0" json:"in_recycle_bin,omitempty"`
	// Time to live in the recycle bin.
	// The file can be deleted from recycle bin when
	// current time > ctime + recycle_bin_ttl_secs. (The ctime will be updated
	// when the file is moved into recycle bin.)
	RecycleBinTtlSecs    *int32   `protobuf:"varint,35,opt,name=recycle_bin_ttl_secs,json=recycleBinTtlSecs" json:"recycle_bin_ttl_secs,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaNFSAttrProto) Reset()         { *m = MedusaNFSAttrProto{} }
func (m *MedusaNFSAttrProto) String() string { return proto.CompactTextString(m) }
func (*MedusaNFSAttrProto) ProtoMessage()    {}
func (*MedusaNFSAttrProto) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{6}
}

func (m *MedusaNFSAttrProto) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNFSAttrProto.Unmarshal(m, b)
}
func (m *MedusaNFSAttrProto) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNFSAttrProto.Marshal(b, m, deterministic)
}
func (m *MedusaNFSAttrProto) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNFSAttrProto.Merge(m, src)
}
func (m *MedusaNFSAttrProto) XXX_Size() int {
	return xxx_messageInfo_MedusaNFSAttrProto.Size(m)
}
func (m *MedusaNFSAttrProto) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNFSAttrProto.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNFSAttrProto proto.InternalMessageInfo

const Default_MedusaNFSAttrProto_WalId int64 = -1
const Default_MedusaNFSAttrProto_PrevWalId int64 = -1
const Default_MedusaNFSAttrProto_Tombstone bool = false
const Default_MedusaNFSAttrProto_SynchronousMetadataUpdates bool = false
const Default_MedusaNFSAttrProto_PathVersion int64 = 0
const Default_MedusaNFSAttrProto_InRecycleBin bool = false

func (m *MedusaNFSAttrProto) GetFtype() int32 {
	if m != nil && m.Ftype != nil {
		return *m.Ftype
	}
	return 0
}

func (m *MedusaNFSAttrProto) GetMode() uint32 {
	if m != nil && m.Mode != nil {
		return *m.Mode
	}
	return 0
}

func (m *MedusaNFSAttrProto) GetParentInodeId() []*NfsInodeIdProto {
	if m != nil {
		return m.ParentInodeId
	}
	return nil
}

func (m *MedusaNFSAttrProto) GetUid() uint32 {
	if m != nil && m.Uid != nil {
		return *m.Uid
	}
	return 0
}

func (m *MedusaNFSAttrProto) GetGid() uint32 {
	if m != nil && m.Gid != nil {
		return *m.Gid
	}
	return 0
}

func (m *MedusaNFSAttrProto) GetFsize() uint64 {
	if m != nil && m.Fsize != nil {
		return *m.Fsize
	}
	return 0
}

func (m *MedusaNFSAttrProto) GetMajorDevice() int32 {
	if m != nil && m.MajorDevice != nil {
		return *m.MajorDevice
	}
	return 0
}

func (m *MedusaNFSAttrProto) GetMinorDevice() int32 {
	if m != nil && m.MinorDevice != nil {
		return *m.MinorDevice
	}
	return 0
}

func (m *MedusaNFSAttrProto) GetInodeId() *NfsInodeIdProto {
	if m != nil {
		return m.InodeId
	}
	return nil
}

func (m *MedusaNFSAttrProto) GetMtime() int64 {
	if m != nil && m.Mtime != nil {
		return *m.Mtime
	}
	return 0
}

func (m *MedusaNFSAttrProto) GetCtime() int64 {
	if m != nil && m.Ctime != nil {
		return *m.Ctime
	}
	return 0
}

func (m *MedusaNFSAttrProto) GetLocs() []*zeus.LogicalOperationClock {
	if m != nil {
		return m.Locs
	}
	return nil
}

func (m *MedusaNFSAttrProto) GetNumDataShards() int32 {
	if m != nil && m.NumDataShards != nil {
		return *m.NumDataShards
	}
	return 0
}

func (m *MedusaNFSAttrProto) GetTotalDataShardEntries() int32 {
	if m != nil && m.TotalDataShardEntries != nil {
		return *m.TotalDataShardEntries
	}
	return 0
}

func (m *MedusaNFSAttrProto) GetVdiskName() string {
	if m != nil && m.VdiskName != nil {
		return *m.VdiskName
	}
	return ""
}

func (m *MedusaNFSAttrProto) GetFileName() string {
	if m != nil && m.FileName != nil {
		return *m.FileName
	}
	return ""
}

func (m *MedusaNFSAttrProto) GetContainerId() int64 {
	if m != nil && m.ContainerId != nil {
		return *m.ContainerId
	}
	return 0
}

func (m *MedusaNFSAttrProto) GetIscsiMetadata() *IscsiMetadata {
	if m != nil {
		return m.IscsiMetadata
	}
	return nil
}

func (m *MedusaNFSAttrProto) GetLocks() []*Lock {
	if m != nil {
		return m.Locks
	}
	return nil
}

func (m *MedusaNFSAttrProto) GetReferenceInodeId() *NfsInodeIdProto {
	if m != nil {
		return m.ReferenceInodeId
	}
	return nil
}

func (m *MedusaNFSAttrProto) GetWalId() int64 {
	if m != nil && m.WalId != nil {
		return *m.WalId
	}
	return Default_MedusaNFSAttrProto_WalId
}

func (m *MedusaNFSAttrProto) GetPrevWalId() int64 {
	if m != nil && m.PrevWalId != nil {
		return *m.PrevWalId
	}
	return Default_MedusaNFSAttrProto_PrevWalId
}

func (m *MedusaNFSAttrProto) GetTombstone() bool {
	if m != nil && m.Tombstone != nil {
		return *m.Tombstone
	}
	return Default_MedusaNFSAttrProto_Tombstone
}

func (m *MedusaNFSAttrProto) GetSmbMetadata() *SmbMetadata {
	if m != nil {
		return m.SmbMetadata
	}
	return nil
}

func (m *MedusaNFSAttrProto) GetLwsId() *LWSIdProto {
	if m != nil {
		return m.LwsId
	}
	return nil
}

func (m *MedusaNFSAttrProto) GetMvalueEpoch() int64 {
	if m != nil && m.MvalueEpoch != nil {
		return *m.MvalueEpoch
	}
	return 0
}

func (m *MedusaNFSAttrProto) GetMvalueTimestamp() int64 {
	if m != nil && m.MvalueTimestamp != nil {
		return *m.MvalueTimestamp
	}
	return 0
}

func (m *MedusaNFSAttrProto) GetIsLwsApply() bool {
	if m != nil && m.IsLwsApply != nil {
		return *m.IsLwsApply
	}
	return false
}

func (m *MedusaNFSAttrProto) GetSmbOpenState() *MedusaNFSAttrProto_SmbOpenState {
	if m != nil {
		return m.SmbOpenState
	}
	return nil
}

func (m *MedusaNFSAttrProto) GetSynchronousMetadataUpdates() bool {
	if m != nil && m.SynchronousMetadataUpdates != nil {
		return *m.SynchronousMetadataUpdates
	}
	return Default_MedusaNFSAttrProto_SynchronousMetadataUpdates
}

func (m *MedusaNFSAttrProto) GetDataVersion() int64 {
	if m != nil && m.DataVersion != nil {
		return *m.DataVersion
	}
	return 0
}

func (m *MedusaNFSAttrProto) GetPathVersion() int64 {
	if m != nil && m.PathVersion != nil {
		return *m.PathVersion
	}
	return Default_MedusaNFSAttrProto_PathVersion
}

func (m *MedusaNFSAttrProto) GetStretchParamsId() *stretch_params.StretchParams_UniversalId {
	if m != nil {
		return m.StretchParamsId
	}
	return nil
}

func (m *MedusaNFSAttrProto) GetInRecycleBin() bool {
	if m != nil && m.InRecycleBin != nil {
		return *m.InRecycleBin
	}
	return Default_MedusaNFSAttrProto_InRecycleBin
}

func (m *MedusaNFSAttrProto) GetRecycleBinTtlSecs() int32 {
	if m != nil && m.RecycleBinTtlSecs != nil {
		return *m.RecycleBinTtlSecs
	}
	return 0
}

// Entry which keeps the SMB open state on a file.
type MedusaNFSAttrProto_SmbOpenState struct {
	SmbFileState *MedusaNFSAttrProto_SmbOpenState_SmbFileState  `protobuf:"varint,1,opt,name=smb_file_state,json=smbFileState,enum=nutanix.medusa.MedusaNFSAttrProto_SmbOpenState_SmbFileState,def=0" json:"smb_file_state,omitempty"`
	SmbOpenData  []*MedusaNFSAttrProto_SmbOpenState_SmbOpenData `protobuf:"bytes,2,rep,name=smb_open_data,json=smbOpenData" json:"smb_open_data,omitempty"`
	// Optional. Following is set to true if DOLC should not be supported
	// for this file. This is set automatically by SMB adapter on files which
	// are shadow cloned. Doing DOLC on files which are shadow cloned causes
	// the NFS token to ping pong as the former needs exclusive access while
	// the latter needs shared access.
	DolcNotSupported     *bool    `protobuf:"varint,3,opt,name=dolc_not_supported,json=dolcNotSupported" json:"dolc_not_supported,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaNFSAttrProto_SmbOpenState) Reset()         { *m = MedusaNFSAttrProto_SmbOpenState{} }
func (m *MedusaNFSAttrProto_SmbOpenState) String() string { return proto.CompactTextString(m) }
func (*MedusaNFSAttrProto_SmbOpenState) ProtoMessage()    {}
func (*MedusaNFSAttrProto_SmbOpenState) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{6, 0}
}

func (m *MedusaNFSAttrProto_SmbOpenState) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNFSAttrProto_SmbOpenState.Unmarshal(m, b)
}
func (m *MedusaNFSAttrProto_SmbOpenState) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNFSAttrProto_SmbOpenState.Marshal(b, m, deterministic)
}
func (m *MedusaNFSAttrProto_SmbOpenState) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNFSAttrProto_SmbOpenState.Merge(m, src)
}
func (m *MedusaNFSAttrProto_SmbOpenState) XXX_Size() int {
	return xxx_messageInfo_MedusaNFSAttrProto_SmbOpenState.Size(m)
}
func (m *MedusaNFSAttrProto_SmbOpenState) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNFSAttrProto_SmbOpenState.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNFSAttrProto_SmbOpenState proto.InternalMessageInfo

const Default_MedusaNFSAttrProto_SmbOpenState_SmbFileState MedusaNFSAttrProto_SmbOpenState_SmbFileState = MedusaNFSAttrProto_SmbOpenState_kSmbOpen

func (m *MedusaNFSAttrProto_SmbOpenState) GetSmbFileState() MedusaNFSAttrProto_SmbOpenState_SmbFileState {
	if m != nil && m.SmbFileState != nil {
		return *m.SmbFileState
	}
	return Default_MedusaNFSAttrProto_SmbOpenState_SmbFileState
}

func (m *MedusaNFSAttrProto_SmbOpenState) GetSmbOpenData() []*MedusaNFSAttrProto_SmbOpenState_SmbOpenData {
	if m != nil {
		return m.SmbOpenData
	}
	return nil
}

func (m *MedusaNFSAttrProto_SmbOpenState) GetDolcNotSupported() bool {
	if m != nil && m.DolcNotSupported != nil {
		return *m.DolcNotSupported
	}
	return false
}

// Entry which describes an SMB open.
type MedusaNFSAttrProto_SmbOpenState_SmbOpenData struct {
	// Required. This specifies the file id.
	FileId *uint64 `protobuf:"varint,1,opt,name=file_id,json=fileId" json:"file_id,omitempty"`
	// Required. The desired access flags of the open. These are the SMB
	// defined flags in SmbAccessFlags in smb_prot.h.
	DesiredAccess *uint32 `protobuf:"varint,2,opt,name=desired_access,json=desiredAccess" json:"desired_access,omitempty"`
	// Required. The share mode of the open. These are the SMB sharing mode
	// bits, defined in SmbShareMode in smb_prot.h.
	ShareMode *uint32 `protobuf:"varint,3,opt,name=share_mode,json=shareMode" json:"share_mode,omitempty"`
	// Required. The create options of the open. These are the SMB defined
	// create options, defined in SmbCreateOptions in smb_prot.h
	CreateOptions *uint32 `protobuf:"varint,4,opt,name=create_options,json=createOptions" json:"create_options,omitempty"`
	// Required. The SVM id of the stargate that created this open or
	// reconnected to it.
	SvmId *int64 `protobuf:"varint,5,opt,name=svm_id,json=svmId" json:"svm_id,omitempty"`
	// Required. The incarnation id of the above stargate.
	StargateIncarnationId *int64 `protobuf:"varint,6,opt,name=stargate_incarnation_id,json=stargateIncarnationId" json:"stargate_incarnation_id,omitempty"`
	// Required. The open reconnect timeout in milliseconds. Its zero for
	// non-durable opens.
	TimeoutMsecs *int64 `protobuf:"varint,7,opt,name=timeout_msecs,json=timeoutMsecs" json:"timeout_msecs,omitempty"`
	// Optional. If the open has been done with app-instance-id, the
	// following contains the same. The 'client_guid' is also set in this
	// case. The guid is 128 bits, so we split it into two 64 bit values and
	// store it.
	AppInstanceIdLowBytes *int64 `protobuf:"varint,8,opt,name=app_instance_id_low_bytes,json=appInstanceIdLowBytes" json:"app_instance_id_low_bytes,omitempty"`
	// Optional. High bytes of the app-instance-id guid.
	AppInstanceIdHighBytes *int64 `protobuf:"varint,9,opt,name=app_instance_id_high_bytes,json=appInstanceIdHighBytes" json:"app_instance_id_high_bytes,omitempty"`
	// Optional. The client guid of the connection through which the open
	// was requested. This is set only if the open was done with an
	// app-instance-id create context. The guid is 128 bits, so we split it
	// into two 64 bit values and store it.
	ClientGuidLowBytes *int64 `protobuf:"varint,10,opt,name=client_guid_low_bytes,json=clientGuidLowBytes" json:"client_guid_low_bytes,omitempty"`
	// Optional. High bytes of the client guid.
	ClientGuidHighBytes *int64 `protobuf:"varint,11,opt,name=client_guid_high_bytes,json=clientGuidHighBytes" json:"client_guid_high_bytes,omitempty"`
	// Optional. Following is true if the open is a shared vdisk open.
	SharedVdiskOpen      *bool    `protobuf:"varint,12,opt,name=shared_vdisk_open,json=sharedVdiskOpen" json:"shared_vdisk_open,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaNFSAttrProto_SmbOpenState_SmbOpenData) Reset() {
	*m = MedusaNFSAttrProto_SmbOpenState_SmbOpenData{}
}
func (m *MedusaNFSAttrProto_SmbOpenState_SmbOpenData) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaNFSAttrProto_SmbOpenState_SmbOpenData) ProtoMessage() {}
func (*MedusaNFSAttrProto_SmbOpenState_SmbOpenData) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{6, 0, 0}
}

func (m *MedusaNFSAttrProto_SmbOpenState_SmbOpenData) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNFSAttrProto_SmbOpenState_SmbOpenData.Unmarshal(m, b)
}
func (m *MedusaNFSAttrProto_SmbOpenState_SmbOpenData) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNFSAttrProto_SmbOpenState_SmbOpenData.Marshal(b, m, deterministic)
}
func (m *MedusaNFSAttrProto_SmbOpenState_SmbOpenData) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNFSAttrProto_SmbOpenState_SmbOpenData.Merge(m, src)
}
func (m *MedusaNFSAttrProto_SmbOpenState_SmbOpenData) XXX_Size() int {
	return xxx_messageInfo_MedusaNFSAttrProto_SmbOpenState_SmbOpenData.Size(m)
}
func (m *MedusaNFSAttrProto_SmbOpenState_SmbOpenData) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNFSAttrProto_SmbOpenState_SmbOpenData.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNFSAttrProto_SmbOpenState_SmbOpenData proto.InternalMessageInfo

func (m *MedusaNFSAttrProto_SmbOpenState_SmbOpenData) GetFileId() uint64 {
	if m != nil && m.FileId != nil {
		return *m.FileId
	}
	return 0
}

func (m *MedusaNFSAttrProto_SmbOpenState_SmbOpenData) GetDesiredAccess() uint32 {
	if m != nil && m.DesiredAccess != nil {
		return *m.DesiredAccess
	}
	return 0
}

func (m *MedusaNFSAttrProto_SmbOpenState_SmbOpenData) GetShareMode() uint32 {
	if m != nil && m.ShareMode != nil {
		return *m.ShareMode
	}
	return 0
}

func (m *MedusaNFSAttrProto_SmbOpenState_SmbOpenData) GetCreateOptions() uint32 {
	if m != nil && m.CreateOptions != nil {
		return *m.CreateOptions
	}
	return 0
}

func (m *MedusaNFSAttrProto_SmbOpenState_SmbOpenData) GetSvmId() int64 {
	if m != nil && m.SvmId != nil {
		return *m.SvmId
	}
	return 0
}

func (m *MedusaNFSAttrProto_SmbOpenState_SmbOpenData) GetStargateIncarnationId() int64 {
	if m != nil && m.StargateIncarnationId != nil {
		return *m.StargateIncarnationId
	}
	return 0
}

func (m *MedusaNFSAttrProto_SmbOpenState_SmbOpenData) GetTimeoutMsecs() int64 {
	if m != nil && m.TimeoutMsecs != nil {
		return *m.TimeoutMsecs
	}
	return 0
}

func (m *MedusaNFSAttrProto_SmbOpenState_SmbOpenData) GetAppInstanceIdLowBytes() int64 {
	if m != nil && m.AppInstanceIdLowBytes != nil {
		return *m.AppInstanceIdLowBytes
	}
	return 0
}

func (m *MedusaNFSAttrProto_SmbOpenState_SmbOpenData) GetAppInstanceIdHighBytes() int64 {
	if m != nil && m.AppInstanceIdHighBytes != nil {
		return *m.AppInstanceIdHighBytes
	}
	return 0
}

func (m *MedusaNFSAttrProto_SmbOpenState_SmbOpenData) GetClientGuidLowBytes() int64 {
	if m != nil && m.ClientGuidLowBytes != nil {
		return *m.ClientGuidLowBytes
	}
	return 0
}

func (m *MedusaNFSAttrProto_SmbOpenState_SmbOpenData) GetClientGuidHighBytes() int64 {
	if m != nil && m.ClientGuidHighBytes != nil {
		return *m.ClientGuidHighBytes
	}
	return 0
}

func (m *MedusaNFSAttrProto_SmbOpenState_SmbOpenData) GetSharedVdiskOpen() bool {
	if m != nil && m.SharedVdiskOpen != nil {
		return *m.SharedVdiskOpen
	}
	return false
}

// State maintained inside a NFS data shard.
type MedusaNFSDataShardProto struct {
	// The following two fields are maintained in case the inode corresponds to
	// a directory. It essentially contains a pairing of names in the directory
	// to the corresponding NFS inode id.
	EntryName    []string           `protobuf:"bytes,1,rep,name=entry_name,json=entryName" json:"entry_name,omitempty"`
	EntryInodeId []*NfsInodeIdProto `protobuf:"bytes,2,rep,name=entry_inode_id,json=entryInodeId" json:"entry_inode_id,omitempty"`
	// In case this data shard belongs to a file or a symbolic link, the
	// following contains the actual data in this shard.
	Content              []byte   `protobuf:"bytes,3,opt,name=content" json:"content,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaNFSDataShardProto) Reset()         { *m = MedusaNFSDataShardProto{} }
func (m *MedusaNFSDataShardProto) String() string { return proto.CompactTextString(m) }
func (*MedusaNFSDataShardProto) ProtoMessage()    {}
func (*MedusaNFSDataShardProto) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{7}
}

func (m *MedusaNFSDataShardProto) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNFSDataShardProto.Unmarshal(m, b)
}
func (m *MedusaNFSDataShardProto) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNFSDataShardProto.Marshal(b, m, deterministic)
}
func (m *MedusaNFSDataShardProto) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNFSDataShardProto.Merge(m, src)
}
func (m *MedusaNFSDataShardProto) XXX_Size() int {
	return xxx_messageInfo_MedusaNFSDataShardProto.Size(m)
}
func (m *MedusaNFSDataShardProto) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNFSDataShardProto.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNFSDataShardProto proto.InternalMessageInfo

func (m *MedusaNFSDataShardProto) GetEntryName() []string {
	if m != nil {
		return m.EntryName
	}
	return nil
}

func (m *MedusaNFSDataShardProto) GetEntryInodeId() []*NfsInodeIdProto {
	if m != nil {
		return m.EntryInodeId
	}
	return nil
}

func (m *MedusaNFSDataShardProto) GetContent() []byte {
	if m != nil {
		return m.Content
	}
	return nil
}

// Proto to store attributes of an NFS inode and its corresponding data shards
// as a single column in the backend store.
type MedusaNFSMapEntryProto struct {
	// NFS inode attributes.
	NfsAttr *MedusaNFSAttrProto `protobuf:"bytes,1,req,name=nfs_attr,json=nfsAttr" json:"nfs_attr,omitempty"`
	// Data shards corresponding to this inode.
	DataShards           []*MedusaNFSDataShardProto `protobuf:"bytes,2,rep,name=data_shards,json=dataShards" json:"data_shards,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                   `json:"-"`
	XXX_unrecognized     []byte                     `json:"-"`
	XXX_sizecache        int32                      `json:"-"`
}

func (m *MedusaNFSMapEntryProto) Reset()         { *m = MedusaNFSMapEntryProto{} }
func (m *MedusaNFSMapEntryProto) String() string { return proto.CompactTextString(m) }
func (*MedusaNFSMapEntryProto) ProtoMessage()    {}
func (*MedusaNFSMapEntryProto) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{8}
}

func (m *MedusaNFSMapEntryProto) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNFSMapEntryProto.Unmarshal(m, b)
}
func (m *MedusaNFSMapEntryProto) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNFSMapEntryProto.Marshal(b, m, deterministic)
}
func (m *MedusaNFSMapEntryProto) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNFSMapEntryProto.Merge(m, src)
}
func (m *MedusaNFSMapEntryProto) XXX_Size() int {
	return xxx_messageInfo_MedusaNFSMapEntryProto.Size(m)
}
func (m *MedusaNFSMapEntryProto) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNFSMapEntryProto.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNFSMapEntryProto proto.InternalMessageInfo

func (m *MedusaNFSMapEntryProto) GetNfsAttr() *MedusaNFSAttrProto {
	if m != nil {
		return m.NfsAttr
	}
	return nil
}

func (m *MedusaNFSMapEntryProto) GetDataShards() []*MedusaNFSDataShardProto {
	if m != nil {
		return m.DataShards
	}
	return nil
}

//-----------------------------------------------------------------------------
//                         State in Medusa's smb fileid map
//-----------------------------------------------------------------------------
//
// Medusa's SMB fileid map contains mappings from an SMB durable file handle id
// to the corresponding state kept for that handle. All the state for a handle
// (including the timestamp and the epoch) is kept in a single column in a
// single cassandra row.
type MedusaSmbFileIdMapEntryProto struct {
	// The durable handle id.
	DurableId *int64 `protobuf:"varint,1,opt,name=durable_id,json=durableId" json:"durable_id,omitempty"`
	// Vector of logical operation clocks that corresponds to potentially
	// ongoing operations that last modified this entry.
	Locs []*zeus.LogicalOperationClock `protobuf:"bytes,2,rep,name=locs" json:"locs,omitempty"`
	// The inode id of the file/directory. Deprecated in favor of
	// nfs_fh.
	InodeId *NfsInodeIdProto `protobuf:"bytes,3,opt,name=inode_id,json=inodeId" json:"inode_id,omitempty"`
	// The id of the container where the file/directory resides. Deprecated in
	// favor of nfs_fh.
	ContainerId *int64 `protobuf:"varint,4,opt,name=container_id,json=containerId" json:"container_id,omitempty"`
	// The inode id of the parent directory of the file/directory. Deprecated in
	// favor of parent_nfs_fh.
	ParentInodeId *NfsInodeIdProto `protobuf:"bytes,5,opt,name=parent_inode_id,json=parentInodeId" json:"parent_inode_id,omitempty"`
	// The file name supplied by the client for opening the file.
	Filename *string `protobuf:"bytes,6,opt,name=filename" json:"filename,omitempty"`
	// The access granted on this open, composed of flags from SmbAccessFlags.
	GrantedAccess *int32 `protobuf:"varint,7,opt,name=granted_access,json=grantedAccess" json:"granted_access,omitempty"`
	// The current oplock level for this open.
	OplockLevel *int32 `protobuf:"varint,8,opt,name=oplock_level,json=oplockLevel" json:"oplock_level,omitempty"`
	// The current oplock state of the file.
	OplockState *int32 `protobuf:"varint,9,opt,name=oplock_state,json=oplockState" json:"oplock_state,omitempty"`
	// A time value that indicates when a handle that has been preserved for
	// durability will be closed by the system if a client has not reclaimed it.
	DurableOpenTimeoutMsecs *int64 `protobuf:"varint,10,opt,name=durable_open_timeout_msecs,json=durableOpenTimeoutMsecs" json:"durable_open_timeout_msecs,omitempty"`
	// The low bytes of the guid that associates this open to a create request.
	CreateGuidLowBytes *int64 `protobuf:"varint,11,opt,name=create_guid_low_bytes,json=createGuidLowBytes" json:"create_guid_low_bytes,omitempty"`
	// The high bytes of the guid that associates this open to a create request.
	CreateGuidHighBytes *int64 `protobuf:"varint,12,opt,name=create_guid_high_bytes,json=createGuidHighBytes" json:"create_guid_high_bytes,omitempty"`
	// The low bytes of the guid that associates this open with a calling
	// application.
	AppInstanceIdLowBytes *int64 `protobuf:"varint,13,opt,name=app_instance_id_low_bytes,json=appInstanceIdLowBytes" json:"app_instance_id_low_bytes,omitempty"`
	// The high bytes of the guid that associates this open with a calling
	// application.
	AppInstanceIdHighBytes *int64 `protobuf:"varint,14,opt,name=app_instance_id_high_bytes,json=appInstanceIdHighBytes" json:"app_instance_id_high_bytes,omitempty"`
	// The access mode requested by the client while opening the file, composed
	// of the flags from SmbAccessFlags.
	DesiredAccess *int32 `protobuf:"varint,15,opt,name=desired_access,json=desiredAccess" json:"desired_access,omitempty"`
	// The sharing mode requested by the client while opening the file, composed
	// of the flags from SmbShareMode.
	ShareMode *int32 `protobuf:"varint,16,opt,name=share_mode,json=shareMode" json:"share_mode,omitempty"`
	// The create options requested by the client while opening the file,
	// composed of the flags from SmbCreateOptions.
	CreateOptions *int32 `protobuf:"varint,17,opt,name=create_options,json=createOptions" json:"create_options,omitempty"`
	// The file attributes used by the client for opening the file, composed of
	// the flags from SmbFileAttributes.
	FileAttributes *int32 `protobuf:"varint,18,opt,name=file_attributes,json=fileAttributes" json:"file_attributes,omitempty"`
	// The create disposition requested by the client for opening the file.
	CreateDisposition *int32 `protobuf:"varint,19,opt,name=create_disposition,json=createDisposition" json:"create_disposition,omitempty"`
	// The action that was performed when creating this file handle.
	CreateAction *int32 `protobuf:"varint,20,opt,name=create_action,json=createAction" json:"create_action,omitempty"`
	// Whether this open is persistent. If the field is not present, the handle
	// is considered persistent.
	IsPersistent *bool `protobuf:"varint,21,opt,name=is_persistent,json=isPersistent" json:"is_persistent,omitempty"`
	// This field is set by Curator if this entry is not live in any stargate. It
	// signals Curator's intent to delete the entry after a threshold amount of
	// time. If the client reconnects to the handle before the expiration time,
	// stargate removes this intent. Curator deletes the entry if it finds the
	// intent intact after the expiration time has elapsed.
	DeletionIntentTimestampMsecs *int32 `protobuf:"varint,22,opt,name=deletion_intent_timestamp_msecs,json=deletionIntentTimestampMsecs" json:"deletion_intent_timestamp_msecs,omitempty"`
	// The id of the service-VM that is connected to this handle. If no
	// service-VM is currently connected to the handle, then this field contains
	// the id of the last service-VM that connected to the handle.
	ServiceVmId *int64 `protobuf:"varint,23,opt,name=service_vm_id,json=serviceVmId" json:"service_vm_id,omitempty"`
	// The NFS file handle of the file/directory. This replaces the inode_id and
	// container_id fields.
	NfsFh []byte `protobuf:"bytes,24,opt,name=nfs_fh,json=nfsFh" json:"nfs_fh,omitempty"`
	// The NFS file handle of the parent directory of the file/directory. This
	// replaces the parent_inode_id field.
	ParentNfsFh []byte `protobuf:"bytes,25,opt,name=parent_nfs_fh,json=parentNfsFh" json:"parent_nfs_fh,omitempty"`
	// Open information for a shared virtual disk file.
	SharedVdiskOpen *MedusaSmbFileIdMapEntryProto_SharedVirtualDiskOpen `protobuf:"bytes,26,opt,name=shared_vdisk_open,json=sharedVdiskOpen" json:"shared_vdisk_open,omitempty"`
	// Following is true if this open may have been added in SmbOpenState.
	// However, it's possible that due to a crash the update to SmbOpenState
	// may not have happened, so this should only be treated as a hint.
	IsDolcSupported *bool `protobuf:"varint,27,opt,name=is_dolc_supported,json=isDolcSupported" json:"is_dolc_supported,omitempty"`
	// Optional The version of application id that is associated with this open.
	// This is valid for smb dialect 3.1.1.
	AppInstanceVersion []byte `protobuf:"bytes,28,opt,name=app_instance_version,json=appInstanceVersion" json:"app_instance_version,omitempty"`
	// The following is an incarnation id for the open. This starts from one for
	// a fresh open and is incremented on each reconnect. If this value is
	// negative then it means that the open entry is being closed. Timed closure
	// of open entries upon connection closure relies on incarnation id changing
	// on a reconnect in which case the close operation will be aborted. This
	// ensures we handle the race between a reconnect and a file-id closure. If
	// the reconnect won the race in setting this field, the file-id closure
	// will be aborted since the incarnation id will not match. If the file-id
	// closure won the race, reconnect will be aborted since the incarnation id
	// would have been made negative. Note that the reconnects can happen on
	// another node but since both the operations proceed only after successfully
	// setting this field, we avoid the above issues.
	OpenIncarnationId    *int64   `protobuf:"varint,29,opt,name=open_incarnation_id,json=openIncarnationId" json:"open_incarnation_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaSmbFileIdMapEntryProto) Reset()         { *m = MedusaSmbFileIdMapEntryProto{} }
func (m *MedusaSmbFileIdMapEntryProto) String() string { return proto.CompactTextString(m) }
func (*MedusaSmbFileIdMapEntryProto) ProtoMessage()    {}
func (*MedusaSmbFileIdMapEntryProto) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{9}
}

func (m *MedusaSmbFileIdMapEntryProto) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaSmbFileIdMapEntryProto.Unmarshal(m, b)
}
func (m *MedusaSmbFileIdMapEntryProto) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaSmbFileIdMapEntryProto.Marshal(b, m, deterministic)
}
func (m *MedusaSmbFileIdMapEntryProto) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaSmbFileIdMapEntryProto.Merge(m, src)
}
func (m *MedusaSmbFileIdMapEntryProto) XXX_Size() int {
	return xxx_messageInfo_MedusaSmbFileIdMapEntryProto.Size(m)
}
func (m *MedusaSmbFileIdMapEntryProto) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaSmbFileIdMapEntryProto.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaSmbFileIdMapEntryProto proto.InternalMessageInfo

func (m *MedusaSmbFileIdMapEntryProto) GetDurableId() int64 {
	if m != nil && m.DurableId != nil {
		return *m.DurableId
	}
	return 0
}

func (m *MedusaSmbFileIdMapEntryProto) GetLocs() []*zeus.LogicalOperationClock {
	if m != nil {
		return m.Locs
	}
	return nil
}

func (m *MedusaSmbFileIdMapEntryProto) GetInodeId() *NfsInodeIdProto {
	if m != nil {
		return m.InodeId
	}
	return nil
}

func (m *MedusaSmbFileIdMapEntryProto) GetContainerId() int64 {
	if m != nil && m.ContainerId != nil {
		return *m.ContainerId
	}
	return 0
}

func (m *MedusaSmbFileIdMapEntryProto) GetParentInodeId() *NfsInodeIdProto {
	if m != nil {
		return m.ParentInodeId
	}
	return nil
}

func (m *MedusaSmbFileIdMapEntryProto) GetFilename() string {
	if m != nil && m.Filename != nil {
		return *m.Filename
	}
	return ""
}

func (m *MedusaSmbFileIdMapEntryProto) GetGrantedAccess() int32 {
	if m != nil && m.GrantedAccess != nil {
		return *m.GrantedAccess
	}
	return 0
}

func (m *MedusaSmbFileIdMapEntryProto) GetOplockLevel() int32 {
	if m != nil && m.OplockLevel != nil {
		return *m.OplockLevel
	}
	return 0
}

func (m *MedusaSmbFileIdMapEntryProto) GetOplockState() int32 {
	if m != nil && m.OplockState != nil {
		return *m.OplockState
	}
	return 0
}

func (m *MedusaSmbFileIdMapEntryProto) GetDurableOpenTimeoutMsecs() int64 {
	if m != nil && m.DurableOpenTimeoutMsecs != nil {
		return *m.DurableOpenTimeoutMsecs
	}
	return 0
}

func (m *MedusaSmbFileIdMapEntryProto) GetCreateGuidLowBytes() int64 {
	if m != nil && m.CreateGuidLowBytes != nil {
		return *m.CreateGuidLowBytes
	}
	return 0
}

func (m *MedusaSmbFileIdMapEntryProto) GetCreateGuidHighBytes() int64 {
	if m != nil && m.CreateGuidHighBytes != nil {
		return *m.CreateGuidHighBytes
	}
	return 0
}

func (m *MedusaSmbFileIdMapEntryProto) GetAppInstanceIdLowBytes() int64 {
	if m != nil && m.AppInstanceIdLowBytes != nil {
		return *m.AppInstanceIdLowBytes
	}
	return 0
}

func (m *MedusaSmbFileIdMapEntryProto) GetAppInstanceIdHighBytes() int64 {
	if m != nil && m.AppInstanceIdHighBytes != nil {
		return *m.AppInstanceIdHighBytes
	}
	return 0
}

func (m *MedusaSmbFileIdMapEntryProto) GetDesiredAccess() int32 {
	if m != nil && m.DesiredAccess != nil {
		return *m.DesiredAccess
	}
	return 0
}

func (m *MedusaSmbFileIdMapEntryProto) GetShareMode() int32 {
	if m != nil && m.ShareMode != nil {
		return *m.ShareMode
	}
	return 0
}

func (m *MedusaSmbFileIdMapEntryProto) GetCreateOptions() int32 {
	if m != nil && m.CreateOptions != nil {
		return *m.CreateOptions
	}
	return 0
}

func (m *MedusaSmbFileIdMapEntryProto) GetFileAttributes() int32 {
	if m != nil && m.FileAttributes != nil {
		return *m.FileAttributes
	}
	return 0
}

func (m *MedusaSmbFileIdMapEntryProto) GetCreateDisposition() int32 {
	if m != nil && m.CreateDisposition != nil {
		return *m.CreateDisposition
	}
	return 0
}

func (m *MedusaSmbFileIdMapEntryProto) GetCreateAction() int32 {
	if m != nil && m.CreateAction != nil {
		return *m.CreateAction
	}
	return 0
}

func (m *MedusaSmbFileIdMapEntryProto) GetIsPersistent() bool {
	if m != nil && m.IsPersistent != nil {
		return *m.IsPersistent
	}
	return false
}

func (m *MedusaSmbFileIdMapEntryProto) GetDeletionIntentTimestampMsecs() int32 {
	if m != nil && m.DeletionIntentTimestampMsecs != nil {
		return *m.DeletionIntentTimestampMsecs
	}
	return 0
}

func (m *MedusaSmbFileIdMapEntryProto) GetServiceVmId() int64 {
	if m != nil && m.ServiceVmId != nil {
		return *m.ServiceVmId
	}
	return 0
}

func (m *MedusaSmbFileIdMapEntryProto) GetNfsFh() []byte {
	if m != nil {
		return m.NfsFh
	}
	return nil
}

func (m *MedusaSmbFileIdMapEntryProto) GetParentNfsFh() []byte {
	if m != nil {
		return m.ParentNfsFh
	}
	return nil
}

func (m *MedusaSmbFileIdMapEntryProto) GetSharedVdiskOpen() *MedusaSmbFileIdMapEntryProto_SharedVirtualDiskOpen {
	if m != nil {
		return m.SharedVdiskOpen
	}
	return nil
}

func (m *MedusaSmbFileIdMapEntryProto) GetIsDolcSupported() bool {
	if m != nil && m.IsDolcSupported != nil {
		return *m.IsDolcSupported
	}
	return false
}

func (m *MedusaSmbFileIdMapEntryProto) GetAppInstanceVersion() []byte {
	if m != nil {
		return m.AppInstanceVersion
	}
	return nil
}

func (m *MedusaSmbFileIdMapEntryProto) GetOpenIncarnationId() int64 {
	if m != nil && m.OpenIncarnationId != nil {
		return *m.OpenIncarnationId
	}
	return 0
}

type MedusaSmbFileIdMapEntryProto_SharedVirtualDiskOpen struct {
	// The GUID that identifies the initiator of the open request.
	InitiatorId          []byte   `protobuf:"bytes,1,opt,name=initiator_id,json=initiatorId" json:"initiator_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaSmbFileIdMapEntryProto_SharedVirtualDiskOpen) Reset() {
	*m = MedusaSmbFileIdMapEntryProto_SharedVirtualDiskOpen{}
}
func (m *MedusaSmbFileIdMapEntryProto_SharedVirtualDiskOpen) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaSmbFileIdMapEntryProto_SharedVirtualDiskOpen) ProtoMessage() {}
func (*MedusaSmbFileIdMapEntryProto_SharedVirtualDiskOpen) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{9, 0}
}

func (m *MedusaSmbFileIdMapEntryProto_SharedVirtualDiskOpen) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaSmbFileIdMapEntryProto_SharedVirtualDiskOpen.Unmarshal(m, b)
}
func (m *MedusaSmbFileIdMapEntryProto_SharedVirtualDiskOpen) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaSmbFileIdMapEntryProto_SharedVirtualDiskOpen.Marshal(b, m, deterministic)
}
func (m *MedusaSmbFileIdMapEntryProto_SharedVirtualDiskOpen) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaSmbFileIdMapEntryProto_SharedVirtualDiskOpen.Merge(m, src)
}
func (m *MedusaSmbFileIdMapEntryProto_SharedVirtualDiskOpen) XXX_Size() int {
	return xxx_messageInfo_MedusaSmbFileIdMapEntryProto_SharedVirtualDiskOpen.Size(m)
}
func (m *MedusaSmbFileIdMapEntryProto_SharedVirtualDiskOpen) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaSmbFileIdMapEntryProto_SharedVirtualDiskOpen.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaSmbFileIdMapEntryProto_SharedVirtualDiskOpen proto.InternalMessageInfo

func (m *MedusaSmbFileIdMapEntryProto_SharedVirtualDiskOpen) GetInitiatorId() []byte {
	if m != nil {
		return m.InitiatorId
	}
	return nil
}

// Unique identifier used to communicate information about snapshot across
// services.
type SnapshotRequestIdentifier struct {
	// Unique ID of the snapshot.
	SnapshotId *string `protobuf:"bytes,1,opt,name=snapshot_id,json=snapshotId" json:"snapshot_id,omitempty"`
	// Path prefix of the snapshot.
	SnapshotPathPrefix *string `protobuf:"bytes,2,opt,name=snapshot_path_prefix,json=snapshotPathPrefix" json:"snapshot_path_prefix,omitempty"`
	// The protection domain to which the snapshot belongs to.
	PdName *string `protobuf:"bytes,3,opt,name=pd_name,json=pdName" json:"pd_name,omitempty"`
	// The consistency group to which the snapshot belongs to.
	CgName *string `protobuf:"bytes,4,opt,name=cg_name,json=cgName" json:"cg_name,omitempty"`
	// Consistency group identifier.
	CgId                 *ConsistencyGroupIdProto `protobuf:"bytes,5,opt,name=cg_id,json=cgId" json:"cg_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                 `json:"-"`
	XXX_unrecognized     []byte                   `json:"-"`
	XXX_sizecache        int32                    `json:"-"`
}

func (m *SnapshotRequestIdentifier) Reset()         { *m = SnapshotRequestIdentifier{} }
func (m *SnapshotRequestIdentifier) String() string { return proto.CompactTextString(m) }
func (*SnapshotRequestIdentifier) ProtoMessage()    {}
func (*SnapshotRequestIdentifier) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{10}
}

func (m *SnapshotRequestIdentifier) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_SnapshotRequestIdentifier.Unmarshal(m, b)
}
func (m *SnapshotRequestIdentifier) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_SnapshotRequestIdentifier.Marshal(b, m, deterministic)
}
func (m *SnapshotRequestIdentifier) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SnapshotRequestIdentifier.Merge(m, src)
}
func (m *SnapshotRequestIdentifier) XXX_Size() int {
	return xxx_messageInfo_SnapshotRequestIdentifier.Size(m)
}
func (m *SnapshotRequestIdentifier) XXX_DiscardUnknown() {
	xxx_messageInfo_SnapshotRequestIdentifier.DiscardUnknown(m)
}

var xxx_messageInfo_SnapshotRequestIdentifier proto.InternalMessageInfo

func (m *SnapshotRequestIdentifier) GetSnapshotId() string {
	if m != nil && m.SnapshotId != nil {
		return *m.SnapshotId
	}
	return ""
}

func (m *SnapshotRequestIdentifier) GetSnapshotPathPrefix() string {
	if m != nil && m.SnapshotPathPrefix != nil {
		return *m.SnapshotPathPrefix
	}
	return ""
}

func (m *SnapshotRequestIdentifier) GetPdName() string {
	if m != nil && m.PdName != nil {
		return *m.PdName
	}
	return ""
}

func (m *SnapshotRequestIdentifier) GetCgName() string {
	if m != nil && m.CgName != nil {
		return *m.CgName
	}
	return ""
}

func (m *SnapshotRequestIdentifier) GetCgId() *ConsistencyGroupIdProto {
	if m != nil {
		return m.CgId
	}
	return nil
}

// Captures generic snapshot information for the snapshots generated by
// Stargate. Can be used by NearSync or Async workflows.
type SnapshotInfo struct {
	// Snapshot ID for the snapshot.
	SnapshotId *SnapshotRequestIdentifier `protobuf:"bytes,1,opt,name=snapshot_id,json=snapshotId" json:"snapshot_id,omitempty"`
	// If we encounter any error while generating this snapshot, the
	// corresponding StargateError status will be captured here.
	ErrorStatus *int32 `protobuf:"varint,2,opt,name=error_status,json=errorStatus" json:"error_status,omitempty"`
	// File info for all the snapshotted files. A non-restorable snapshot
	// will not have any file info associated with it.
	FileInfoVec []*SnapshotInfo_FileInfo `protobuf:"bytes,3,rep,name=file_info_vec,json=fileInfoVec" json:"file_info_vec,omitempty"`
	// If true, indicates that the snapshot is aborted and could not be consumed.
	// It is possible that the snapshot was successful for a subset of files
	// before getting marked as aborted.
	IsAborted            *bool    `protobuf:"varint,4,opt,name=is_aborted,json=isAborted" json:"is_aborted,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *SnapshotInfo) Reset()         { *m = SnapshotInfo{} }
func (m *SnapshotInfo) String() string { return proto.CompactTextString(m) }
func (*SnapshotInfo) ProtoMessage()    {}
func (*SnapshotInfo) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{11}
}

func (m *SnapshotInfo) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_SnapshotInfo.Unmarshal(m, b)
}
func (m *SnapshotInfo) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_SnapshotInfo.Marshal(b, m, deterministic)
}
func (m *SnapshotInfo) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SnapshotInfo.Merge(m, src)
}
func (m *SnapshotInfo) XXX_Size() int {
	return xxx_messageInfo_SnapshotInfo.Size(m)
}
func (m *SnapshotInfo) XXX_DiscardUnknown() {
	xxx_messageInfo_SnapshotInfo.DiscardUnknown(m)
}

var xxx_messageInfo_SnapshotInfo proto.InternalMessageInfo

func (m *SnapshotInfo) GetSnapshotId() *SnapshotRequestIdentifier {
	if m != nil {
		return m.SnapshotId
	}
	return nil
}

func (m *SnapshotInfo) GetErrorStatus() int32 {
	if m != nil && m.ErrorStatus != nil {
		return *m.ErrorStatus
	}
	return 0
}

func (m *SnapshotInfo) GetFileInfoVec() []*SnapshotInfo_FileInfo {
	if m != nil {
		return m.FileInfoVec
	}
	return nil
}

func (m *SnapshotInfo) GetIsAborted() bool {
	if m != nil && m.IsAborted != nil {
		return *m.IsAborted
	}
	return false
}

type SnapshotInfo_FileInfo struct {
	// File that was snapshotted.
	FilePath *string `protobuf:"bytes,1,opt,name=file_path,json=filePath" json:"file_path,omitempty"`
	// The size of the file in bytes.
	FileBytes *int64 `protobuf:"varint,2,opt,name=file_bytes,json=fileBytes" json:"file_bytes,omitempty"`
	// The size of user written bytes for the file.
	UserBytes            *int64   `protobuf:"varint,3,opt,name=user_bytes,json=userBytes" json:"user_bytes,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *SnapshotInfo_FileInfo) Reset()         { *m = SnapshotInfo_FileInfo{} }
func (m *SnapshotInfo_FileInfo) String() string { return proto.CompactTextString(m) }
func (*SnapshotInfo_FileInfo) ProtoMessage()    {}
func (*SnapshotInfo_FileInfo) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{11, 0}
}

func (m *SnapshotInfo_FileInfo) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_SnapshotInfo_FileInfo.Unmarshal(m, b)
}
func (m *SnapshotInfo_FileInfo) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_SnapshotInfo_FileInfo.Marshal(b, m, deterministic)
}
func (m *SnapshotInfo_FileInfo) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SnapshotInfo_FileInfo.Merge(m, src)
}
func (m *SnapshotInfo_FileInfo) XXX_Size() int {
	return xxx_messageInfo_SnapshotInfo_FileInfo.Size(m)
}
func (m *SnapshotInfo_FileInfo) XXX_DiscardUnknown() {
	xxx_messageInfo_SnapshotInfo_FileInfo.DiscardUnknown(m)
}

var xxx_messageInfo_SnapshotInfo_FileInfo proto.InternalMessageInfo

func (m *SnapshotInfo_FileInfo) GetFilePath() string {
	if m != nil && m.FilePath != nil {
		return *m.FilePath
	}
	return ""
}

func (m *SnapshotInfo_FileInfo) GetFileBytes() int64 {
	if m != nil && m.FileBytes != nil {
		return *m.FileBytes
	}
	return 0
}

func (m *SnapshotInfo_FileInfo) GetUserBytes() int64 {
	if m != nil && m.UserBytes != nil {
		return *m.UserBytes
	}
	return 0
}

type MedusaNearSyncConsistencyGroupMapEntryProto struct {
	// The cg incarnation id. This is incremented each time the local cluster's
	// cg controller is hosted.
	CgIncarnationId *int64 `protobuf:"varint,1,opt,name=cg_incarnation_id,json=cgIncarnationId" json:"cg_incarnation_id,omitempty"`
	// If the local cluster is a remote, the last known cg incarnation id of the
	// source cluster.
	SourceCgIncarnationId *int64 `protobuf:"varint,2,opt,name=source_cg_incarnation_id,json=sourceCgIncarnationId,def=-1" json:"source_cg_incarnation_id,omitempty"`
	// List of LWS ids that have been finalized for the consistency group. On the
	// source cluster, a new entry is appended on LWS finalization. On the remote
	// cluster, a new entry is appended when it receives a finalized LWS's
	// metadata record from the source. The remote receives a finalized LWS's
	// metadata record from the source after it has received the corresponding
	// oplog data. The remote cluster's 'finalized_lws_ids' list will always lag
	// behind the source's.
	FinalizedLwsIds []int64 `protobuf:"varint,3,rep,name=finalized_lws_ids,json=finalizedLwsIds" json:"finalized_lws_ids,omitempty"`
	// List of LWSs that are to be deleted. This list is populated at a start of
	// LWS deletion transaction and cleared once all the underlying metadata and
	// data is deleted, thus marking completion of the transaction.
	DeletedLwsIds []int64 `protobuf:"varint,4,rep,name=deleted_lws_ids,json=deletedLwsIds" json:"deleted_lws_ids,omitempty"`
	// Remote replication states for each near sync remote to which we are
	// replicating the cg. We manipulate this at LWS finalization on the
	// source cluster.
	// (1) If a new remote is detected at LWS finalization time and a remote
	//     replicator state doesn't exist, then create a new remote replicator
	//     state and add it to the following list.
	// (2) If a new remote is detected at LWS finalization time and a remote
	//     replicator already exists, then verify that :
	//     - It has unreplicated LWS ids, i.e 'lws_range_start_indices' is non
	//       emtpy.
	//     - The last oplog range in each of the individual file replicator state
	//       is closed.
	// (3) If a remote is detected as removed at LWS finalization time, then
	//     verify that :
	//     - The remote replication state exists.
	//     - Last range in at least 1 per-file replication state is open.
	//     Go over the per-file replication states and close their open ranges.
	RemoteReplicatorStates []*MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState `protobuf:"bytes,5,rep,name=remote_replicator_states,json=remoteReplicatorStates" json:"remote_replicator_states,omitempty"`
	// The segment_ids corresponding to the entries for this cg in
	// NearSyncOplogMap.
	OplogSegmentIds []int64 `protobuf:"varint,6,rep,name=oplog_segment_ids,json=oplogSegmentIds" json:"oplog_segment_ids,omitempty"`
	// List of oplog segment ids that need complete deletion. Following is the
	// transactional mechanism we use for segment deletion:
	// 1. Add a segment id to 'deleted_oplog_segment_ids' list.
	// 2. Delete segment metadata.
	// 3. Remove a segment id from 'deleted_oplog_segment_ids' list.
	DeletedOplogSegmentIds      []int64                                                              `protobuf:"varint,7,rep,name=deleted_oplog_segment_ids,json=deletedOplogSegmentIds" json:"deleted_oplog_segment_ids,omitempty"`
	VdiskOplogTransferStates    []*MedusaNearSyncConsistencyGroupMapEntryProto_OplogTransferState    `protobuf:"bytes,8,rep,name=vdisk_oplog_transfer_states,json=vdiskOplogTransferStates" json:"vdisk_oplog_transfer_states,omitempty"`
	VdiskOplogReplicationStates []*MedusaNearSyncConsistencyGroupMapEntryProto_OplogReplicationState `protobuf:"bytes,9,rep,name=vdisk_oplog_replication_states,json=vdiskOplogReplicationStates" json:"vdisk_oplog_replication_states,omitempty"`
	// Id of the highest replicated LWS.
	HighestReplicatedLwsId *int64 `protobuf:"varint,10,opt,name=highest_replicated_lws_id,json=highestReplicatedLwsId,def=-1" json:"highest_replicated_lws_id,omitempty"`
	// State of the consistency group.
	CgState *ConsistencyGroupState `protobuf:"varint,11,opt,name=cg_state,json=cgState,enum=nutanix.medusa.ConsistencyGroupState,def=0" json:"cg_state,omitempty"`
	// Counter for allocating next batch of ids.
	NextIdCounter *int64 `protobuf:"varint,12,opt,name=next_id_counter,json=nextIdCounter" json:"next_id_counter,omitempty"`
	// Vector of logical operation clocks that corresponds to potentially
	// ongoing operations that last modified this entry.
	Locs []*zeus.LogicalOperationClock `protobuf:"bytes,13,rep,name=locs" json:"locs,omitempty"`
	// Index used to persist progress of segments prune operation.
	NextSegmentScanIndex *int32 `protobuf:"varint,14,opt,name=next_segment_scan_index,json=nextSegmentScanIndex,def=0" json:"next_segment_scan_index,omitempty"`
	// Control information to drive autonomous snapshot schedules.
	ConsistencyGroupConfig      *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig        `protobuf:"bytes,15,opt,name=consistency_group_config,json=consistencyGroupConfig" json:"consistency_group_config,omitempty"`
	ControlPlaneSnapshotMapping []*MedusaNearSyncConsistencyGroupMapEntryProto_ControlPlaneSnapshotMapping `protobuf:"bytes,16,rep,name=control_plane_snapshot_mapping,json=controlPlaneSnapshotMapping" json:"control_plane_snapshot_mapping,omitempty"`
	// Container mapping for all remotes.
	RemoteCtrMappingVec []*MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping `protobuf:"bytes,17,rep,name=remote_ctr_mapping_vec,json=remoteCtrMappingVec" json:"remote_ctr_mapping_vec,omitempty"`
	// Last processed pithos logical timestamp of the nearsync params entry.
	NearsyncParamsTimestamp *int64 `protobuf:"varint,18,opt,name=nearsync_params_timestamp,json=nearsyncParamsTimestamp,def=-1" json:"nearsync_params_timestamp,omitempty"`
	// Highest LWS id for which CG metadata was updated. With autonomous nearsync
	// one or more finalized LWSs might not have been processed for CG metadata
	// update. This field is updated each time CG metadata is updated for an LWS.
	HighestCgUpdatedLwsId *int64 `protobuf:"varint,19,opt,name=highest_cg_updated_lws_id,json=highestCgUpdatedLwsId,def=-1" json:"highest_cg_updated_lws_id,omitempty"`
	// The type of oplog used by vdisks that are protected by the CG. This is
	// used to determine whether the CG must interface with legacy vdisk oplog to
	// manage oplog episode metadata containing the physical location of episodes
	// in oplog and LWS stores or whether the CG can use distributed oplog to
	// take care of this.
	OplogType            *MedusaNearSyncConsistencyGroupMapEntryProto_CGOplogType         `protobuf:"varint,20,opt,name=oplog_type,json=oplogType,enum=nutanix.medusa.MedusaNearSyncConsistencyGroupMapEntryProto_CGOplogType,def=0" json:"oplog_type,omitempty"`
	OplogRegistrations   []*MedusaNearSyncConsistencyGroupMapEntryProto_OplogRegistration `protobuf:"bytes,21,rep,name=oplog_registrations,json=oplogRegistrations" json:"oplog_registrations,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                                                         `json:"-"`
	XXX_unrecognized     []byte                                                           `json:"-"`
	XXX_sizecache        int32                                                            `json:"-"`
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto) Reset() {
	*m = MedusaNearSyncConsistencyGroupMapEntryProto{}
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaNearSyncConsistencyGroupMapEntryProto) ProtoMessage() {}
func (*MedusaNearSyncConsistencyGroupMapEntryProto) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{12}
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto.Unmarshal(m, b)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto.Marshal(b, m, deterministic)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto.Merge(m, src)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto) XXX_Size() int {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto.Size(m)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto proto.InternalMessageInfo

const Default_MedusaNearSyncConsistencyGroupMapEntryProto_SourceCgIncarnationId int64 = -1
const Default_MedusaNearSyncConsistencyGroupMapEntryProto_HighestReplicatedLwsId int64 = -1
const Default_MedusaNearSyncConsistencyGroupMapEntryProto_CgState ConsistencyGroupState = ConsistencyGroupState_kActive
const Default_MedusaNearSyncConsistencyGroupMapEntryProto_NextSegmentScanIndex int32 = 0
const Default_MedusaNearSyncConsistencyGroupMapEntryProto_NearsyncParamsTimestamp int64 = -1
const Default_MedusaNearSyncConsistencyGroupMapEntryProto_HighestCgUpdatedLwsId int64 = -1
const Default_MedusaNearSyncConsistencyGroupMapEntryProto_OplogType MedusaNearSyncConsistencyGroupMapEntryProto_CGOplogType = MedusaNearSyncConsistencyGroupMapEntryProto_kVDiskOplog

func (m *MedusaNearSyncConsistencyGroupMapEntryProto) GetCgIncarnationId() int64 {
	if m != nil && m.CgIncarnationId != nil {
		return *m.CgIncarnationId
	}
	return 0
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto) GetSourceCgIncarnationId() int64 {
	if m != nil && m.SourceCgIncarnationId != nil {
		return *m.SourceCgIncarnationId
	}
	return Default_MedusaNearSyncConsistencyGroupMapEntryProto_SourceCgIncarnationId
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto) GetFinalizedLwsIds() []int64 {
	if m != nil {
		return m.FinalizedLwsIds
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto) GetDeletedLwsIds() []int64 {
	if m != nil {
		return m.DeletedLwsIds
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto) GetRemoteReplicatorStates() []*MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState {
	if m != nil {
		return m.RemoteReplicatorStates
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto) GetOplogSegmentIds() []int64 {
	if m != nil {
		return m.OplogSegmentIds
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto) GetDeletedOplogSegmentIds() []int64 {
	if m != nil {
		return m.DeletedOplogSegmentIds
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto) GetVdiskOplogTransferStates() []*MedusaNearSyncConsistencyGroupMapEntryProto_OplogTransferState {
	if m != nil {
		return m.VdiskOplogTransferStates
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto) GetVdiskOplogReplicationStates() []*MedusaNearSyncConsistencyGroupMapEntryProto_OplogReplicationState {
	if m != nil {
		return m.VdiskOplogReplicationStates
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto) GetHighestReplicatedLwsId() int64 {
	if m != nil && m.HighestReplicatedLwsId != nil {
		return *m.HighestReplicatedLwsId
	}
	return Default_MedusaNearSyncConsistencyGroupMapEntryProto_HighestReplicatedLwsId
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto) GetCgState() ConsistencyGroupState {
	if m != nil && m.CgState != nil {
		return *m.CgState
	}
	return Default_MedusaNearSyncConsistencyGroupMapEntryProto_CgState
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto) GetNextIdCounter() int64 {
	if m != nil && m.NextIdCounter != nil {
		return *m.NextIdCounter
	}
	return 0
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto) GetLocs() []*zeus.LogicalOperationClock {
	if m != nil {
		return m.Locs
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto) GetNextSegmentScanIndex() int32 {
	if m != nil && m.NextSegmentScanIndex != nil {
		return *m.NextSegmentScanIndex
	}
	return Default_MedusaNearSyncConsistencyGroupMapEntryProto_NextSegmentScanIndex
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto) GetConsistencyGroupConfig() *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig {
	if m != nil {
		return m.ConsistencyGroupConfig
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto) GetControlPlaneSnapshotMapping() []*MedusaNearSyncConsistencyGroupMapEntryProto_ControlPlaneSnapshotMapping {
	if m != nil {
		return m.ControlPlaneSnapshotMapping
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto) GetRemoteCtrMappingVec() []*MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping {
	if m != nil {
		return m.RemoteCtrMappingVec
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto) GetNearsyncParamsTimestamp() int64 {
	if m != nil && m.NearsyncParamsTimestamp != nil {
		return *m.NearsyncParamsTimestamp
	}
	return Default_MedusaNearSyncConsistencyGroupMapEntryProto_NearsyncParamsTimestamp
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto) GetHighestCgUpdatedLwsId() int64 {
	if m != nil && m.HighestCgUpdatedLwsId != nil {
		return *m.HighestCgUpdatedLwsId
	}
	return Default_MedusaNearSyncConsistencyGroupMapEntryProto_HighestCgUpdatedLwsId
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto) GetOplogType() MedusaNearSyncConsistencyGroupMapEntryProto_CGOplogType {
	if m != nil && m.OplogType != nil {
		return *m.OplogType
	}
	return Default_MedusaNearSyncConsistencyGroupMapEntryProto_OplogType
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto) GetOplogRegistrations() []*MedusaNearSyncConsistencyGroupMapEntryProto_OplogRegistration {
	if m != nil {
		return m.OplogRegistrations
	}
	return nil
}

// Per remote data replication state. This state is kept only on the source
// cluster.
type MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState struct {
	// The Uuid of the remote site.
	RemoteSiteUuid []byte `protobuf:"bytes,1,opt,name=remote_site_uuid,json=remoteSiteUuid" json:"remote_site_uuid,omitempty"`
	// File replication states to the remote for each file in the cg. We
	// manipulate this at LWS finalization on the source cluster.
	// (1) If a new file is detected at LWS finalization time and a file
	//     replicator state doesn't exist, then create a new file replicator
	//     state and add it to the following list.
	// (2) If a new file is detected at LWS finalization time and a file
	//     replicator already exists, then verify that the last oplog range is
	//     closed.
	// (3) If a file is detected as removed at LWS finalization time, then
	//     verify that the file replication state exists, and it's last oplog
	//     timestamp range is open. Close the last oplog timestamp range.
	//     This file state will be removed from 'file_replicator_states' once
	//     all oplog data is replicated.
	FileReplicationStates []*MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState `protobuf:"bytes,2,rep,name=file_replication_states,json=fileReplicationStates" json:"file_replication_states,omitempty"`
	// A remote may only be a target for a subset of the LWS'es finalized for
	// the cg. The following 2 fields specify LWS ranges to be replicated to
	// the remote.
	// Indices in 'finalized_lws_ids' that correspond to the first LWS id for
	// the ranges.
	LwsRangeStartIndices []int32 `protobuf:"varint,3,rep,name=lws_range_start_indices,json=lwsRangeStartIndices" json:"lws_range_start_indices,omitempty"`
	// Indices in 'finalized_lws_ids' that correspond to the last LWS id for
	// the ranges. Index value of '-1' indicates an open range.
	LwsRangeEndIndices []int32 `protobuf:"varint,4,rep,name=lws_range_end_indices,json=lwsRangeEndIndices" json:"lws_range_end_indices,omitempty"`
	// Current replication status.
	ReplicationState *ReplicationState `protobuf:"varint,5,opt,name=replication_state,json=replicationState,enum=nutanix.medusa.ReplicationState,def=0" json:"replication_state,omitempty"`
	// Total oplog bytes replicated for all files in this nearsync session for
	// this remote. This is needed to publish LWS replication stats to cerebro.
	TotalReplicatedBytes *int64 `protobuf:"varint,6,opt,name=total_replicated_bytes,json=totalReplicatedBytes" json:"total_replicated_bytes,omitempty"`
	// The last known version of the remote site. This is used to ensure that
	// the last known state of the remote site is still valid. If the version
	// is different in the pithos nearsync params, we assume that the remote
	// got removed and added back and clean up all the replication state.
	RemoteVersion        *ConsistencyGroupIdProto `protobuf:"bytes,7,opt,name=remote_version,json=remoteVersion" json:"remote_version,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                 `json:"-"`
	XXX_unrecognized     []byte                   `json:"-"`
	XXX_sizecache        int32                    `json:"-"`
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState) Reset() {
	*m = MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState{}
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState) ProtoMessage() {}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{12, 0}
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState.Unmarshal(m, b)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState.Marshal(b, m, deterministic)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState.Merge(m, src)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState) XXX_Size() int {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState.Size(m)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState proto.InternalMessageInfo

const Default_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_ReplicationState ReplicationState = ReplicationState_kInProgress

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState) GetRemoteSiteUuid() []byte {
	if m != nil {
		return m.RemoteSiteUuid
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState) GetFileReplicationStates() []*MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState {
	if m != nil {
		return m.FileReplicationStates
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState) GetLwsRangeStartIndices() []int32 {
	if m != nil {
		return m.LwsRangeStartIndices
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState) GetLwsRangeEndIndices() []int32 {
	if m != nil {
		return m.LwsRangeEndIndices
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState) GetReplicationState() ReplicationState {
	if m != nil && m.ReplicationState != nil {
		return *m.ReplicationState
	}
	return Default_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_ReplicationState
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState) GetTotalReplicatedBytes() int64 {
	if m != nil && m.TotalReplicatedBytes != nil {
		return *m.TotalReplicatedBytes
	}
	return 0
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState) GetRemoteVersion() *ConsistencyGroupIdProto {
	if m != nil {
		return m.RemoteVersion
	}
	return nil
}

// The per file replication state to the remote.
type MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState struct {
	// The vdisk name associated with the file.
	VdiskName *string `protobuf:"bytes,1,opt,name=vdisk_name,json=vdiskName" json:"vdisk_name,omitempty"`
	// The current leaf vdisk id associated with the file.
	VdiskId *int64 `protobuf:"varint,2,opt,name=vdisk_id,json=vdiskId" json:"vdisk_id,omitempty"`
	// The ranges in the file's oplog that needs replication to the remote.
	// A timestamp is considered replicated once the corresponding record has
	// been replicated to the remote lws store, and the timestamp is
	// available for lookup in the remote's oplog map.
	// The start oplog global timestamps for the ranges. The first entry
	// corresponds to the first unreplicted oplog timestamp to the remote.
	// The replicator updates this as replication progresses, and removes the
	// range once all timestamps up to the corresponding value in
	// 'end_oplog_global_timestamp' has been replicated.
	StartOplogGlobalTimestamps []int64 `protobuf:"varint,3,rep,name=start_oplog_global_timestamps,json=startOplogGlobalTimestamps" json:"start_oplog_global_timestamps,omitempty"`
	// The corresponding end oplog global timestamps for the ranges. All
	// entries except the last one must have values that are greater than or
	// equal to the corresponding entry in 'start_oplog_global_timestamps'.
	// The last entry may have a value of -1, to imply an open range.
	EndOplogGlobalTimestamps []int64 `protobuf:"varint,4,rep,name=end_oplog_global_timestamps,json=endOplogGlobalTimestamps" json:"end_oplog_global_timestamps,omitempty"`
	// The byte position in the oplog stream for the first byte of the
	// corresponding timestamp in 'start_oplog_global_timestamps'.
	StartOplogGlobalBytes []int64 `protobuf:"varint,5,rep,name=start_oplog_global_bytes,json=startOplogGlobalBytes" json:"start_oplog_global_bytes,omitempty"`
	// The byte position in the oplog stream for the last byte of the
	// corresponding timestamp in 'end_oplog_global_timestamps'. The last
	// entry may have a value of -1, if the corresponding last entry in
	// 'end_oplog_global_timestamps' has a value of -1.
	EndOplogGlobalBytes []int64 `protobuf:"varint,6,rep,name=end_oplog_global_bytes,json=endOplogGlobalBytes" json:"end_oplog_global_bytes,omitempty"`
	// First LWS for the replication session.
	ReplicationSessionLwsIds []int64 `protobuf:"varint,7,rep,name=replication_session_lws_ids,json=replicationSessionLwsIds" json:"replication_session_lws_ids,omitempty"`
	// Timestamp corresponding to the latest oplog record that has been
	// replicated to the remote's lws store.
	HighestReplicatedDataTimestamp *int64 `protobuf:"varint,8,opt,name=highest_replicated_data_timestamp,json=highestReplicatedDataTimestamp,def=-1" json:"highest_replicated_data_timestamp,omitempty"`
	// The byte position in the oplog stream for the last byte of the record
	// corresponding to 'highest_replicated_data_timestamp'.
	HighestReplicatedByte *int64 `protobuf:"varint,9,opt,name=highest_replicated_byte,json=highestReplicatedByte,def=-1" json:"highest_replicated_byte,omitempty"`
	// Episode sequence on the remote's lws store to which the latest oplog
	// record has been replicated.
	RemoteEpisodeSequence *int64 `protobuf:"varint,10,opt,name=remote_episode_sequence,json=remoteEpisodeSequence,def=-1" json:"remote_episode_sequence,omitempty"`
	// Episode file sizes (per file type) on the remote's lws store after the
	// latest oplog record has been replicated.
	RemoteEpisodeFileSizes []int64 `protobuf:"varint,11,rep,name=remote_episode_file_sizes,json=remoteEpisodeFileSizes" json:"remote_episode_file_sizes,omitempty"`
	// Source container id to which the file belongs.
	ContainerId          *int64   `protobuf:"varint,12,opt,name=container_id,json=containerId,def=-1" json:"container_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState) Reset() {
	*m = MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState{}
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState) ProtoMessage() {
}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{12, 0, 0}
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState.Unmarshal(m, b)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState.Marshal(b, m, deterministic)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState.Merge(m, src)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState) XXX_Size() int {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState.Size(m)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState proto.InternalMessageInfo

const Default_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState_HighestReplicatedDataTimestamp int64 = -1
const Default_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState_HighestReplicatedByte int64 = -1
const Default_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState_RemoteEpisodeSequence int64 = -1
const Default_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState_ContainerId int64 = -1

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState) GetVdiskName() string {
	if m != nil && m.VdiskName != nil {
		return *m.VdiskName
	}
	return ""
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState) GetVdiskId() int64 {
	if m != nil && m.VdiskId != nil {
		return *m.VdiskId
	}
	return 0
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState) GetStartOplogGlobalTimestamps() []int64 {
	if m != nil {
		return m.StartOplogGlobalTimestamps
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState) GetEndOplogGlobalTimestamps() []int64 {
	if m != nil {
		return m.EndOplogGlobalTimestamps
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState) GetStartOplogGlobalBytes() []int64 {
	if m != nil {
		return m.StartOplogGlobalBytes
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState) GetEndOplogGlobalBytes() []int64 {
	if m != nil {
		return m.EndOplogGlobalBytes
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState) GetReplicationSessionLwsIds() []int64 {
	if m != nil {
		return m.ReplicationSessionLwsIds
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState) GetHighestReplicatedDataTimestamp() int64 {
	if m != nil && m.HighestReplicatedDataTimestamp != nil {
		return *m.HighestReplicatedDataTimestamp
	}
	return Default_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState_HighestReplicatedDataTimestamp
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState) GetHighestReplicatedByte() int64 {
	if m != nil && m.HighestReplicatedByte != nil {
		return *m.HighestReplicatedByte
	}
	return Default_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState_HighestReplicatedByte
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState) GetRemoteEpisodeSequence() int64 {
	if m != nil && m.RemoteEpisodeSequence != nil {
		return *m.RemoteEpisodeSequence
	}
	return Default_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState_RemoteEpisodeSequence
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState) GetRemoteEpisodeFileSizes() []int64 {
	if m != nil {
		return m.RemoteEpisodeFileSizes
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState) GetContainerId() int64 {
	if m != nil && m.ContainerId != nil {
		return *m.ContainerId
	}
	return Default_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState_ContainerId
}

type MedusaNearSyncConsistencyGroupMapEntryProto_OplogTransferState struct {
	// Name of the VDisk for which LWS's are captured.
	VdiskName *string `protobuf:"bytes,1,opt,name=vdisk_name,json=vdiskName" json:"vdisk_name,omitempty"`
	// Start of the range of global timestamps to be transferred.
	StartOplogGlobalTimestamp *int64 `protobuf:"varint,2,opt,name=start_oplog_global_timestamp,json=startOplogGlobalTimestamp" json:"start_oplog_global_timestamp,omitempty"`
	// End of the range of global timestamps to be transferred.
	// Contains the value of end_timestamp from the last LWS finalized with
	// this vdisk.
	EndOplogGlobalTimestamp *int64 `protobuf:"varint,3,opt,name=end_oplog_global_timestamp,json=endOplogGlobalTimestamp" json:"end_oplog_global_timestamp,omitempty"`
	// Whether the range is closed.
	IsClosed             *bool    `protobuf:"varint,4,opt,name=is_closed,json=isClosed,def=0" json:"is_closed,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogTransferState) Reset() {
	*m = MedusaNearSyncConsistencyGroupMapEntryProto_OplogTransferState{}
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogTransferState) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_OplogTransferState) ProtoMessage() {}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_OplogTransferState) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{12, 1}
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogTransferState) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_OplogTransferState.Unmarshal(m, b)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogTransferState) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_OplogTransferState.Marshal(b, m, deterministic)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogTransferState) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_OplogTransferState.Merge(m, src)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogTransferState) XXX_Size() int {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_OplogTransferState.Size(m)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogTransferState) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_OplogTransferState.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_OplogTransferState proto.InternalMessageInfo

const Default_MedusaNearSyncConsistencyGroupMapEntryProto_OplogTransferState_IsClosed bool = false

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogTransferState) GetVdiskName() string {
	if m != nil && m.VdiskName != nil {
		return *m.VdiskName
	}
	return ""
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogTransferState) GetStartOplogGlobalTimestamp() int64 {
	if m != nil && m.StartOplogGlobalTimestamp != nil {
		return *m.StartOplogGlobalTimestamp
	}
	return 0
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogTransferState) GetEndOplogGlobalTimestamp() int64 {
	if m != nil && m.EndOplogGlobalTimestamp != nil {
		return *m.EndOplogGlobalTimestamp
	}
	return 0
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogTransferState) GetIsClosed() bool {
	if m != nil && m.IsClosed != nil {
		return *m.IsClosed
	}
	return Default_MedusaNearSyncConsistencyGroupMapEntryProto_OplogTransferState_IsClosed
}

// This field is only applicable on remote_site (site that receives LWS
// replication). This is populated for vdisks that are getting actively
// replicated.
type MedusaNearSyncConsistencyGroupMapEntryProto_OplogReplicationState struct {
	// Name of the vdisk for which ranges are being replicated.
	VdiskName *string `protobuf:"bytes,1,opt,name=vdisk_name,json=vdiskName" json:"vdisk_name,omitempty"`
	// Highest global timestamp that is referred by any LWS.
	HighestReplicatedLwsTimestamp *int64   `protobuf:"varint,2,opt,name=highest_replicated_lws_timestamp,json=highestReplicatedLwsTimestamp" json:"highest_replicated_lws_timestamp,omitempty"`
	XXX_NoUnkeyedLiteral          struct{} `json:"-"`
	XXX_unrecognized              []byte   `json:"-"`
	XXX_sizecache                 int32    `json:"-"`
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogReplicationState) Reset() {
	*m = MedusaNearSyncConsistencyGroupMapEntryProto_OplogReplicationState{}
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogReplicationState) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_OplogReplicationState) ProtoMessage() {}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_OplogReplicationState) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{12, 2}
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogReplicationState) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_OplogReplicationState.Unmarshal(m, b)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogReplicationState) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_OplogReplicationState.Marshal(b, m, deterministic)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogReplicationState) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_OplogReplicationState.Merge(m, src)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogReplicationState) XXX_Size() int {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_OplogReplicationState.Size(m)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogReplicationState) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_OplogReplicationState.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_OplogReplicationState proto.InternalMessageInfo

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogReplicationState) GetVdiskName() string {
	if m != nil && m.VdiskName != nil {
		return *m.VdiskName
	}
	return ""
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogReplicationState) GetHighestReplicatedLwsTimestamp() int64 {
	if m != nil && m.HighestReplicatedLwsTimestamp != nil {
		return *m.HighestReplicatedLwsTimestamp
	}
	return 0
}

// Configuration of a CG. Includes all control information necessary to drive
// autonomous snapshot schedules.
type MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig struct {
	// List of file paths comprising the CG.
	FilePaths []string `protobuf:"bytes,1,rep,name=file_paths,json=filePaths" json:"file_paths,omitempty"`
	// List of validation files among file_paths.
	ValidationFileInfo []*MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_ValidationFileInfo `protobuf:"bytes,2,rep,name=validation_file_info,json=validationFileInfo" json:"validation_file_info,omitempty"`
	// Autonomous mode of this CG.
	AutonomousMode *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_AutonomousMode `protobuf:"varint,3,opt,name=autonomous_mode,json=autonomousMode,enum=nutanix.medusa.MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_AutonomousMode,def=0" json:"autonomous_mode,omitempty"`
	// List of remote sites to replicate to.
	RemoteSiteUuids [][]byte `protobuf:"bytes,4,rep,name=remote_site_uuids,json=remoteSiteUuids" json:"remote_site_uuids,omitempty"`
	// Snapshot interval in seconds.
	SnapshotIntervalSecs *int32 `protobuf:"varint,5,opt,name=snapshot_interval_secs,json=snapshotIntervalSecs" json:"snapshot_interval_secs,omitempty"`
	// Retention period in secs.
	RetentionPeriodSecs *int32 `protobuf:"varint,6,opt,name=retention_period_secs,json=retentionPeriodSecs" json:"retention_period_secs,omitempty"`
	// The state maintained for on-going inline hydration or on-demand
	// hydration(s). Used by target for both inline hydration or on-demand
	// hydration(s). Used by source for on-demand hydration(s) only.
	HydrationStates []*MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState `protobuf:"bytes,7,rep,name=hydration_states,json=hydrationStates" json:"hydration_states,omitempty"`
	// Whether to silently skip nonexistent source files or not.
	SkipNonexistentSources *bool `protobuf:"varint,8,opt,name=skip_nonexistent_sources,json=skipNonexistentSources" json:"skip_nonexistent_sources,omitempty"`
	// List of LWS ids corresponding to the full snapshots that have been
	// finalized for the consistency group. On the remote cluster, a new entry
	// is appended when it receives a finalized full LWS's metadata from the
	// source.
	FullSnapshotLwsIds   []int64  `protobuf:"varint,9,rep,name=full_snapshot_lws_ids,json=fullSnapshotLwsIds" json:"full_snapshot_lws_ids,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig) Reset() {
	*m = MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig{}
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig) ProtoMessage() {}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{12, 3}
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig.Unmarshal(m, b)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig.Marshal(b, m, deterministic)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig.Merge(m, src)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig) XXX_Size() int {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig.Size(m)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig proto.InternalMessageInfo

const Default_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_AutonomousMode MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_AutonomousMode = MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_kDisabled

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig) GetFilePaths() []string {
	if m != nil {
		return m.FilePaths
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig) GetValidationFileInfo() []*MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_ValidationFileInfo {
	if m != nil {
		return m.ValidationFileInfo
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig) GetAutonomousMode() MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_AutonomousMode {
	if m != nil && m.AutonomousMode != nil {
		return *m.AutonomousMode
	}
	return Default_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_AutonomousMode
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig) GetRemoteSiteUuids() [][]byte {
	if m != nil {
		return m.RemoteSiteUuids
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig) GetSnapshotIntervalSecs() int32 {
	if m != nil && m.SnapshotIntervalSecs != nil {
		return *m.SnapshotIntervalSecs
	}
	return 0
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig) GetRetentionPeriodSecs() int32 {
	if m != nil && m.RetentionPeriodSecs != nil {
		return *m.RetentionPeriodSecs
	}
	return 0
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig) GetHydrationStates() []*MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState {
	if m != nil {
		return m.HydrationStates
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig) GetSkipNonexistentSources() bool {
	if m != nil && m.SkipNonexistentSources != nil {
		return *m.SkipNonexistentSources
	}
	return false
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig) GetFullSnapshotLwsIds() []int64 {
	if m != nil {
		return m.FullSnapshotLwsIds
	}
	return nil
}

type MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_ValidationFileInfo struct {
	// Index to file_paths indicating the validation file.
	ValidationIndex *int64 `protobuf:"varint,1,opt,name=validation_index,json=validationIndex" json:"validation_index,omitempty"`
	// Epoch when the validation file was last modified.
	ValidationEpoch *int64 `protobuf:"varint,2,opt,name=validation_epoch,json=validationEpoch" json:"validation_epoch,omitempty"`
	// Timestamp when the validation file was last modified.
	ValidationTimestamp  *int64   `protobuf:"varint,3,opt,name=validation_timestamp,json=validationTimestamp" json:"validation_timestamp,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_ValidationFileInfo) Reset() {
	*m = MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_ValidationFileInfo{}
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_ValidationFileInfo) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_ValidationFileInfo) ProtoMessage() {
}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_ValidationFileInfo) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{12, 3, 0}
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_ValidationFileInfo) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_ValidationFileInfo.Unmarshal(m, b)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_ValidationFileInfo) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_ValidationFileInfo.Marshal(b, m, deterministic)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_ValidationFileInfo) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_ValidationFileInfo.Merge(m, src)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_ValidationFileInfo) XXX_Size() int {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_ValidationFileInfo.Size(m)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_ValidationFileInfo) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_ValidationFileInfo.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_ValidationFileInfo proto.InternalMessageInfo

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_ValidationFileInfo) GetValidationIndex() int64 {
	if m != nil && m.ValidationIndex != nil {
		return *m.ValidationIndex
	}
	return 0
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_ValidationFileInfo) GetValidationEpoch() int64 {
	if m != nil && m.ValidationEpoch != nil {
		return *m.ValidationEpoch
	}
	return 0
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_ValidationFileInfo) GetValidationTimestamp() int64 {
	if m != nil && m.ValidationTimestamp != nil {
		return *m.ValidationTimestamp
	}
	return 0
}

type MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState struct {
	// Path prefix of temporary staging area used for inline/on-demand
	// hydration.
	StagingAreaPrefix *string `protobuf:"bytes,1,opt,name=staging_area_prefix,json=stagingAreaPrefix" json:"staging_area_prefix,omitempty"`
	// The LWS id from which we need to start applying in the given staging
	// area. For inline hydration, this will be the first LWS received by
	// target after transitioning into nearsync. For on-demand hydration,
	// this will be set to the most recent recoverable full LWS preceding
	// 'target_lws_id'.
	StartLwsId *int64 `protobuf:"varint,2,opt,name=start_lws_id,json=startLwsId" json:"start_lws_id,omitempty"`
	// The LWS id upto which we need to hydrate. This will be set to '-1' for
	// autonomous inline hydration.
	TargetLwsId *int64 `protobuf:"varint,3,opt,name=target_lws_id,json=targetLwsId,def=-1" json:"target_lws_id,omitempty"`
	// Used only for on-demand hydration. This is the final directory where
	// we need to generate a restorable snapshot after on-demand hydration.
	OndemandTargetDirPrefix *string `protobuf:"bytes,4,opt,name=ondemand_target_dir_prefix,json=ondemandTargetDirPrefix" json:"ondemand_target_dir_prefix,omitempty"`
	// If the hydration work is aborted due to some reason, this field will
	// contain the error status.
	ErrorStatus *int32 `protobuf:"varint,5,opt,name=error_status,json=errorStatus" json:"error_status,omitempty"`
	// If the staging area was snapshotted, then the following field will
	// contain the information about the snapshot. This information is
	// maintained here until Cerebro consumes it to construct the
	// corresponding snapshot object. Inline hydration can have mutiple
	// of these corresponding to the full snapshots on remote. Whereas,
	// on-demand hydration will populate this only for the final restorable
	// snapshot.
	SnapshotInfoVec []*SnapshotInfo `protobuf:"bytes,6,rep,name=snapshot_info_vec,json=snapshotInfoVec" json:"snapshot_info_vec,omitempty"`
	// Snapshot state corresponding to the snapshots in 'snapshot_info_vec'.
	SnapshotStateVec []*MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotStateInfo `protobuf:"bytes,7,rep,name=snapshot_state_vec,json=snapshotStateVec" json:"snapshot_state_vec,omitempty"`
	// Snapshot seeding state corresponding to the snapshots in
	// 'snapshot_info_vec'.
	SnapshotSeedingInfoVec []*MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotSeedingInfo `protobuf:"bytes,8,rep,name=snapshot_seeding_info_vec,json=snapshotSeedingInfoVec" json:"snapshot_seeding_info_vec,omitempty"`
	XXX_NoUnkeyedLiteral   struct{}                                                                                                 `json:"-"`
	XXX_unrecognized       []byte                                                                                                   `json:"-"`
	XXX_sizecache          int32                                                                                                    `json:"-"`
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState) Reset() {
	*m = MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState{}
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState) ProtoMessage() {
}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{12, 3, 1}
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState.Unmarshal(m, b)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState.Marshal(b, m, deterministic)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState.Merge(m, src)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState) XXX_Size() int {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState.Size(m)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState proto.InternalMessageInfo

const Default_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_TargetLwsId int64 = -1

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState) GetStagingAreaPrefix() string {
	if m != nil && m.StagingAreaPrefix != nil {
		return *m.StagingAreaPrefix
	}
	return ""
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState) GetStartLwsId() int64 {
	if m != nil && m.StartLwsId != nil {
		return *m.StartLwsId
	}
	return 0
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState) GetTargetLwsId() int64 {
	if m != nil && m.TargetLwsId != nil {
		return *m.TargetLwsId
	}
	return Default_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_TargetLwsId
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState) GetOndemandTargetDirPrefix() string {
	if m != nil && m.OndemandTargetDirPrefix != nil {
		return *m.OndemandTargetDirPrefix
	}
	return ""
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState) GetErrorStatus() int32 {
	if m != nil && m.ErrorStatus != nil {
		return *m.ErrorStatus
	}
	return 0
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState) GetSnapshotInfoVec() []*SnapshotInfo {
	if m != nil {
		return m.SnapshotInfoVec
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState) GetSnapshotStateVec() []*MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotStateInfo {
	if m != nil {
		return m.SnapshotStateVec
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState) GetSnapshotSeedingInfoVec() []*MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotSeedingInfo {
	if m != nil {
		return m.SnapshotSeedingInfoVec
	}
	return nil
}

type MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotStateInfo struct {
	SnapshotState *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState `protobuf:"varint,1,opt,name=snapshot_state,json=snapshotState,enum=nutanix.medusa.MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState,def=0" json:"snapshot_state,omitempty"`
	// List of the ancestor vdisk ids which are still seeding. This field
	// will be populated only when the snapshot is in kSeeding/kNeedsFixing
	// states.
	AncestorVdiskIds []int64 `protobuf:"varint,2,rep,name=ancestor_vdisk_ids,json=ancestorVdiskIds" json:"ancestor_vdisk_ids,omitempty"`
	// List of the child vdisk ids whose attributes need to be fixed once
	// their corresponding ancestors in the 'ancestor_vdisk_ids' list have
	// finished seeding. This field will be populated only when the
	// snapshot is in kSeeding/kNeedsFixing states.
	ChildVdiskIds        []int64  `protobuf:"varint,3,rep,name=child_vdisk_ids,json=childVdiskIds" json:"child_vdisk_ids,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotStateInfo) Reset() {
	*m = MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotStateInfo{}
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotStateInfo) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotStateInfo) ProtoMessage() {
}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotStateInfo) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{12, 3, 1, 0}
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotStateInfo) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotStateInfo.Unmarshal(m, b)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotStateInfo) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotStateInfo.Marshal(b, m, deterministic)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotStateInfo) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotStateInfo.Merge(m, src)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotStateInfo) XXX_Size() int {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotStateInfo.Size(m)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotStateInfo) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotStateInfo.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotStateInfo proto.InternalMessageInfo

const Default_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotStateInfo_SnapshotState MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState = MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_kReady

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotStateInfo) GetSnapshotState() MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState {
	if m != nil && m.SnapshotState != nil {
		return *m.SnapshotState
	}
	return Default_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotStateInfo_SnapshotState
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotStateInfo) GetAncestorVdiskIds() []int64 {
	if m != nil {
		return m.AncestorVdiskIds
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotStateInfo) GetChildVdiskIds() []int64 {
	if m != nil {
		return m.ChildVdiskIds
	}
	return nil
}

type MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotSeedingInfo struct {
	SeedingStatus *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState `protobuf:"varint,1,opt,name=seeding_status,json=seedingStatus,enum=nutanix.medusa.MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState,def=0" json:"seeding_status,omitempty"`
	// List of vdisk ids which are still seeding. This field will be
	// populated only when the snapshot is in kSeeding/kNeedsFixing states.
	SeedingVdiskIds []int64 `protobuf:"varint,2,rep,name=seeding_vdisk_ids,json=seedingVdiskIds" json:"seeding_vdisk_ids,omitempty"`
	// List of dependent vdisk ids whose attributes need to be fixed once
	// their corresponding seeding vdisks in the 'seeding_vdisk_ids'
	// list are complete. This field will be populated only when the
	// snapshot is in kSeeding/kNeedsFixing states. The entries in
	// this field have 1:1 mapping with entries in 'seeding_vdisk_ids'
	// field.
	DependentVdiskIds    []int64  `protobuf:"varint,3,rep,name=dependent_vdisk_ids,json=dependentVdiskIds" json:"dependent_vdisk_ids,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotSeedingInfo) Reset() {
	*m = MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotSeedingInfo{}
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotSeedingInfo) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotSeedingInfo) ProtoMessage() {
}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotSeedingInfo) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{12, 3, 1, 1}
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotSeedingInfo) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotSeedingInfo.Unmarshal(m, b)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotSeedingInfo) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotSeedingInfo.Marshal(b, m, deterministic)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotSeedingInfo) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotSeedingInfo.Merge(m, src)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotSeedingInfo) XXX_Size() int {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotSeedingInfo.Size(m)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotSeedingInfo) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotSeedingInfo.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotSeedingInfo proto.InternalMessageInfo

const Default_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotSeedingInfo_SeedingStatus MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState = MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_kReady

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotSeedingInfo) GetSeedingStatus() MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState {
	if m != nil && m.SeedingStatus != nil {
		return *m.SeedingStatus
	}
	return Default_MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotSeedingInfo_SeedingStatus
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotSeedingInfo) GetSeedingVdiskIds() []int64 {
	if m != nil {
		return m.SeedingVdiskIds
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotSeedingInfo) GetDependentVdiskIds() []int64 {
	if m != nil {
		return m.DependentVdiskIds
	}
	return nil
}

// Mapping from a control plane snapshot to an LWS. Maintained only at the
// source. When autonomous mode is enabled, cerebro will communicate with
// stargate using LCS uuids instead of LWS ids, since LWSs are now internal
// to stargate. This mapping will also be used by cerebro triggered
// snapshots to identify and recover from various VDisk snapshot leakage
// scenarios.
type MedusaNearSyncConsistencyGroupMapEntryProto_ControlPlaneSnapshotMapping struct {
	// Id of the snapshot in the control plane. This will typically be the LCS
	// uuid.
	LcsUuid *string `protobuf:"bytes,1,opt,name=lcs_uuid,json=lcsUuid" json:"lcs_uuid,omitempty"`
	// LWS id associated.
	LwsId                *int64   `protobuf:"varint,2,opt,name=lws_id,json=lwsId" json:"lws_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ControlPlaneSnapshotMapping) Reset() {
	*m = MedusaNearSyncConsistencyGroupMapEntryProto_ControlPlaneSnapshotMapping{}
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ControlPlaneSnapshotMapping) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_ControlPlaneSnapshotMapping) ProtoMessage() {}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_ControlPlaneSnapshotMapping) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{12, 4}
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ControlPlaneSnapshotMapping) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ControlPlaneSnapshotMapping.Unmarshal(m, b)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ControlPlaneSnapshotMapping) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ControlPlaneSnapshotMapping.Marshal(b, m, deterministic)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ControlPlaneSnapshotMapping) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ControlPlaneSnapshotMapping.Merge(m, src)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ControlPlaneSnapshotMapping) XXX_Size() int {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ControlPlaneSnapshotMapping.Size(m)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ControlPlaneSnapshotMapping) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ControlPlaneSnapshotMapping.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_ControlPlaneSnapshotMapping proto.InternalMessageInfo

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ControlPlaneSnapshotMapping) GetLcsUuid() string {
	if m != nil && m.LcsUuid != nil {
		return *m.LcsUuid
	}
	return ""
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_ControlPlaneSnapshotMapping) GetLwsId() int64 {
	if m != nil && m.LwsId != nil {
		return *m.LwsId
	}
	return 0
}

// Container mapping configuration for each remote. If a remote does not
// include an entry in 'remote_ctr_mapping_vec', nearsync container mapping
// is not enabled for the remote.
type MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping struct {
	RemoteSiteUuid []byte `protobuf:"bytes,1,opt,name=remote_site_uuid,json=remoteSiteUuid" json:"remote_site_uuid,omitempty"`
	// List of remote containers.
	RemoteCtrNameVec []string `protobuf:"bytes,2,rep,name=remote_ctr_name_vec,json=remoteCtrNameVec" json:"remote_ctr_name_vec,omitempty"`
	// Represents 'file_path' --> index into 'remote_ctr_name_vec' mapping for
	// all files.
	FileCtrMappingVec []*MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_FileContainerMapping `protobuf:"bytes,3,rep,name=file_ctr_mapping_vec,json=fileCtrMappingVec" json:"file_ctr_mapping_vec,omitempty"`
	// Represents 'vdisk_name' --> index into 'remote_ctr_name_vec' mapping for
	// all vdisks.
	VdiskCtrMappingVec   []*MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_VDiskContainerMapping `protobuf:"bytes,4,rep,name=vdisk_ctr_mapping_vec,json=vdiskCtrMappingVec" json:"vdisk_ctr_mapping_vec,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                                                                                    `json:"-"`
	XXX_unrecognized     []byte                                                                                      `json:"-"`
	XXX_sizecache        int32                                                                                       `json:"-"`
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping) Reset() {
	*m = MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping{}
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping) ProtoMessage() {}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{12, 5}
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping.Unmarshal(m, b)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping.Marshal(b, m, deterministic)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping.Merge(m, src)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping) XXX_Size() int {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping.Size(m)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping proto.InternalMessageInfo

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping) GetRemoteSiteUuid() []byte {
	if m != nil {
		return m.RemoteSiteUuid
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping) GetRemoteCtrNameVec() []string {
	if m != nil {
		return m.RemoteCtrNameVec
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping) GetFileCtrMappingVec() []*MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_FileContainerMapping {
	if m != nil {
		return m.FileCtrMappingVec
	}
	return nil
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping) GetVdiskCtrMappingVec() []*MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_VDiskContainerMapping {
	if m != nil {
		return m.VdiskCtrMappingVec
	}
	return nil
}

// File level container mapping info for remote 'remote_site_uuid'.
type MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_FileContainerMapping struct {
	FilePath *string `protobuf:"bytes,1,opt,name=file_path,json=filePath" json:"file_path,omitempty"`
	// Represents index into 'remote_ctr_name_vec' for file 'file_path'.
	RemoteCtrNameIndex   *int32   `protobuf:"varint,2,opt,name=remote_ctr_name_index,json=remoteCtrNameIndex" json:"remote_ctr_name_index,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_FileContainerMapping) Reset() {
	*m = MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_FileContainerMapping{}
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_FileContainerMapping) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_FileContainerMapping) ProtoMessage() {
}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_FileContainerMapping) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{12, 5, 0}
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_FileContainerMapping) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_FileContainerMapping.Unmarshal(m, b)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_FileContainerMapping) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_FileContainerMapping.Marshal(b, m, deterministic)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_FileContainerMapping) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_FileContainerMapping.Merge(m, src)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_FileContainerMapping) XXX_Size() int {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_FileContainerMapping.Size(m)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_FileContainerMapping) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_FileContainerMapping.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_FileContainerMapping proto.InternalMessageInfo

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_FileContainerMapping) GetFilePath() string {
	if m != nil && m.FilePath != nil {
		return *m.FilePath
	}
	return ""
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_FileContainerMapping) GetRemoteCtrNameIndex() int32 {
	if m != nil && m.RemoteCtrNameIndex != nil {
		return *m.RemoteCtrNameIndex
	}
	return 0
}

// VDisk to target container mapping for remote 'remote_site_uuid'.
type MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_VDiskContainerMapping struct {
	// VDisk for which remote container mapping information is stored.
	VdiskName *string `protobuf:"bytes,1,opt,name=vdisk_name,json=vdiskName" json:"vdisk_name,omitempty"`
	// Index into 'remote_ctr_name_vec' for vdisk 'vdisk_name'.
	RemoteCtrNameIndex   *int32   `protobuf:"varint,2,opt,name=remote_ctr_name_index,json=remoteCtrNameIndex" json:"remote_ctr_name_index,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_VDiskContainerMapping) Reset() {
	*m = MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_VDiskContainerMapping{}
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_VDiskContainerMapping) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_VDiskContainerMapping) ProtoMessage() {
}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_VDiskContainerMapping) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{12, 5, 1}
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_VDiskContainerMapping) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_VDiskContainerMapping.Unmarshal(m, b)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_VDiskContainerMapping) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_VDiskContainerMapping.Marshal(b, m, deterministic)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_VDiskContainerMapping) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_VDiskContainerMapping.Merge(m, src)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_VDiskContainerMapping) XXX_Size() int {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_VDiskContainerMapping.Size(m)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_VDiskContainerMapping) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_VDiskContainerMapping.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_VDiskContainerMapping proto.InternalMessageInfo

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_VDiskContainerMapping) GetVdiskName() string {
	if m != nil && m.VdiskName != nil {
		return *m.VdiskName
	}
	return ""
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_VDiskContainerMapping) GetRemoteCtrNameIndex() int32 {
	if m != nil && m.RemoteCtrNameIndex != nil {
		return *m.RemoteCtrNameIndex
	}
	return 0
}

// This field tracks the distributed oplog data log ID for each vdisk that is
// part of the CG.
type MedusaNearSyncConsistencyGroupMapEntryProto_OplogRegistration struct {
	// Name of the vdisk protected by this CG.
	VdiskName *string `protobuf:"bytes,1,opt,name=vdisk_name,json=vdiskName" json:"vdisk_name,omitempty"`
	// Distributed oplog log ID corresponding to the protected vdisk's data
	// log.
	DataLogId            *int64   `protobuf:"varint,2,opt,name=data_log_id,json=dataLogId" json:"data_log_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogRegistration) Reset() {
	*m = MedusaNearSyncConsistencyGroupMapEntryProto_OplogRegistration{}
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogRegistration) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_OplogRegistration) ProtoMessage() {}
func (*MedusaNearSyncConsistencyGroupMapEntryProto_OplogRegistration) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{12, 6}
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogRegistration) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_OplogRegistration.Unmarshal(m, b)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogRegistration) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_OplogRegistration.Marshal(b, m, deterministic)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogRegistration) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_OplogRegistration.Merge(m, src)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogRegistration) XXX_Size() int {
	return xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_OplogRegistration.Size(m)
}
func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogRegistration) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_OplogRegistration.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNearSyncConsistencyGroupMapEntryProto_OplogRegistration proto.InternalMessageInfo

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogRegistration) GetVdiskName() string {
	if m != nil && m.VdiskName != nil {
		return *m.VdiskName
	}
	return ""
}

func (m *MedusaNearSyncConsistencyGroupMapEntryProto_OplogRegistration) GetDataLogId() int64 {
	if m != nil && m.DataLogId != nil {
		return *m.DataLogId
	}
	return 0
}

// Entry in the near sync oplog map in Medusa. This map provides the following
// information:
// (cgid, segment_id) -> Medusa state maintained for the cg's oplog.
// On the source cluster this map is updated after the cg controller takes
// ownership of episode metadata from the vdisk controller or when an episode
// is relocated or deleted. On the remote cluster this map is updated after it
// receives an episode metadata update from the source cluster, or when an
// episode is relocated or deleted.
type MedusaNearSyncOplogMapEntryProto struct {
	VdiskOplogs          []*MedusaNearSyncOplogMapEntryProto_Oplog `protobuf:"bytes,1,rep,name=vdisk_oplogs,json=vdiskOplogs" json:"vdisk_oplogs,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                                  `json:"-"`
	XXX_unrecognized     []byte                                    `json:"-"`
	XXX_sizecache        int32                                     `json:"-"`
}

func (m *MedusaNearSyncOplogMapEntryProto) Reset()         { *m = MedusaNearSyncOplogMapEntryProto{} }
func (m *MedusaNearSyncOplogMapEntryProto) String() string { return proto.CompactTextString(m) }
func (*MedusaNearSyncOplogMapEntryProto) ProtoMessage()    {}
func (*MedusaNearSyncOplogMapEntryProto) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{13}
}

func (m *MedusaNearSyncOplogMapEntryProto) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNearSyncOplogMapEntryProto.Unmarshal(m, b)
}
func (m *MedusaNearSyncOplogMapEntryProto) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNearSyncOplogMapEntryProto.Marshal(b, m, deterministic)
}
func (m *MedusaNearSyncOplogMapEntryProto) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNearSyncOplogMapEntryProto.Merge(m, src)
}
func (m *MedusaNearSyncOplogMapEntryProto) XXX_Size() int {
	return xxx_messageInfo_MedusaNearSyncOplogMapEntryProto.Size(m)
}
func (m *MedusaNearSyncOplogMapEntryProto) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNearSyncOplogMapEntryProto.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNearSyncOplogMapEntryProto proto.InternalMessageInfo

func (m *MedusaNearSyncOplogMapEntryProto) GetVdiskOplogs() []*MedusaNearSyncOplogMapEntryProto_Oplog {
	if m != nil {
		return m.VdiskOplogs
	}
	return nil
}

type MedusaNearSyncOplogMapEntryProto_Oplog struct {
	// The vdisk name whose oplog episodes are captured in this entry.
	VdiskName *string `protobuf:"bytes,1,opt,name=vdisk_name,json=vdiskName" json:"vdisk_name,omitempty"`
	// The range of oplog global timestamps that the episodes in this entry
	// spans.
	StartOplogGlobalTimestamp *int64 `protobuf:"varint,2,opt,name=start_oplog_global_timestamp,json=startOplogGlobalTimestamp" json:"start_oplog_global_timestamp,omitempty"`
	EndOplogGlobalTimestamp   *int64 `protobuf:"varint,3,opt,name=end_oplog_global_timestamp,json=endOplogGlobalTimestamp" json:"end_oplog_global_timestamp,omitempty"`
	// List of oplog episode metadata captured in this oplog map segment.
	Episodes             []*MedusaVDiskOplogMapEntryProto_Episode                     `protobuf:"bytes,4,rep,name=episodes" json:"episodes,omitempty"`
	TentativePruneUpdate *MedusaNearSyncOplogMapEntryProto_Oplog_TentativePruneUpdate `protobuf:"bytes,5,opt,name=tentative_prune_update,json=tentativePruneUpdate" json:"tentative_prune_update,omitempty"`
	// On the source site, this represents the container id of the vdisk whose
	// oplog episodes are captured in this entry. On the remote site, this
	// represents the container id obtained from the corresponding
	// vstore_mapping which is maintained by cerebro in zeus config.
	ContainerId *int64 `protobuf:"varint,6,opt,name=container_id,json=containerId,def=-1" json:"container_id,omitempty"`
	// Highest persistently transferred data episode sequence.
	HighestSyncedDataEpisodeSeq *int64 `protobuf:"varint,7,opt,name=highest_synced_data_episode_seq,json=highestSyncedDataEpisodeSeq" json:"highest_synced_data_episode_seq,omitempty"`
	// Last received episode. Used on the remote site.
	LastRecvdEpisode     *MedusaVDiskOplogMapEntryProto_Episode `protobuf:"bytes,8,opt,name=last_recvd_episode,json=lastRecvdEpisode" json:"last_recvd_episode,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                               `json:"-"`
	XXX_unrecognized     []byte                                 `json:"-"`
	XXX_sizecache        int32                                  `json:"-"`
}

func (m *MedusaNearSyncOplogMapEntryProto_Oplog) Reset() {
	*m = MedusaNearSyncOplogMapEntryProto_Oplog{}
}
func (m *MedusaNearSyncOplogMapEntryProto_Oplog) String() string { return proto.CompactTextString(m) }
func (*MedusaNearSyncOplogMapEntryProto_Oplog) ProtoMessage()    {}
func (*MedusaNearSyncOplogMapEntryProto_Oplog) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{13, 0}
}

func (m *MedusaNearSyncOplogMapEntryProto_Oplog) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNearSyncOplogMapEntryProto_Oplog.Unmarshal(m, b)
}
func (m *MedusaNearSyncOplogMapEntryProto_Oplog) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNearSyncOplogMapEntryProto_Oplog.Marshal(b, m, deterministic)
}
func (m *MedusaNearSyncOplogMapEntryProto_Oplog) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNearSyncOplogMapEntryProto_Oplog.Merge(m, src)
}
func (m *MedusaNearSyncOplogMapEntryProto_Oplog) XXX_Size() int {
	return xxx_messageInfo_MedusaNearSyncOplogMapEntryProto_Oplog.Size(m)
}
func (m *MedusaNearSyncOplogMapEntryProto_Oplog) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNearSyncOplogMapEntryProto_Oplog.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNearSyncOplogMapEntryProto_Oplog proto.InternalMessageInfo

const Default_MedusaNearSyncOplogMapEntryProto_Oplog_ContainerId int64 = -1

func (m *MedusaNearSyncOplogMapEntryProto_Oplog) GetVdiskName() string {
	if m != nil && m.VdiskName != nil {
		return *m.VdiskName
	}
	return ""
}

func (m *MedusaNearSyncOplogMapEntryProto_Oplog) GetStartOplogGlobalTimestamp() int64 {
	if m != nil && m.StartOplogGlobalTimestamp != nil {
		return *m.StartOplogGlobalTimestamp
	}
	return 0
}

func (m *MedusaNearSyncOplogMapEntryProto_Oplog) GetEndOplogGlobalTimestamp() int64 {
	if m != nil && m.EndOplogGlobalTimestamp != nil {
		return *m.EndOplogGlobalTimestamp
	}
	return 0
}

func (m *MedusaNearSyncOplogMapEntryProto_Oplog) GetEpisodes() []*MedusaVDiskOplogMapEntryProto_Episode {
	if m != nil {
		return m.Episodes
	}
	return nil
}

func (m *MedusaNearSyncOplogMapEntryProto_Oplog) GetTentativePruneUpdate() *MedusaNearSyncOplogMapEntryProto_Oplog_TentativePruneUpdate {
	if m != nil {
		return m.TentativePruneUpdate
	}
	return nil
}

func (m *MedusaNearSyncOplogMapEntryProto_Oplog) GetContainerId() int64 {
	if m != nil && m.ContainerId != nil {
		return *m.ContainerId
	}
	return Default_MedusaNearSyncOplogMapEntryProto_Oplog_ContainerId
}

func (m *MedusaNearSyncOplogMapEntryProto_Oplog) GetHighestSyncedDataEpisodeSeq() int64 {
	if m != nil && m.HighestSyncedDataEpisodeSeq != nil {
		return *m.HighestSyncedDataEpisodeSeq
	}
	return 0
}

func (m *MedusaNearSyncOplogMapEntryProto_Oplog) GetLastRecvdEpisode() *MedusaVDiskOplogMapEntryProto_Episode {
	if m != nil {
		return m.LastRecvdEpisode
	}
	return nil
}

// Tentative prune update contains episodes that have been identified for
// deletion from lws-store.
type MedusaNearSyncOplogMapEntryProto_Oplog_TentativePruneUpdate struct {
	Episodes             []*MedusaVDiskOplogMapEntryProto_Episode `protobuf:"bytes,3,rep,name=episodes" json:"episodes,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                                 `json:"-"`
	XXX_unrecognized     []byte                                   `json:"-"`
	XXX_sizecache        int32                                    `json:"-"`
}

func (m *MedusaNearSyncOplogMapEntryProto_Oplog_TentativePruneUpdate) Reset() {
	*m = MedusaNearSyncOplogMapEntryProto_Oplog_TentativePruneUpdate{}
}
func (m *MedusaNearSyncOplogMapEntryProto_Oplog_TentativePruneUpdate) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaNearSyncOplogMapEntryProto_Oplog_TentativePruneUpdate) ProtoMessage() {}
func (*MedusaNearSyncOplogMapEntryProto_Oplog_TentativePruneUpdate) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{13, 0, 0}
}

func (m *MedusaNearSyncOplogMapEntryProto_Oplog_TentativePruneUpdate) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNearSyncOplogMapEntryProto_Oplog_TentativePruneUpdate.Unmarshal(m, b)
}
func (m *MedusaNearSyncOplogMapEntryProto_Oplog_TentativePruneUpdate) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNearSyncOplogMapEntryProto_Oplog_TentativePruneUpdate.Marshal(b, m, deterministic)
}
func (m *MedusaNearSyncOplogMapEntryProto_Oplog_TentativePruneUpdate) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNearSyncOplogMapEntryProto_Oplog_TentativePruneUpdate.Merge(m, src)
}
func (m *MedusaNearSyncOplogMapEntryProto_Oplog_TentativePruneUpdate) XXX_Size() int {
	return xxx_messageInfo_MedusaNearSyncOplogMapEntryProto_Oplog_TentativePruneUpdate.Size(m)
}
func (m *MedusaNearSyncOplogMapEntryProto_Oplog_TentativePruneUpdate) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNearSyncOplogMapEntryProto_Oplog_TentativePruneUpdate.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNearSyncOplogMapEntryProto_Oplog_TentativePruneUpdate proto.InternalMessageInfo

func (m *MedusaNearSyncOplogMapEntryProto_Oplog_TentativePruneUpdate) GetEpisodes() []*MedusaVDiskOplogMapEntryProto_Episode {
	if m != nil {
		return m.Episodes
	}
	return nil
}

// Entry in the near sync LWS map in Medusa. This map provides the following
// information :
// lwsid -> Medusa state maintained for the LWS entry.
// On the source cluster this map is updated when a LWS is finalized. On the
// remote cluster this map is updated when it receives a finalized LWS's
// metadata from the source cluster.
type MedusaNearSyncLWSMapEntryProto struct {
	// The LWS metadata.
	LwsMetadata *LWSMetadataProto `protobuf:"bytes,1,opt,name=lws_metadata,json=lwsMetadata" json:"lws_metadata,omitempty"`
	// The vdisk names for files specified by
	// 'vdisk_backed_current_file_indices' in 'lws_metadata'.
	VdiskNames []string `protobuf:"bytes,2,rep,name=vdisk_names,json=vdiskNames" json:"vdisk_names,omitempty"`
	// The nfs attributes captured at lws finalization for files specified by
	// 'vdisk_backed_current_file_indices' in 'lws_metadata'.
	NfsAttrForVdiskBackedFiles []*MedusaNFSAttrProto `protobuf:"bytes,3,rep,name=nfs_attr_for_vdisk_backed_files,json=nfsAttrForVdiskBackedFiles" json:"nfs_attr_for_vdisk_backed_files,omitempty"`
	// The oplog global timestamp ranges captured at LWS finalization.
	StartOplogGlobalTimestamps []int64 `protobuf:"varint,4,rep,name=start_oplog_global_timestamps,json=startOplogGlobalTimestamps" json:"start_oplog_global_timestamps,omitempty"`
	EndOplogGlobalTimestamps   []int64 `protobuf:"varint,5,rep,name=end_oplog_global_timestamps,json=endOplogGlobalTimestamps" json:"end_oplog_global_timestamps,omitempty"`
	// Total oplog bytes written from the time the file was added to the cg to
	// when this LWS entry was finalized.
	StartOplogGlobalBytes []int64 `protobuf:"varint,6,rep,name=start_oplog_global_bytes,json=startOplogGlobalBytes" json:"start_oplog_global_bytes,omitempty"`
	EndOplogGlobalBytes   []int64 `protobuf:"varint,7,rep,name=end_oplog_global_bytes,json=endOplogGlobalBytes" json:"end_oplog_global_bytes,omitempty"`
	// Shadow inode ids for small files.
	ShadowInodeIds []*NfsInodeIdProto `protobuf:"bytes,8,rep,name=shadow_inode_ids,json=shadowInodeIds" json:"shadow_inode_ids,omitempty"`
	// Vector of logical operation clocks that corresponds to potentially
	// ongoing operations that last modified this entry.
	Locs                 []*zeus.LogicalOperationClock `protobuf:"bytes,9,rep,name=locs" json:"locs,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                      `json:"-"`
	XXX_unrecognized     []byte                        `json:"-"`
	XXX_sizecache        int32                         `json:"-"`
}

func (m *MedusaNearSyncLWSMapEntryProto) Reset()         { *m = MedusaNearSyncLWSMapEntryProto{} }
func (m *MedusaNearSyncLWSMapEntryProto) String() string { return proto.CompactTextString(m) }
func (*MedusaNearSyncLWSMapEntryProto) ProtoMessage()    {}
func (*MedusaNearSyncLWSMapEntryProto) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{14}
}

func (m *MedusaNearSyncLWSMapEntryProto) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNearSyncLWSMapEntryProto.Unmarshal(m, b)
}
func (m *MedusaNearSyncLWSMapEntryProto) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNearSyncLWSMapEntryProto.Marshal(b, m, deterministic)
}
func (m *MedusaNearSyncLWSMapEntryProto) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNearSyncLWSMapEntryProto.Merge(m, src)
}
func (m *MedusaNearSyncLWSMapEntryProto) XXX_Size() int {
	return xxx_messageInfo_MedusaNearSyncLWSMapEntryProto.Size(m)
}
func (m *MedusaNearSyncLWSMapEntryProto) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNearSyncLWSMapEntryProto.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNearSyncLWSMapEntryProto proto.InternalMessageInfo

func (m *MedusaNearSyncLWSMapEntryProto) GetLwsMetadata() *LWSMetadataProto {
	if m != nil {
		return m.LwsMetadata
	}
	return nil
}

func (m *MedusaNearSyncLWSMapEntryProto) GetVdiskNames() []string {
	if m != nil {
		return m.VdiskNames
	}
	return nil
}

func (m *MedusaNearSyncLWSMapEntryProto) GetNfsAttrForVdiskBackedFiles() []*MedusaNFSAttrProto {
	if m != nil {
		return m.NfsAttrForVdiskBackedFiles
	}
	return nil
}

func (m *MedusaNearSyncLWSMapEntryProto) GetStartOplogGlobalTimestamps() []int64 {
	if m != nil {
		return m.StartOplogGlobalTimestamps
	}
	return nil
}

func (m *MedusaNearSyncLWSMapEntryProto) GetEndOplogGlobalTimestamps() []int64 {
	if m != nil {
		return m.EndOplogGlobalTimestamps
	}
	return nil
}

func (m *MedusaNearSyncLWSMapEntryProto) GetStartOplogGlobalBytes() []int64 {
	if m != nil {
		return m.StartOplogGlobalBytes
	}
	return nil
}

func (m *MedusaNearSyncLWSMapEntryProto) GetEndOplogGlobalBytes() []int64 {
	if m != nil {
		return m.EndOplogGlobalBytes
	}
	return nil
}

func (m *MedusaNearSyncLWSMapEntryProto) GetShadowInodeIds() []*NfsInodeIdProto {
	if m != nil {
		return m.ShadowInodeIds
	}
	return nil
}

func (m *MedusaNearSyncLWSMapEntryProto) GetLocs() []*zeus.LogicalOperationClock {
	if m != nil {
		return m.Locs
	}
	return nil
}

// Entry in the near sync staging area map in Medusa. This map provides the
// following information :
// staging_area_path_identifier -> Medusa state maintained for state of the
// apply operation on the staging area.
// The entry is used to save state and track operations on the LWS
// staging area. This staging area is used as a scratch space during recovery
// of Light Weight Snapshots (LWS)
type MedusaNearSyncStagingAreaMapEntryProto struct {
	// Indicates the operation currently in progress on the staging area.
	CurrOpInProg *MedusaNearSyncStagingAreaMapEntryProto_LWSStagingAreaOps `protobuf:"varint,1,opt,name=curr_op_in_prog,json=currOpInProg,enum=nutanix.medusa.MedusaNearSyncStagingAreaMapEntryProto_LWSStagingAreaOps,def=0" json:"curr_op_in_prog,omitempty"`
	// List of all the container name to container ids touched during the
	// application of LWS'es to the staging area.
	ContainerNameToIdVec []*MedusaNearSyncStagingAreaMapEntryProto_ContainerNameToContainerId `protobuf:"bytes,2,rep,name=container_name_to_id_vec,json=containerNameToIdVec" json:"container_name_to_id_vec,omitempty"`
	// The consistency group in the staging area that this entry corresponds to.
	CgId *ConsistencyGroupIdProto `protobuf:"bytes,3,opt,name=cg_id,json=cgId" json:"cg_id,omitempty"`
	// The current staging area path that this state is associated with. This
	// path is relative to the container(s).
	StagingAreaDirPath   *string                                              `protobuf:"bytes,4,opt,name=staging_area_dir_path,json=stagingAreaDirPath" json:"staging_area_dir_path,omitempty"`
	NfsLwsApplyOpState   *MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState `protobuf:"bytes,5,opt,name=nfs_lws_apply_op_state,json=nfsLwsApplyOpState" json:"nfs_lws_apply_op_state,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                                             `json:"-"`
	XXX_unrecognized     []byte                                               `json:"-"`
	XXX_sizecache        int32                                                `json:"-"`
}

func (m *MedusaNearSyncStagingAreaMapEntryProto) Reset() {
	*m = MedusaNearSyncStagingAreaMapEntryProto{}
}
func (m *MedusaNearSyncStagingAreaMapEntryProto) String() string { return proto.CompactTextString(m) }
func (*MedusaNearSyncStagingAreaMapEntryProto) ProtoMessage()    {}
func (*MedusaNearSyncStagingAreaMapEntryProto) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{15}
}

func (m *MedusaNearSyncStagingAreaMapEntryProto) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNearSyncStagingAreaMapEntryProto.Unmarshal(m, b)
}
func (m *MedusaNearSyncStagingAreaMapEntryProto) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNearSyncStagingAreaMapEntryProto.Marshal(b, m, deterministic)
}
func (m *MedusaNearSyncStagingAreaMapEntryProto) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNearSyncStagingAreaMapEntryProto.Merge(m, src)
}
func (m *MedusaNearSyncStagingAreaMapEntryProto) XXX_Size() int {
	return xxx_messageInfo_MedusaNearSyncStagingAreaMapEntryProto.Size(m)
}
func (m *MedusaNearSyncStagingAreaMapEntryProto) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNearSyncStagingAreaMapEntryProto.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNearSyncStagingAreaMapEntryProto proto.InternalMessageInfo

const Default_MedusaNearSyncStagingAreaMapEntryProto_CurrOpInProg MedusaNearSyncStagingAreaMapEntryProto_LWSStagingAreaOps = MedusaNearSyncStagingAreaMapEntryProto_kIdle

func (m *MedusaNearSyncStagingAreaMapEntryProto) GetCurrOpInProg() MedusaNearSyncStagingAreaMapEntryProto_LWSStagingAreaOps {
	if m != nil && m.CurrOpInProg != nil {
		return *m.CurrOpInProg
	}
	return Default_MedusaNearSyncStagingAreaMapEntryProto_CurrOpInProg
}

func (m *MedusaNearSyncStagingAreaMapEntryProto) GetContainerNameToIdVec() []*MedusaNearSyncStagingAreaMapEntryProto_ContainerNameToContainerId {
	if m != nil {
		return m.ContainerNameToIdVec
	}
	return nil
}

func (m *MedusaNearSyncStagingAreaMapEntryProto) GetCgId() *ConsistencyGroupIdProto {
	if m != nil {
		return m.CgId
	}
	return nil
}

func (m *MedusaNearSyncStagingAreaMapEntryProto) GetStagingAreaDirPath() string {
	if m != nil && m.StagingAreaDirPath != nil {
		return *m.StagingAreaDirPath
	}
	return ""
}

func (m *MedusaNearSyncStagingAreaMapEntryProto) GetNfsLwsApplyOpState() *MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState {
	if m != nil {
		return m.NfsLwsApplyOpState
	}
	return nil
}

// Track the container name to container id for file paths that we have
// seen during apply to this staging area. This information can be be used
// to detect deletion/re-addition of a container in the middle of apply of
// LWS'es to a staging area.
type MedusaNearSyncStagingAreaMapEntryProto_ContainerNameToContainerId struct {
	// The name of the container operated upon during LWS apply.
	ContainerName *string `protobuf:"bytes,1,opt,name=container_name,json=containerName" json:"container_name,omitempty"`
	// The id of the container.
	ContainerId          *int64   `protobuf:"varint,2,opt,name=container_id,json=containerId" json:"container_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaNearSyncStagingAreaMapEntryProto_ContainerNameToContainerId) Reset() {
	*m = MedusaNearSyncStagingAreaMapEntryProto_ContainerNameToContainerId{}
}
func (m *MedusaNearSyncStagingAreaMapEntryProto_ContainerNameToContainerId) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaNearSyncStagingAreaMapEntryProto_ContainerNameToContainerId) ProtoMessage() {}
func (*MedusaNearSyncStagingAreaMapEntryProto_ContainerNameToContainerId) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{15, 0}
}

func (m *MedusaNearSyncStagingAreaMapEntryProto_ContainerNameToContainerId) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNearSyncStagingAreaMapEntryProto_ContainerNameToContainerId.Unmarshal(m, b)
}
func (m *MedusaNearSyncStagingAreaMapEntryProto_ContainerNameToContainerId) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNearSyncStagingAreaMapEntryProto_ContainerNameToContainerId.Marshal(b, m, deterministic)
}
func (m *MedusaNearSyncStagingAreaMapEntryProto_ContainerNameToContainerId) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNearSyncStagingAreaMapEntryProto_ContainerNameToContainerId.Merge(m, src)
}
func (m *MedusaNearSyncStagingAreaMapEntryProto_ContainerNameToContainerId) XXX_Size() int {
	return xxx_messageInfo_MedusaNearSyncStagingAreaMapEntryProto_ContainerNameToContainerId.Size(m)
}
func (m *MedusaNearSyncStagingAreaMapEntryProto_ContainerNameToContainerId) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNearSyncStagingAreaMapEntryProto_ContainerNameToContainerId.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNearSyncStagingAreaMapEntryProto_ContainerNameToContainerId proto.InternalMessageInfo

func (m *MedusaNearSyncStagingAreaMapEntryProto_ContainerNameToContainerId) GetContainerName() string {
	if m != nil && m.ContainerName != nil {
		return *m.ContainerName
	}
	return ""
}

func (m *MedusaNearSyncStagingAreaMapEntryProto_ContainerNameToContainerId) GetContainerId() int64 {
	if m != nil && m.ContainerId != nil {
		return *m.ContainerId
	}
	return 0
}

type MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState struct {
	// Indicates the current stage that the LWS apply op is in.
	LwsApplyStage *MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage `protobuf:"varint,1,opt,name=lws_apply_stage,json=lwsApplyStage,enum=nutanix.medusa.MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage,def=0" json:"lws_apply_stage,omitempty"`
	// Record of expected file paths that an inode can be expected to be
	// associated with during the rename phase of LWS apply operation.
	FileRenameRecords []*MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_FileRenameState `protobuf:"bytes,2,rep,name=file_rename_records,json=fileRenameRecords" json:"file_rename_records,omitempty"`
	// The LWS id that is being applied in this staging area. This field is
	// not set if the 'lws_apply_stage' is set to LWSApplyStage::kIdle.
	CurrLwsId *int64 `protobuf:"varint,3,opt,name=curr_lws_id,json=currLwsId" json:"curr_lws_id,omitempty"`
	// The last LWS that was applied to this staging area. This field will
	// be set always.
	LastAppliedLwsId     *int64   `protobuf:"varint,5,opt,name=last_applied_lws_id,json=lastAppliedLwsId" json:"last_applied_lws_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState) Reset() {
	*m = MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState{}
}
func (m *MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState) ProtoMessage() {}
func (*MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{15, 1}
}

func (m *MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState.Unmarshal(m, b)
}
func (m *MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState.Marshal(b, m, deterministic)
}
func (m *MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState.Merge(m, src)
}
func (m *MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState) XXX_Size() int {
	return xxx_messageInfo_MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState.Size(m)
}
func (m *MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState proto.InternalMessageInfo

const Default_MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LwsApplyStage MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage = MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_kIdle

func (m *MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState) GetLwsApplyStage() MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage {
	if m != nil && m.LwsApplyStage != nil {
		return *m.LwsApplyStage
	}
	return Default_MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LwsApplyStage
}

func (m *MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState) GetFileRenameRecords() []*MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_FileRenameState {
	if m != nil {
		return m.FileRenameRecords
	}
	return nil
}

func (m *MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState) GetCurrLwsId() int64 {
	if m != nil && m.CurrLwsId != nil {
		return *m.CurrLwsId
	}
	return 0
}

func (m *MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState) GetLastAppliedLwsId() int64 {
	if m != nil && m.LastAppliedLwsId != nil {
		return *m.LastAppliedLwsId
	}
	return 0
}

// Track the file path associated with an inode across renames. This
// information can be used to provide idempotency guarantees across
// renames.
type MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_FileRenameState struct {
	// The inode id which is begin tracked across renames during LWS
	// apply.
	InodeId *NfsInodeIdProto `protobuf:"bytes,1,opt,name=inode_id,json=inodeId" json:"inode_id,omitempty"`
	// The target file paths that is going to be associated with the
	// inode in 'inode_id' during the rename phase of LWS apply.
	IntendedFilePath     *string  `protobuf:"bytes,2,opt,name=intended_file_path,json=intendedFilePath" json:"intended_file_path,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_FileRenameState) Reset() {
	*m = MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_FileRenameState{}
}
func (m *MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_FileRenameState) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_FileRenameState) ProtoMessage() {}
func (*MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_FileRenameState) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{15, 1, 0}
}

func (m *MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_FileRenameState) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_FileRenameState.Unmarshal(m, b)
}
func (m *MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_FileRenameState) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_FileRenameState.Marshal(b, m, deterministic)
}
func (m *MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_FileRenameState) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_FileRenameState.Merge(m, src)
}
func (m *MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_FileRenameState) XXX_Size() int {
	return xxx_messageInfo_MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_FileRenameState.Size(m)
}
func (m *MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_FileRenameState) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_FileRenameState.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_FileRenameState proto.InternalMessageInfo

func (m *MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_FileRenameState) GetInodeId() *NfsInodeIdProto {
	if m != nil {
		return m.InodeId
	}
	return nil
}

func (m *MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_FileRenameState) GetIntendedFilePath() string {
	if m != nil && m.IntendedFilePath != nil {
		return *m.IntendedFilePath
	}
	return ""
}

// Entry in the near sync episode link map in Medusa.
// The entry is used to save state and track unlinkable episodes when
// the parent CVM of the episode instance is down.
type MedusaNearSyncEpisodeLinkMapEntryProto struct {
	// The consistency group these episodes are related to.
	CgId *ConsistencyGroupIdProto `protobuf:"bytes,1,opt,name=cg_id,json=cgId" json:"cg_id,omitempty"`
	// The set of episode entries that will need to be hard linked to either
	// the oplog or lws stores on a node in a near sync source or target clusters
	// when the node has sufficiently recovered from a power condition.
	EpisodeLinkEntries   []*MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry `protobuf:"bytes,2,rep,name=episode_link_entries,json=episodeLinkEntries" json:"episode_link_entries,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                                            `json:"-"`
	XXX_unrecognized     []byte                                              `json:"-"`
	XXX_sizecache        int32                                               `json:"-"`
}

func (m *MedusaNearSyncEpisodeLinkMapEntryProto) Reset() {
	*m = MedusaNearSyncEpisodeLinkMapEntryProto{}
}
func (m *MedusaNearSyncEpisodeLinkMapEntryProto) String() string { return proto.CompactTextString(m) }
func (*MedusaNearSyncEpisodeLinkMapEntryProto) ProtoMessage()    {}
func (*MedusaNearSyncEpisodeLinkMapEntryProto) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{16}
}

func (m *MedusaNearSyncEpisodeLinkMapEntryProto) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNearSyncEpisodeLinkMapEntryProto.Unmarshal(m, b)
}
func (m *MedusaNearSyncEpisodeLinkMapEntryProto) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNearSyncEpisodeLinkMapEntryProto.Marshal(b, m, deterministic)
}
func (m *MedusaNearSyncEpisodeLinkMapEntryProto) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNearSyncEpisodeLinkMapEntryProto.Merge(m, src)
}
func (m *MedusaNearSyncEpisodeLinkMapEntryProto) XXX_Size() int {
	return xxx_messageInfo_MedusaNearSyncEpisodeLinkMapEntryProto.Size(m)
}
func (m *MedusaNearSyncEpisodeLinkMapEntryProto) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNearSyncEpisodeLinkMapEntryProto.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNearSyncEpisodeLinkMapEntryProto proto.InternalMessageInfo

func (m *MedusaNearSyncEpisodeLinkMapEntryProto) GetCgId() *ConsistencyGroupIdProto {
	if m != nil {
		return m.CgId
	}
	return nil
}

func (m *MedusaNearSyncEpisodeLinkMapEntryProto) GetEpisodeLinkEntries() []*MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry {
	if m != nil {
		return m.EpisodeLinkEntries
	}
	return nil
}

type MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry struct {
	// The vdisk id associated with the episode.
	VdiskId *int64 `protobuf:"varint,1,opt,name=vdisk_id,json=vdiskId" json:"vdisk_id,omitempty"`
	// Name of the vdisk the episode is associated with.
	VdiskName *string `protobuf:"bytes,2,opt,name=vdisk_name,json=vdiskName" json:"vdisk_name,omitempty"`
	// Oplog/LWS store episode sequence to be hard linked.
	SourceEpisodeSequence *int64 `protobuf:"varint,3,opt,name=source_episode_sequence,json=sourceEpisodeSequence" json:"source_episode_sequence,omitempty"`
	// Oplog episode target sequence to be hard linked.
	TargetEpisodeSequence *int64 `protobuf:"varint,4,opt,name=target_episode_sequence,json=targetEpisodeSequence" json:"target_episode_sequence,omitempty"`
	// Episode file types.
	FileTypes []OplogEpisodeFileType `protobuf:"varint,5,rep,name=file_types,json=fileTypes,enum=nutanix.medusa.OplogEpisodeFileType" json:"file_types,omitempty"`
	// Episode file sizes in oplog.
	FileSizes []int64 `protobuf:"varint,6,rep,name=file_sizes,json=fileSizes" json:"file_sizes,omitempty"`
	// Store type the episode needs to be linked to.
	StoreType            *EpisodeLinkStoreType `protobuf:"varint,7,opt,name=store_type,json=storeType,enum=nutanix.medusa.EpisodeLinkStoreType,def=0" json:"store_type,omitempty"`
	XXX_NoUnkeyedLiteral struct{}              `json:"-"`
	XXX_unrecognized     []byte                `json:"-"`
	XXX_sizecache        int32                 `json:"-"`
}

func (m *MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry) Reset() {
	*m = MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry{}
}
func (m *MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry) ProtoMessage() {}
func (*MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{16, 0}
}

func (m *MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry.Unmarshal(m, b)
}
func (m *MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry.Marshal(b, m, deterministic)
}
func (m *MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry.Merge(m, src)
}
func (m *MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry) XXX_Size() int {
	return xxx_messageInfo_MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry.Size(m)
}
func (m *MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry proto.InternalMessageInfo

const Default_MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry_StoreType EpisodeLinkStoreType = EpisodeLinkStoreType_kOplogToLws

func (m *MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry) GetVdiskId() int64 {
	if m != nil && m.VdiskId != nil {
		return *m.VdiskId
	}
	return 0
}

func (m *MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry) GetVdiskName() string {
	if m != nil && m.VdiskName != nil {
		return *m.VdiskName
	}
	return ""
}

func (m *MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry) GetSourceEpisodeSequence() int64 {
	if m != nil && m.SourceEpisodeSequence != nil {
		return *m.SourceEpisodeSequence
	}
	return 0
}

func (m *MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry) GetTargetEpisodeSequence() int64 {
	if m != nil && m.TargetEpisodeSequence != nil {
		return *m.TargetEpisodeSequence
	}
	return 0
}

func (m *MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry) GetFileTypes() []OplogEpisodeFileType {
	if m != nil {
		return m.FileTypes
	}
	return nil
}

func (m *MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry) GetFileSizes() []int64 {
	if m != nil {
		return m.FileSizes
	}
	return nil
}

func (m *MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry) GetStoreType() EpisodeLinkStoreType {
	if m != nil && m.StoreType != nil {
		return *m.StoreType
	}
	return Default_MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry_StoreType
}

// Proto describing the serialized IOBuffer payload containing the flatbuffers
// associated with a MedusaExtentGroupPhysicalStateEntry. This is used when
// sending the entry over an RPC.
type MedusaExtentGroupPhysicalStatePayloadDescriptor struct {
	// Length of the control block payload. If not set or non-positive, then no
	// other field in this descriptor will be set.
	ControlBlockPayloadLength *int32 `protobuf:"varint,1,opt,name=control_block_payload_length,json=controlBlockPayloadLength" json:"control_block_payload_length,omitempty"`
	// List of all the slice groups described.
	SliceGroupList []*MedusaExtentGroupPhysicalStatePayloadDescriptor_SliceGroupPayloadDescriptor `protobuf:"bytes,2,rep,name=slice_group_list,json=sliceGroupList" json:"slice_group_list,omitempty"`
	// List of all the extents described.
	ExtentIdList         []*MedusaExtentGroupPhysicalStatePayloadDescriptor_ExtentIdPayloadDescriptor `protobuf:"bytes,3,rep,name=extent_id_list,json=extentIdList" json:"extent_id_list,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                                                                     `json:"-"`
	XXX_unrecognized     []byte                                                                       `json:"-"`
	XXX_sizecache        int32                                                                        `json:"-"`
}

func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor) Reset() {
	*m = MedusaExtentGroupPhysicalStatePayloadDescriptor{}
}
func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaExtentGroupPhysicalStatePayloadDescriptor) ProtoMessage() {}
func (*MedusaExtentGroupPhysicalStatePayloadDescriptor) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{17}
}

func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaExtentGroupPhysicalStatePayloadDescriptor.Unmarshal(m, b)
}
func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaExtentGroupPhysicalStatePayloadDescriptor.Marshal(b, m, deterministic)
}
func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaExtentGroupPhysicalStatePayloadDescriptor.Merge(m, src)
}
func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor) XXX_Size() int {
	return xxx_messageInfo_MedusaExtentGroupPhysicalStatePayloadDescriptor.Size(m)
}
func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaExtentGroupPhysicalStatePayloadDescriptor.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaExtentGroupPhysicalStatePayloadDescriptor proto.InternalMessageInfo

func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor) GetControlBlockPayloadLength() int32 {
	if m != nil && m.ControlBlockPayloadLength != nil {
		return *m.ControlBlockPayloadLength
	}
	return 0
}

func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor) GetSliceGroupList() []*MedusaExtentGroupPhysicalStatePayloadDescriptor_SliceGroupPayloadDescriptor {
	if m != nil {
		return m.SliceGroupList
	}
	return nil
}

func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor) GetExtentIdList() []*MedusaExtentGroupPhysicalStatePayloadDescriptor_ExtentIdPayloadDescriptor {
	if m != nil {
		return m.ExtentIdList
	}
	return nil
}

// Describes the SliceGroup payload.
// Slices can be stored in one of the following ways:
// 1) Key based on slice index in an extent. In this case the SliceGroup key
//    will be described by pair consisting of (extent_id, slice_group_id).
// 2) Key based on slice id. In this case slices are stored independent of
//    their extent association. The SliceGroup key will be described by pair
//    consisting of (nullptr, slice_group_id).
type MedusaExtentGroupPhysicalStatePayloadDescriptor_SliceGroupPayloadDescriptor struct {
	// Id of the extent to which this SliceGroup is associated to.
	ExtentId *ExtentIdProto `protobuf:"bytes,1,opt,name=extent_id,json=extentId" json:"extent_id,omitempty"`
	// Id of the base slice.
	SliceGroupId *uint32 `protobuf:"varint,2,opt,name=slice_group_id,json=sliceGroupId" json:"slice_group_id,omitempty"`
	// Length of the payload containing the slice group flatbuffer.
	PayloadLength        *int32   `protobuf:"varint,3,opt,name=payload_length,json=payloadLength" json:"payload_length,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor_SliceGroupPayloadDescriptor) Reset() {
	*m = MedusaExtentGroupPhysicalStatePayloadDescriptor_SliceGroupPayloadDescriptor{}
}
func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor_SliceGroupPayloadDescriptor) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaExtentGroupPhysicalStatePayloadDescriptor_SliceGroupPayloadDescriptor) ProtoMessage() {}
func (*MedusaExtentGroupPhysicalStatePayloadDescriptor_SliceGroupPayloadDescriptor) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{17, 0}
}

func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor_SliceGroupPayloadDescriptor) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaExtentGroupPhysicalStatePayloadDescriptor_SliceGroupPayloadDescriptor.Unmarshal(m, b)
}
func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor_SliceGroupPayloadDescriptor) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaExtentGroupPhysicalStatePayloadDescriptor_SliceGroupPayloadDescriptor.Marshal(b, m, deterministic)
}
func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor_SliceGroupPayloadDescriptor) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaExtentGroupPhysicalStatePayloadDescriptor_SliceGroupPayloadDescriptor.Merge(m, src)
}
func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor_SliceGroupPayloadDescriptor) XXX_Size() int {
	return xxx_messageInfo_MedusaExtentGroupPhysicalStatePayloadDescriptor_SliceGroupPayloadDescriptor.Size(m)
}
func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor_SliceGroupPayloadDescriptor) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaExtentGroupPhysicalStatePayloadDescriptor_SliceGroupPayloadDescriptor.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaExtentGroupPhysicalStatePayloadDescriptor_SliceGroupPayloadDescriptor proto.InternalMessageInfo

func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor_SliceGroupPayloadDescriptor) GetExtentId() *ExtentIdProto {
	if m != nil {
		return m.ExtentId
	}
	return nil
}

func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor_SliceGroupPayloadDescriptor) GetSliceGroupId() uint32 {
	if m != nil && m.SliceGroupId != nil {
		return *m.SliceGroupId
	}
	return 0
}

func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor_SliceGroupPayloadDescriptor) GetPayloadLength() int32 {
	if m != nil && m.PayloadLength != nil {
		return *m.PayloadLength
	}
	return 0
}

// Describes the ExtentId payload.
type MedusaExtentGroupPhysicalStatePayloadDescriptor_ExtentIdPayloadDescriptor struct {
	// Id of the extent.
	ExtentId *ExtentIdProto `protobuf:"bytes,1,opt,name=extent_id,json=extentId" json:"extent_id,omitempty"`
	// Length of the payload containing the extent state flatbuffer associated
	// with the above extent id.
	PayloadLength        *int32   `protobuf:"varint,2,opt,name=payload_length,json=payloadLength" json:"payload_length,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor_ExtentIdPayloadDescriptor) Reset() {
	*m = MedusaExtentGroupPhysicalStatePayloadDescriptor_ExtentIdPayloadDescriptor{}
}
func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor_ExtentIdPayloadDescriptor) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaExtentGroupPhysicalStatePayloadDescriptor_ExtentIdPayloadDescriptor) ProtoMessage() {}
func (*MedusaExtentGroupPhysicalStatePayloadDescriptor_ExtentIdPayloadDescriptor) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{17, 1}
}

func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor_ExtentIdPayloadDescriptor) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaExtentGroupPhysicalStatePayloadDescriptor_ExtentIdPayloadDescriptor.Unmarshal(m, b)
}
func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor_ExtentIdPayloadDescriptor) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaExtentGroupPhysicalStatePayloadDescriptor_ExtentIdPayloadDescriptor.Marshal(b, m, deterministic)
}
func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor_ExtentIdPayloadDescriptor) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaExtentGroupPhysicalStatePayloadDescriptor_ExtentIdPayloadDescriptor.Merge(m, src)
}
func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor_ExtentIdPayloadDescriptor) XXX_Size() int {
	return xxx_messageInfo_MedusaExtentGroupPhysicalStatePayloadDescriptor_ExtentIdPayloadDescriptor.Size(m)
}
func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor_ExtentIdPayloadDescriptor) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaExtentGroupPhysicalStatePayloadDescriptor_ExtentIdPayloadDescriptor.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaExtentGroupPhysicalStatePayloadDescriptor_ExtentIdPayloadDescriptor proto.InternalMessageInfo

func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor_ExtentIdPayloadDescriptor) GetExtentId() *ExtentIdProto {
	if m != nil {
		return m.ExtentId
	}
	return nil
}

func (m *MedusaExtentGroupPhysicalStatePayloadDescriptor_ExtentIdPayloadDescriptor) GetPayloadLength() int32 {
	if m != nil && m.PayloadLength != nil {
		return *m.PayloadLength
	}
	return 0
}

// Additional metadata logged by the RPC library when writing binary log
// records.
type MedusaBinaryLogRecordMValueMetadata struct {
	// Id of this Medusa value.
	Id *int64 `protobuf:"varint,1,opt,name=id" json:"id,omitempty"`
	// Epoch.
	Epoch *int64 `protobuf:"varint,2,opt,name=epoch" json:"epoch,omitempty"`
	// Timestamp.
	Timestamp *int64 `protobuf:"varint,3,opt,name=timestamp" json:"timestamp,omitempty"`
	// Error Status.
	ErrorStatus *int32 `protobuf:"varint,4,opt,name=error_status,json=errorStatus" json:"error_status,omitempty"`
	// Valid only for lookup requests.
	// Flag indicating where the lookup result is being returned from.
	// True indicates that the value is being returned from cache, false
	// indicates that the value was read from cassandra.
	FromCache            *bool    `protobuf:"varint,5,opt,name=from_cache,json=fromCache" json:"from_cache,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaBinaryLogRecordMValueMetadata) Reset()         { *m = MedusaBinaryLogRecordMValueMetadata{} }
func (m *MedusaBinaryLogRecordMValueMetadata) String() string { return proto.CompactTextString(m) }
func (*MedusaBinaryLogRecordMValueMetadata) ProtoMessage()    {}
func (*MedusaBinaryLogRecordMValueMetadata) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{18}
}

func (m *MedusaBinaryLogRecordMValueMetadata) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaBinaryLogRecordMValueMetadata.Unmarshal(m, b)
}
func (m *MedusaBinaryLogRecordMValueMetadata) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaBinaryLogRecordMValueMetadata.Marshal(b, m, deterministic)
}
func (m *MedusaBinaryLogRecordMValueMetadata) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaBinaryLogRecordMValueMetadata.Merge(m, src)
}
func (m *MedusaBinaryLogRecordMValueMetadata) XXX_Size() int {
	return xxx_messageInfo_MedusaBinaryLogRecordMValueMetadata.Size(m)
}
func (m *MedusaBinaryLogRecordMValueMetadata) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaBinaryLogRecordMValueMetadata.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaBinaryLogRecordMValueMetadata proto.InternalMessageInfo

func (m *MedusaBinaryLogRecordMValueMetadata) GetId() int64 {
	if m != nil && m.Id != nil {
		return *m.Id
	}
	return 0
}

func (m *MedusaBinaryLogRecordMValueMetadata) GetEpoch() int64 {
	if m != nil && m.Epoch != nil {
		return *m.Epoch
	}
	return 0
}

func (m *MedusaBinaryLogRecordMValueMetadata) GetTimestamp() int64 {
	if m != nil && m.Timestamp != nil {
		return *m.Timestamp
	}
	return 0
}

func (m *MedusaBinaryLogRecordMValueMetadata) GetErrorStatus() int32 {
	if m != nil && m.ErrorStatus != nil {
		return *m.ErrorStatus
	}
	return 0
}

func (m *MedusaBinaryLogRecordMValueMetadata) GetFromCache() bool {
	if m != nil && m.FromCache != nil {
		return *m.FromCache
	}
	return false
}

type MedusaBinaryLogRecordMetadata struct {
	// Medusa map that the binary log record corresponds to.
	Type *string `protobuf:"bytes,1,req,name=type" json:"type,omitempty"`
	// Unique Medusa op id for this op.
	OpId *int64 `protobuf:"varint,2,req,name=op_id,json=opId" json:"op_id,omitempty"`
	// Whether this op succeeded or failed.
	OpStatus *bool `protobuf:"varint,3,opt,name=op_status,json=opStatus" json:"op_status,omitempty"`
	// List of mvalues affected by this op.
	Mvalues []*MedusaBinaryLogRecordMValueMetadata `protobuf:"bytes,4,rep,name=mvalues" json:"mvalues,omitempty"`
	// In case of vblock updates, this is the start block number.
	StartBlockNumber *int64 `protobuf:"varint,5,opt,name=start_block_number,json=startBlockNumber" json:"start_block_number,omitempty"`
	// In case of vblock updates, these are all the non contiguous
	// block numbers.
	BlockNumbers         []int64  `protobuf:"varint,6,rep,name=block_numbers,json=blockNumbers" json:"block_numbers,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaBinaryLogRecordMetadata) Reset()         { *m = MedusaBinaryLogRecordMetadata{} }
func (m *MedusaBinaryLogRecordMetadata) String() string { return proto.CompactTextString(m) }
func (*MedusaBinaryLogRecordMetadata) ProtoMessage()    {}
func (*MedusaBinaryLogRecordMetadata) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{19}
}

func (m *MedusaBinaryLogRecordMetadata) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaBinaryLogRecordMetadata.Unmarshal(m, b)
}
func (m *MedusaBinaryLogRecordMetadata) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaBinaryLogRecordMetadata.Marshal(b, m, deterministic)
}
func (m *MedusaBinaryLogRecordMetadata) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaBinaryLogRecordMetadata.Merge(m, src)
}
func (m *MedusaBinaryLogRecordMetadata) XXX_Size() int {
	return xxx_messageInfo_MedusaBinaryLogRecordMetadata.Size(m)
}
func (m *MedusaBinaryLogRecordMetadata) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaBinaryLogRecordMetadata.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaBinaryLogRecordMetadata proto.InternalMessageInfo

func (m *MedusaBinaryLogRecordMetadata) GetType() string {
	if m != nil && m.Type != nil {
		return *m.Type
	}
	return ""
}

func (m *MedusaBinaryLogRecordMetadata) GetOpId() int64 {
	if m != nil && m.OpId != nil {
		return *m.OpId
	}
	return 0
}

func (m *MedusaBinaryLogRecordMetadata) GetOpStatus() bool {
	if m != nil && m.OpStatus != nil {
		return *m.OpStatus
	}
	return false
}

func (m *MedusaBinaryLogRecordMetadata) GetMvalues() []*MedusaBinaryLogRecordMValueMetadata {
	if m != nil {
		return m.Mvalues
	}
	return nil
}

func (m *MedusaBinaryLogRecordMetadata) GetStartBlockNumber() int64 {
	if m != nil && m.StartBlockNumber != nil {
		return *m.StartBlockNumber
	}
	return 0
}

func (m *MedusaBinaryLogRecordMetadata) GetBlockNumbers() []int64 {
	if m != nil {
		return m.BlockNumbers
	}
	return nil
}

type DistributedOplogClientIdProto struct {
	// The unique client type as declared in OplogClientType.
	Type *DistributedOplogClientType `protobuf:"varint,1,opt,name=type,enum=nutanix.medusa.DistributedOplogClientType" json:"type,omitempty"`
	// VDisk identifier for vdisk client.
	VdiskId *int64 `protobuf:"varint,2,opt,name=vdisk_id,json=vdiskId" json:"vdisk_id,omitempty"`
	// Consistency group identifier.
	CgId                 *ConsistencyGroupIdProto `protobuf:"bytes,3,opt,name=cg_id,json=cgId" json:"cg_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                 `json:"-"`
	XXX_unrecognized     []byte                   `json:"-"`
	XXX_sizecache        int32                    `json:"-"`
}

func (m *DistributedOplogClientIdProto) Reset()         { *m = DistributedOplogClientIdProto{} }
func (m *DistributedOplogClientIdProto) String() string { return proto.CompactTextString(m) }
func (*DistributedOplogClientIdProto) ProtoMessage()    {}
func (*DistributedOplogClientIdProto) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{20}
}

func (m *DistributedOplogClientIdProto) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_DistributedOplogClientIdProto.Unmarshal(m, b)
}
func (m *DistributedOplogClientIdProto) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_DistributedOplogClientIdProto.Marshal(b, m, deterministic)
}
func (m *DistributedOplogClientIdProto) XXX_Merge(src proto.Message) {
	xxx_messageInfo_DistributedOplogClientIdProto.Merge(m, src)
}
func (m *DistributedOplogClientIdProto) XXX_Size() int {
	return xxx_messageInfo_DistributedOplogClientIdProto.Size(m)
}
func (m *DistributedOplogClientIdProto) XXX_DiscardUnknown() {
	xxx_messageInfo_DistributedOplogClientIdProto.DiscardUnknown(m)
}

var xxx_messageInfo_DistributedOplogClientIdProto proto.InternalMessageInfo

func (m *DistributedOplogClientIdProto) GetType() DistributedOplogClientType {
	if m != nil && m.Type != nil {
		return *m.Type
	}
	return DistributedOplogClientType_kVDisk
}

func (m *DistributedOplogClientIdProto) GetVdiskId() int64 {
	if m != nil && m.VdiskId != nil {
		return *m.VdiskId
	}
	return 0
}

func (m *DistributedOplogClientIdProto) GetCgId() *ConsistencyGroupIdProto {
	if m != nil {
		return m.CgId
	}
	return nil
}

type MedusaDistributedOplogMapEntryProto struct {
	// A unique id associated with this log instance.
	LogId             *int64                                                  `protobuf:"varint,1,opt,name=log_id,json=logId" json:"log_id,omitempty"`
	RegisteredClients []*MedusaDistributedOplogMapEntryProto_RegisteredClient `protobuf:"bytes,2,rep,name=registered_clients,json=registeredClients" json:"registered_clients,omitempty"`
	Episodes          []*MedusaDistributedOplogMapEntryProto_Episode          `protobuf:"bytes,3,rep,name=episodes" json:"episodes,omitempty"`
	// Highest episode sequence oplog master ever assigned to any episode.
	HighestUsedEpisodeSequence *int64   `protobuf:"varint,4,opt,name=highest_used_episode_sequence,json=highestUsedEpisodeSequence,def=-1" json:"highest_used_episode_sequence,omitempty"`
	XXX_NoUnkeyedLiteral       struct{} `json:"-"`
	XXX_unrecognized           []byte   `json:"-"`
	XXX_sizecache              int32    `json:"-"`
}

func (m *MedusaDistributedOplogMapEntryProto) Reset()         { *m = MedusaDistributedOplogMapEntryProto{} }
func (m *MedusaDistributedOplogMapEntryProto) String() string { return proto.CompactTextString(m) }
func (*MedusaDistributedOplogMapEntryProto) ProtoMessage()    {}
func (*MedusaDistributedOplogMapEntryProto) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{21}
}

func (m *MedusaDistributedOplogMapEntryProto) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaDistributedOplogMapEntryProto.Unmarshal(m, b)
}
func (m *MedusaDistributedOplogMapEntryProto) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaDistributedOplogMapEntryProto.Marshal(b, m, deterministic)
}
func (m *MedusaDistributedOplogMapEntryProto) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaDistributedOplogMapEntryProto.Merge(m, src)
}
func (m *MedusaDistributedOplogMapEntryProto) XXX_Size() int {
	return xxx_messageInfo_MedusaDistributedOplogMapEntryProto.Size(m)
}
func (m *MedusaDistributedOplogMapEntryProto) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaDistributedOplogMapEntryProto.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaDistributedOplogMapEntryProto proto.InternalMessageInfo

const Default_MedusaDistributedOplogMapEntryProto_HighestUsedEpisodeSequence int64 = -1

func (m *MedusaDistributedOplogMapEntryProto) GetLogId() int64 {
	if m != nil && m.LogId != nil {
		return *m.LogId
	}
	return 0
}

func (m *MedusaDistributedOplogMapEntryProto) GetRegisteredClients() []*MedusaDistributedOplogMapEntryProto_RegisteredClient {
	if m != nil {
		return m.RegisteredClients
	}
	return nil
}

func (m *MedusaDistributedOplogMapEntryProto) GetEpisodes() []*MedusaDistributedOplogMapEntryProto_Episode {
	if m != nil {
		return m.Episodes
	}
	return nil
}

func (m *MedusaDistributedOplogMapEntryProto) GetHighestUsedEpisodeSequence() int64 {
	if m != nil && m.HighestUsedEpisodeSequence != nil {
		return *m.HighestUsedEpisodeSequence
	}
	return Default_MedusaDistributedOplogMapEntryProto_HighestUsedEpisodeSequence
}

// Attributes associated with a registered client.
type MedusaDistributedOplogMapEntryProto_RegisteredClient struct {
	// A registered client identifier associated with the log instance.
	ClientId *DistributedOplogClientIdProto `protobuf:"bytes,1,opt,name=client_id,json=clientId" json:"client_id,omitempty"`
	// Lowest record timestamp for the timestamp range tracked by client.
	LowestTrackedLogicalTimestamp []int64 `protobuf:"varint,2,rep,name=lowest_tracked_logical_timestamp,json=lowestTrackedLogicalTimestamp" json:"lowest_tracked_logical_timestamp,omitempty"`
	// Highest record timestamp for the timestamp range tracked by client.
	HighestTrackedLogicalTimestamp []int64 `protobuf:"varint,3,rep,name=highest_tracked_logical_timestamp,json=highestTrackedLogicalTimestamp" json:"highest_tracked_logical_timestamp,omitempty"`
	// Episode sequence housing the record with
	// 'lowest_tracked_logical_timestamp'. This allows oplog store to track
	// the episode bounds of logical timestamp range quicker.
	LowestReferencedEpisodeSequence []int64 `protobuf:"varint,4,rep,name=lowest_referenced_episode_sequence,json=lowestReferencedEpisodeSequence" json:"lowest_referenced_episode_sequence,omitempty"`
	// Episode sequence housing the record with
	// 'highest_tracked_logical_timestamp'. This allows oplog store to track
	// the episode bounds of logical timestamp range quicker.
	HighestReferencedEpisodeSequence []int64 `protobuf:"varint,5,rep,name=highest_referenced_episode_sequence,json=highestReferencedEpisodeSequence" json:"highest_referenced_episode_sequence,omitempty"`
	// A registered client may need a small persistent metadata store for
	// maintaining state or similar information. This field shall be
	// managed by the oplog instance on behalf of its client.
	ClientMetadata       []byte   `protobuf:"bytes,6,opt,name=client_metadata,json=clientMetadata" json:"client_metadata,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaDistributedOplogMapEntryProto_RegisteredClient) Reset() {
	*m = MedusaDistributedOplogMapEntryProto_RegisteredClient{}
}
func (m *MedusaDistributedOplogMapEntryProto_RegisteredClient) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaDistributedOplogMapEntryProto_RegisteredClient) ProtoMessage() {}
func (*MedusaDistributedOplogMapEntryProto_RegisteredClient) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{21, 0}
}

func (m *MedusaDistributedOplogMapEntryProto_RegisteredClient) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaDistributedOplogMapEntryProto_RegisteredClient.Unmarshal(m, b)
}
func (m *MedusaDistributedOplogMapEntryProto_RegisteredClient) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaDistributedOplogMapEntryProto_RegisteredClient.Marshal(b, m, deterministic)
}
func (m *MedusaDistributedOplogMapEntryProto_RegisteredClient) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaDistributedOplogMapEntryProto_RegisteredClient.Merge(m, src)
}
func (m *MedusaDistributedOplogMapEntryProto_RegisteredClient) XXX_Size() int {
	return xxx_messageInfo_MedusaDistributedOplogMapEntryProto_RegisteredClient.Size(m)
}
func (m *MedusaDistributedOplogMapEntryProto_RegisteredClient) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaDistributedOplogMapEntryProto_RegisteredClient.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaDistributedOplogMapEntryProto_RegisteredClient proto.InternalMessageInfo

func (m *MedusaDistributedOplogMapEntryProto_RegisteredClient) GetClientId() *DistributedOplogClientIdProto {
	if m != nil {
		return m.ClientId
	}
	return nil
}

func (m *MedusaDistributedOplogMapEntryProto_RegisteredClient) GetLowestTrackedLogicalTimestamp() []int64 {
	if m != nil {
		return m.LowestTrackedLogicalTimestamp
	}
	return nil
}

func (m *MedusaDistributedOplogMapEntryProto_RegisteredClient) GetHighestTrackedLogicalTimestamp() []int64 {
	if m != nil {
		return m.HighestTrackedLogicalTimestamp
	}
	return nil
}

func (m *MedusaDistributedOplogMapEntryProto_RegisteredClient) GetLowestReferencedEpisodeSequence() []int64 {
	if m != nil {
		return m.LowestReferencedEpisodeSequence
	}
	return nil
}

func (m *MedusaDistributedOplogMapEntryProto_RegisteredClient) GetHighestReferencedEpisodeSequence() []int64 {
	if m != nil {
		return m.HighestReferencedEpisodeSequence
	}
	return nil
}

func (m *MedusaDistributedOplogMapEntryProto_RegisteredClient) GetClientMetadata() []byte {
	if m != nil {
		return m.ClientMetadata
	}
	return nil
}

// Episode metadata that acts like table of contents to track data records
// in distributed oplog store.
type MedusaDistributedOplogMapEntryProto_Episode struct {
	// Unique sequence assigned to this episode. Episode sequences are
	// monotonically increasing. However, consecutive episodes in Medusa may
	// not have consecutive sequences (i.e., at times we may skip adding some
	// episodes to Medusa metadata). This happens when an episode has no valid
	// records.
	EpisodeSequence *int64 `protobuf:"varint,1,opt,name=episode_sequence,json=episodeSequence" json:"episode_sequence,omitempty"`
	// The cluster wide unique id assigned to this episode. This id is used by
	// the oplog store to ensure that the data read from an fallocated file
	// indeed belongs to this episode.
	EpisodeUid *int64                                                      `protobuf:"varint,2,opt,name=episode_uid,json=episodeUid" json:"episode_uid,omitempty"`
	Version    *MedusaDistributedOplogMapEntryProto_Episode_EpisodeVersion `protobuf:"varint,3,opt,name=version,enum=nutanix.medusa.MedusaDistributedOplogMapEntryProto_Episode_EpisodeVersion,def=0" json:"version,omitempty"`
	// The disk ids of the replicas. Depending on the replication factor for
	// the oplog instance, one or more replica shall be set. The first disk at
	// index 0 is the primary disk.
	ReplicaDisks []int64 `protobuf:"varint,4,rep,name=replica_disks,json=replicaDisks" json:"replica_disks,omitempty"`
	// The first record in every episode is given a logical timestamp that is
	// previous episode's highest_episode_logical_timestamp + 1.
	// Thus, any record is uniquely identified by the pair
	// (episode_sequence, logical_timestamp).
	//
	// For verification purposes, every episode other than the latest one also
	// has a logical timestamp that must be found in that episode. This
	// corresponds to the logical timestamp of the latest record that is known
	// to have been committed in that episode. Note that record entries with
	// higher logical timestamps may exist in that episode, but the data in
	// such records may not have been copied to later episodes. This happens
	// when the master recovers from a replica that hasn't written these
	// extra record entries. If on a subsequent recovery the other replica is
	// examined, the master may find these extra record entries. Thus, for
	// every episode other than the latest one, the master recovery should
	// ignore any record entries whose logical timestamp exceeds
	// highest_episode_logical_timestamp (if such records really committed,
	// they'll be found again in the next episode).
	//
	// While recovering, if the records seen do not show all the logical
	// timestamps to this number, then there is some record entry missing
	// from this episode.
	HighestEpisodeLogicalTimestamp *int64 `protobuf:"varint,5,opt,name=highest_episode_logical_timestamp,json=highestEpisodeLogicalTimestamp,def=-1" json:"highest_episode_logical_timestamp,omitempty"`
	// Lowest valid logical timestamp in the episode.
	LowestEpisodeLogicalTimestamp *int64 `protobuf:"varint,6,opt,name=lowest_episode_logical_timestamp,json=lowestEpisodeLogicalTimestamp,def=-1" json:"lowest_episode_logical_timestamp,omitempty"`
	// A tentative episode is one that is temporary in nature. Recovery should
	// not recover from records in a tentative episode. It just serves to
	// indicate that the episode sequence should not be re-used in subsequent
	// master restarts. Once a tentative episode is finalized, all previous
	// tentative episodes will be removed.
	TentativeEpisode *bool `protobuf:"varint,7,opt,name=tentative_episode,json=tentativeEpisode" json:"tentative_episode,omitempty"`
	// The file size of the episode metadata file.
	MetadataFileSize *int64 `protobuf:"varint,8,opt,name=metadata_file_size,json=metadataFileSize" json:"metadata_file_size,omitempty"`
	// The file size of the episide data file.
	DataFileSize *int64 `protobuf:"varint,9,opt,name=data_file_size,json=dataFileSize" json:"data_file_size,omitempty"`
	// The number of records in the episode including commit records (commit
	// records are not assigned a logical timestamp value). Like file sizes,
	// this value is only set on closed episodes.
	RecordCount *int64 `protobuf:"varint,10,opt,name=record_count,json=recordCount" json:"record_count,omitempty"`
	// The transformations applied on the records in this episode. The
	// transformations describe how the original data is morphed into the form
	// that is stored on disk. For example, the transformation may be an
	// identity function, or a number of functions like compression, encryption
	// etc., that are applied one after another. All transformed data records
	// stored in the episode have the same transformation. The order in the
	// repeated field specifies the order in which the transformation types are
	// applied. For example: [kCompressionX, kEncryptionY] means compression X
	// is applied before encryption Y. Note that not all records in the episode
	// need to be transformed especially when the transformation is not
	// required and if it does not yield any significant benefits for example
	// when the only transformation required is compression and when applied,
	// results in negative compression.
	TransformationTypeList []base.DataTransformation_Type `protobuf:"varint,11,rep,name=transformation_type_list,json=transformationTypeList,enum=nutanix.DataTransformation_Type" json:"transformation_type_list,omitempty"`
	// Cipher key UUID used to lookup cipher key in Mantle.
	CipherKeyId []byte `protobuf:"bytes,12,opt,name=cipher_key_id,json=cipherKeyId" json:"cipher_key_id,omitempty"`
	// Adler32 checksum of the cipher key.
	CipherKeyChecksum    *uint32  `protobuf:"varint,13,opt,name=cipher_key_checksum,json=cipherKeyChecksum" json:"cipher_key_checksum,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *MedusaDistributedOplogMapEntryProto_Episode) Reset() {
	*m = MedusaDistributedOplogMapEntryProto_Episode{}
}
func (m *MedusaDistributedOplogMapEntryProto_Episode) String() string {
	return proto.CompactTextString(m)
}
func (*MedusaDistributedOplogMapEntryProto_Episode) ProtoMessage() {}
func (*MedusaDistributedOplogMapEntryProto_Episode) Descriptor() ([]byte, []int) {
	return fileDescriptor_7980e5de23e20f34, []int{21, 1}
}

func (m *MedusaDistributedOplogMapEntryProto_Episode) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_MedusaDistributedOplogMapEntryProto_Episode.Unmarshal(m, b)
}
func (m *MedusaDistributedOplogMapEntryProto_Episode) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_MedusaDistributedOplogMapEntryProto_Episode.Marshal(b, m, deterministic)
}
func (m *MedusaDistributedOplogMapEntryProto_Episode) XXX_Merge(src proto.Message) {
	xxx_messageInfo_MedusaDistributedOplogMapEntryProto_Episode.Merge(m, src)
}
func (m *MedusaDistributedOplogMapEntryProto_Episode) XXX_Size() int {
	return xxx_messageInfo_MedusaDistributedOplogMapEntryProto_Episode.Size(m)
}
func (m *MedusaDistributedOplogMapEntryProto_Episode) XXX_DiscardUnknown() {
	xxx_messageInfo_MedusaDistributedOplogMapEntryProto_Episode.DiscardUnknown(m)
}

var xxx_messageInfo_MedusaDistributedOplogMapEntryProto_Episode proto.InternalMessageInfo

const Default_MedusaDistributedOplogMapEntryProto_Episode_Version MedusaDistributedOplogMapEntryProto_Episode_EpisodeVersion = MedusaDistributedOplogMapEntryProto_Episode_kVersionInitial
const Default_MedusaDistributedOplogMapEntryProto_Episode_HighestEpisodeLogicalTimestamp int64 = -1
const Default_MedusaDistributedOplogMapEntryProto_Episode_LowestEpisodeLogicalTimestamp int64 = -1

func (m *MedusaDistributedOplogMapEntryProto_Episode) GetEpisodeSequence() int64 {
	if m != nil && m.EpisodeSequence != nil {
		return *m.EpisodeSequence
	}
	return 0
}

func (m *MedusaDistributedOplogMapEntryProto_Episode) GetEpisodeUid() int64 {
	if m != nil && m.EpisodeUid != nil {
		return *m.EpisodeUid
	}
	return 0
}

func (m *MedusaDistributedOplogMapEntryProto_Episode) GetVersion() MedusaDistributedOplogMapEntryProto_Episode_EpisodeVersion {
	if m != nil && m.Version != nil {
		return *m.Version
	}
	return Default_MedusaDistributedOplogMapEntryProto_Episode_Version
}

func (m *MedusaDistributedOplogMapEntryProto_Episode) GetReplicaDisks() []int64 {
	if m != nil {
		return m.ReplicaDisks
	}
	return nil
}

func (m *MedusaDistributedOplogMapEntryProto_Episode) GetHighestEpisodeLogicalTimestamp() int64 {
	if m != nil && m.HighestEpisodeLogicalTimestamp != nil {
		return *m.HighestEpisodeLogicalTimestamp
	}
	return Default_MedusaDistributedOplogMapEntryProto_Episode_HighestEpisodeLogicalTimestamp
}

func (m *MedusaDistributedOplogMapEntryProto_Episode) GetLowestEpisodeLogicalTimestamp() int64 {
	if m != nil && m.LowestEpisodeLogicalTimestamp != nil {
		return *m.LowestEpisodeLogicalTimestamp
	}
	return Default_MedusaDistributedOplogMapEntryProto_Episode_LowestEpisodeLogicalTimestamp
}

func (m *MedusaDistributedOplogMapEntryProto_Episode) GetTentativeEpisode() bool {
	if m != nil && m.TentativeEpisode != nil {
		return *m.TentativeEpisode
	}
	return false
}

func (m *MedusaDistributedOplogMapEntryProto_Episode) GetMetadataFileSize() int64 {
	if m != nil && m.MetadataFileSize != nil {
		return *m.MetadataFileSize
	}
	return 0
}

func (m *MedusaDistributedOplogMapEntryProto_Episode) GetDataFileSize() int64 {
	if m != nil && m.DataFileSize != nil {
		return *m.DataFileSize
	}
	return 0
}

func (m *MedusaDistributedOplogMapEntryProto_Episode) GetRecordCount() int64 {
	if m != nil && m.RecordCount != nil {
		return *m.RecordCount
	}
	return 0
}

func (m *MedusaDistributedOplogMapEntryProto_Episode) GetTransformationTypeList() []base.DataTransformation_Type {
	if m != nil {
		return m.TransformationTypeList
	}
	return nil
}

func (m *MedusaDistributedOplogMapEntryProto_Episode) GetCipherKeyId() []byte {
	if m != nil {
		return m.CipherKeyId
	}
	return nil
}

func (m *MedusaDistributedOplogMapEntryProto_Episode) GetCipherKeyChecksum() uint32 {
	if m != nil && m.CipherKeyChecksum != nil {
		return *m.CipherKeyChecksum
	}
	return 0
}

func init() {
	proto.RegisterEnum("nutanix.medusa.OplogEpisodeFileType", OplogEpisodeFileType_name, OplogEpisodeFileType_value)
	proto.RegisterEnum("nutanix.medusa.ConsistencyGroupState", ConsistencyGroupState_name, ConsistencyGroupState_value)
	proto.RegisterEnum("nutanix.medusa.ReplicationState", ReplicationState_name, ReplicationState_value)
	proto.RegisterEnum("nutanix.medusa.EpisodeLinkStoreType", EpisodeLinkStoreType_name, EpisodeLinkStoreType_value)
	proto.RegisterEnum("nutanix.medusa.DistributedOplogClientType", DistributedOplogClientType_name, DistributedOplogClientType_value)
	proto.RegisterEnum("nutanix.medusa.MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason", MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason_name, MedusaExtentGroupIdMapEntryProto_ExtentGroupMigrationReason_value)
	proto.RegisterEnum("nutanix.medusa.MedusaExtentGroupIdMapEntryProto_Replica_Status", MedusaExtentGroupIdMapEntryProto_Replica_Status_name, MedusaExtentGroupIdMapEntryProto_Replica_Status_value)
	proto.RegisterEnum("nutanix.medusa.MedusaExtentGroupIdMapEntryProto_ControlBlock_BooleanProperty", MedusaExtentGroupIdMapEntryProto_ControlBlock_BooleanProperty_name, MedusaExtentGroupIdMapEntryProto_ControlBlock_BooleanProperty_value)
	proto.RegisterEnum("nutanix.medusa.MedusaVDiskOplogMapEntryProto_Episode_EpisodeVersion", MedusaVDiskOplogMapEntryProto_Episode_EpisodeVersion_name, MedusaVDiskOplogMapEntryProto_Episode_EpisodeVersion_value)
	proto.RegisterEnum("nutanix.medusa.Lock_LockType", Lock_LockType_name, Lock_LockType_value)
	proto.RegisterEnum("nutanix.medusa.MedusaNFSAttrProto_SmbOpenState_SmbFileState", MedusaNFSAttrProto_SmbOpenState_SmbFileState_name, MedusaNFSAttrProto_SmbOpenState_SmbFileState_value)
	proto.RegisterEnum("nutanix.medusa.MedusaNearSyncConsistencyGroupMapEntryProto_CGOplogType", MedusaNearSyncConsistencyGroupMapEntryProto_CGOplogType_name, MedusaNearSyncConsistencyGroupMapEntryProto_CGOplogType_value)
	proto.RegisterEnum("nutanix.medusa.MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_AutonomousMode", MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_AutonomousMode_name, MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_AutonomousMode_value)
	proto.RegisterEnum("nutanix.medusa.MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState", MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState_name, MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotState_value)
	proto.RegisterEnum("nutanix.medusa.MedusaNearSyncStagingAreaMapEntryProto_LWSStagingAreaOps", MedusaNearSyncStagingAreaMapEntryProto_LWSStagingAreaOps_name, MedusaNearSyncStagingAreaMapEntryProto_LWSStagingAreaOps_value)
	proto.RegisterEnum("nutanix.medusa.MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage", MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage_name, MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_LWSApplyStage_value)
	proto.RegisterEnum("nutanix.medusa.MedusaDistributedOplogMapEntryProto_Episode_EpisodeVersion", MedusaDistributedOplogMapEntryProto_Episode_EpisodeVersion_name, MedusaDistributedOplogMapEntryProto_Episode_EpisodeVersion_value)
	proto.RegisterType((*MedusaExtentIdMapEntryProto)(nil), "nutanix.medusa.MedusaExtentIdMapEntryProto")
	proto.RegisterType((*MedusaExtentGroupIdMapEntryProto)(nil), "nutanix.medusa.MedusaExtentGroupIdMapEntryProto")
	proto.RegisterType((*MedusaExtentGroupIdMapEntryProto_SliceState)(nil), "nutanix.medusa.MedusaExtentGroupIdMapEntryProto.SliceState")
	proto.RegisterType((*MedusaExtentGroupIdMapEntryProto_SliceStateVec)(nil), "nutanix.medusa.MedusaExtentGroupIdMapEntryProto.SliceStateVec")
	proto.RegisterType((*MedusaExtentGroupIdMapEntryProto_ExtentState)(nil), "nutanix.medusa.MedusaExtentGroupIdMapEntryProto.ExtentState")
	proto.RegisterType((*MedusaExtentGroupIdMapEntryProto_ExtentStateVec)(nil), "nutanix.medusa.MedusaExtentGroupIdMapEntryProto.ExtentStateVec")
	proto.RegisterType((*MedusaExtentGroupIdMapEntryProto_TentativeUpdate)(nil), "nutanix.medusa.MedusaExtentGroupIdMapEntryProto.TentativeUpdate")
	proto.RegisterType((*MedusaExtentGroupIdMapEntryProto_Replica)(nil), "nutanix.medusa.MedusaExtentGroupIdMapEntryProto.Replica")
	proto.RegisterType((*MedusaExtentGroupIdMapEntryProto_ControlBlock)(nil), "nutanix.medusa.MedusaExtentGroupIdMapEntryProto.ControlBlock")
	proto.RegisterType((*MedusaExtentGroupIdMapEntryProto_ControlBlock_EgroupMovementHistory)(nil), "nutanix.medusa.MedusaExtentGroupIdMapEntryProto.ControlBlock.EgroupMovementHistory")
	proto.RegisterType((*MedusaExtentGroupIdMapEntryProto_AccessData)(nil), "nutanix.medusa.MedusaExtentGroupIdMapEntryProto.AccessData")
	proto.RegisterType((*MedusaVDiskOplogMapEntryProto)(nil), "nutanix.medusa.MedusaVDiskOplogMapEntryProto")
	proto.RegisterType((*MedusaVDiskOplogMapEntryProto_Stripe)(nil), "nutanix.medusa.MedusaVDiskOplogMapEntryProto.Stripe")
	proto.RegisterType((*MedusaVDiskOplogMapEntryProto_Episode)(nil), "nutanix.medusa.MedusaVDiskOplogMapEntryProto.Episode")
	proto.RegisterType((*MedusaVDiskOplogMapEntryProto_TentativeUpdate)(nil), "nutanix.medusa.MedusaVDiskOplogMapEntryProto.TentativeUpdate")
	proto.RegisterType((*MedusaVDiskOplogMapEntryProto_StretchedState)(nil), "nutanix.medusa.MedusaVDiskOplogMapEntryProto.StretchedState")
	proto.RegisterType((*MedusaVDiskOplogMapEntryProto_StretchedState_DrainedEpisodeRecordMetadata)(nil), "nutanix.medusa.MedusaVDiskOplogMapEntryProto.StretchedState.DrainedEpisodeRecordMetadata")
	proto.RegisterType((*MedusaVDiskOplogMapEntryProto_NearSyncState)(nil), "nutanix.medusa.MedusaVDiskOplogMapEntryProto.NearSyncState")
	proto.RegisterType((*MedusaVDiskOplogMapEntryProto_LwsApplyTentativeUpdate)(nil), "nutanix.medusa.MedusaVDiskOplogMapEntryProto.LwsApplyTentativeUpdate")
	proto.RegisterType((*Lock)(nil), "nutanix.medusa.Lock")
	proto.RegisterType((*Lock_ByteRange)(nil), "nutanix.medusa.Lock.ByteRange")
	proto.RegisterType((*IscsiMetadata)(nil), "nutanix.medusa.IscsiMetadata")
	proto.RegisterType((*SmbMetadata)(nil), "nutanix.medusa.SmbMetadata")
	proto.RegisterType((*MedusaNFSAttrProto)(nil), "nutanix.medusa.MedusaNFSAttrProto")
	proto.RegisterType((*MedusaNFSAttrProto_SmbOpenState)(nil), "nutanix.medusa.MedusaNFSAttrProto.SmbOpenState")
	proto.RegisterType((*MedusaNFSAttrProto_SmbOpenState_SmbOpenData)(nil), "nutanix.medusa.MedusaNFSAttrProto.SmbOpenState.SmbOpenData")
	proto.RegisterType((*MedusaNFSDataShardProto)(nil), "nutanix.medusa.MedusaNFSDataShardProto")
	proto.RegisterType((*MedusaNFSMapEntryProto)(nil), "nutanix.medusa.MedusaNFSMapEntryProto")
	proto.RegisterType((*MedusaSmbFileIdMapEntryProto)(nil), "nutanix.medusa.MedusaSmbFileIdMapEntryProto")
	proto.RegisterType((*MedusaSmbFileIdMapEntryProto_SharedVirtualDiskOpen)(nil), "nutanix.medusa.MedusaSmbFileIdMapEntryProto.SharedVirtualDiskOpen")
	proto.RegisterType((*SnapshotRequestIdentifier)(nil), "nutanix.medusa.SnapshotRequestIdentifier")
	proto.RegisterType((*SnapshotInfo)(nil), "nutanix.medusa.SnapshotInfo")
	proto.RegisterType((*SnapshotInfo_FileInfo)(nil), "nutanix.medusa.SnapshotInfo.FileInfo")
	proto.RegisterType((*MedusaNearSyncConsistencyGroupMapEntryProto)(nil), "nutanix.medusa.MedusaNearSyncConsistencyGroupMapEntryProto")
	proto.RegisterType((*MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState)(nil), "nutanix.medusa.MedusaNearSyncConsistencyGroupMapEntryProto.RemoteReplicationState")
	proto.RegisterType((*MedusaNearSyncConsistencyGroupMapEntryProto_RemoteReplicationState_FileReplicationState)(nil), "nutanix.medusa.MedusaNearSyncConsistencyGroupMapEntryProto.RemoteReplicationState.FileReplicationState")
	proto.RegisterType((*MedusaNearSyncConsistencyGroupMapEntryProto_OplogTransferState)(nil), "nutanix.medusa.MedusaNearSyncConsistencyGroupMapEntryProto.OplogTransferState")
	proto.RegisterType((*MedusaNearSyncConsistencyGroupMapEntryProto_OplogReplicationState)(nil), "nutanix.medusa.MedusaNearSyncConsistencyGroupMapEntryProto.OplogReplicationState")
	proto.RegisterType((*MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig)(nil), "nutanix.medusa.MedusaNearSyncConsistencyGroupMapEntryProto.ConsistencyGroupConfig")
	proto.RegisterType((*MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_ValidationFileInfo)(nil), "nutanix.medusa.MedusaNearSyncConsistencyGroupMapEntryProto.ConsistencyGroupConfig.ValidationFileInfo")
	proto.RegisterType((*MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState)(nil), "nutanix.medusa.MedusaNearSyncConsistencyGroupMapEntryProto.ConsistencyGroupConfig.HydrationState")
	proto.RegisterType((*MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotStateInfo)(nil), "nutanix.medusa.MedusaNearSyncConsistencyGroupMapEntryProto.ConsistencyGroupConfig.HydrationState.SnapshotStateInfo")
	proto.RegisterType((*MedusaNearSyncConsistencyGroupMapEntryProto_ConsistencyGroupConfig_HydrationState_SnapshotSeedingInfo)(nil), "nutanix.medusa.MedusaNearSyncConsistencyGroupMapEntryProto.ConsistencyGroupConfig.HydrationState.SnapshotSeedingInfo")
	proto.RegisterType((*MedusaNearSyncConsistencyGroupMapEntryProto_ControlPlaneSnapshotMapping)(nil), "nutanix.medusa.MedusaNearSyncConsistencyGroupMapEntryProto.ControlPlaneSnapshotMapping")
	proto.RegisterType((*MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping)(nil), "nutanix.medusa.MedusaNearSyncConsistencyGroupMapEntryProto.RemoteContainerMapping")
	proto.RegisterType((*MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_FileContainerMapping)(nil), "nutanix.medusa.MedusaNearSyncConsistencyGroupMapEntryProto.RemoteContainerMapping.FileContainerMapping")
	proto.RegisterType((*MedusaNearSyncConsistencyGroupMapEntryProto_RemoteContainerMapping_VDiskContainerMapping)(nil), "nutanix.medusa.MedusaNearSyncConsistencyGroupMapEntryProto.RemoteContainerMapping.VDiskContainerMapping")
	proto.RegisterType((*MedusaNearSyncConsistencyGroupMapEntryProto_OplogRegistration)(nil), "nutanix.medusa.MedusaNearSyncConsistencyGroupMapEntryProto.OplogRegistration")
	proto.RegisterType((*MedusaNearSyncOplogMapEntryProto)(nil), "nutanix.medusa.MedusaNearSyncOplogMapEntryProto")
	proto.RegisterType((*MedusaNearSyncOplogMapEntryProto_Oplog)(nil), "nutanix.medusa.MedusaNearSyncOplogMapEntryProto.Oplog")
	proto.RegisterType((*MedusaNearSyncOplogMapEntryProto_Oplog_TentativePruneUpdate)(nil), "nutanix.medusa.MedusaNearSyncOplogMapEntryProto.Oplog.TentativePruneUpdate")
	proto.RegisterType((*MedusaNearSyncLWSMapEntryProto)(nil), "nutanix.medusa.MedusaNearSyncLWSMapEntryProto")
	proto.RegisterType((*MedusaNearSyncStagingAreaMapEntryProto)(nil), "nutanix.medusa.MedusaNearSyncStagingAreaMapEntryProto")
	proto.RegisterType((*MedusaNearSyncStagingAreaMapEntryProto_ContainerNameToContainerId)(nil), "nutanix.medusa.MedusaNearSyncStagingAreaMapEntryProto.ContainerNameToContainerId")
	proto.RegisterType((*MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState)(nil), "nutanix.medusa.MedusaNearSyncStagingAreaMapEntryProto.ApplyOpState")
	proto.RegisterType((*MedusaNearSyncStagingAreaMapEntryProto_ApplyOpState_FileRenameState)(nil), "nutanix.medusa.MedusaNearSyncStagingAreaMapEntryProto.ApplyOpState.FileRenameState")
	proto.RegisterType((*MedusaNearSyncEpisodeLinkMapEntryProto)(nil), "nutanix.medusa.MedusaNearSyncEpisodeLinkMapEntryProto")
	proto.RegisterType((*MedusaNearSyncEpisodeLinkMapEntryProto_LinkEntry)(nil), "nutanix.medusa.MedusaNearSyncEpisodeLinkMapEntryProto.LinkEntry")
	proto.RegisterType((*MedusaExtentGroupPhysicalStatePayloadDescriptor)(nil), "nutanix.medusa.MedusaExtentGroupPhysicalStatePayloadDescriptor")
	proto.RegisterType((*MedusaExtentGroupPhysicalStatePayloadDescriptor_SliceGroupPayloadDescriptor)(nil), "nutanix.medusa.MedusaExtentGroupPhysicalStatePayloadDescriptor.SliceGroupPayloadDescriptor")
	proto.RegisterType((*MedusaExtentGroupPhysicalStatePayloadDescriptor_ExtentIdPayloadDescriptor)(nil), "nutanix.medusa.MedusaExtentGroupPhysicalStatePayloadDescriptor.ExtentIdPayloadDescriptor")
	proto.RegisterType((*MedusaBinaryLogRecordMValueMetadata)(nil), "nutanix.medusa.MedusaBinaryLogRecordMValueMetadata")
	proto.RegisterType((*MedusaBinaryLogRecordMetadata)(nil), "nutanix.medusa.MedusaBinaryLogRecordMetadata")
	proto.RegisterType((*DistributedOplogClientIdProto)(nil), "nutanix.medusa.DistributedOplogClientIdProto")
	proto.RegisterType((*MedusaDistributedOplogMapEntryProto)(nil), "nutanix.medusa.MedusaDistributedOplogMapEntryProto")
	proto.RegisterType((*MedusaDistributedOplogMapEntryProto_RegisteredClient)(nil), "nutanix.medusa.MedusaDistributedOplogMapEntryProto.RegisteredClient")
	proto.RegisterType((*MedusaDistributedOplogMapEntryProto_Episode)(nil), "nutanix.medusa.MedusaDistributedOplogMapEntryProto.Episode")
}

func init() { proto.RegisterFile("medusa/medusa.proto", fileDescriptor_7980e5de23e20f34) }

var fileDescriptor_7980e5de23e20f34 = []byte{
	// 8856 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0xcc, 0x7d, 0x5b, 0x8c, 0x1c, 0x59,
	0x96, 0x50, 0x67, 0xd6, 0xfb, 0xe4, 0xa3, 0xb2, 0x6e, 0xbd, 0xb2, 0xb2, 0x6c, 0xb7, 0x9d, 0xb6,
	0xbb, 0xdd, 0x9e, 0xee, 0xf2, 0x74, 0xcd, 0xbb, 0xdc, 0xd3, 0xb3, 0x76, 0x95, 0x1f, 0x35, 0xed,
	0xb2, 0x3d, 0x51, 0xb6, 0x5b, 0x33, 0xac, 0x36, 0x88, 0x8a, 0xb8, 0x99, 0x15, 0x54, 0x64, 0x44,
	0x6e, 0xdc, 0xc8, 0x2a, 0x57, 0xa3, 0xdd, 0x65, 0x40, 0x68, 0x79, 0x0c, 0x42, 0x20, 0xd8, 0x05,
	0xf1, 0x5c, 0x09, 0xad, 0x90, 0xf8, 0x01, 0x21, 0xc4, 0x7c, 0xf2, 0x85, 0x10, 0x1f, 0xfc, 0xf1,
	0x85, 0xe0, 0x07, 0xbe, 0x58, 0x09, 0xbe, 0x90, 0x56, 0x2c, 0x48, 0xe8, 0x9e, 0x73, 0xef, 0x8d,
	0x47, 0x66, 0x56, 0xf9, 0xd5, 0xcb, 0xfe, 0xd8, 0x19, 0xe7, 0x9c, 0x7b, 0xee, 0xfb, 0xbc, 0xee,
	0xb9, 0xb7, 0x60, 0xb1, 0xc7, 0xbd, 0x81, 0x70, 0x6e, 0xd1, 0x7f, 0x1b, 0xfd, 0x38, 0x4a, 0x22,
	0x56, 0x0f, 0x07, 0x89, 0x13, 0xfa, 0x2f, 0x37, 0x08, 0xda, 0xba, 0xa2, 0x88, 0xdc, 0x28, 0x14,
	0xbe, 0x48, 0x78, 0xe8, 0x9e, 0xda, 0xdd, 0x38, 0x1a, 0xf4, 0x6d, 0xdf, 0xa3, 0x22, 0xad, 0x15,
	0x45, 0xc2, 0x5f, 0x26, 0x3c, 0x4c, 0x52, 0xb8, 0xe6, 0x1f, 0x9c, 0x88, 0x14, 0xb8, 0x96, 0x01,
	0xf6, 0x78, 0xe2, 0x78, 0x4e, 0xe2, 0x14, 0x50, 0x61, 0x47, 0xd8, 0x7e, 0x18, 0x79, 0x3c, 0x2d,
	0x75, 0x41, 0xa1, 0x8e, 0x3d, 0x5f, 0x1c, 0xd9, 0x07, 0x41, 0xe4, 0x1e, 0xd9, 0x3d, 0xa7, 0xaf,
	0xb0, 0xeb, 0x7d, 0x3f, 0x39, 0x8c, 0xc4, 0x2d, 0x91, 0xc4, 0x3c, 0x71, 0x0f, 0xed, 0xbe, 0x13,
	0x3b, 0x3d, 0xa1, 0x90, 0xdf, 0x1c, 0x24, 0x7e, 0x70, 0x4b, 0x04, 0xf6, 0xc1, 0xa0, 0x23, 0x6e,
	0x1d, 0x38, 0x82, 0xdf, 0x92, 0x75, 0xda, 0x49, 0xec, 0x84, 0xa2, 0x13, 0xc5, 0x3d, 0x27, 0xf1,
	0xa3, 0xd0, 0x4e, 0x4e, 0xfb, 0x5c, 0x95, 0x68, 0xe7, 0x4a, 0x84, 0x3c, 0xb9, 0x85, 0xf5, 0xb9,
	0x81, 0xcf, 0xc3, 0x44, 0xd1, 0xd4, 0xbf, 0xe2, 0x03, 0x21, 0xe1, 0xf4, 0xdd, 0xfe, 0x9f, 0x25,
	0x58, 0xdf, 0xc3, 0x36, 0xde, 0xc3, 0x51, 0xd8, 0xf5, 0xf6, 0x9c, 0xfe, 0xbd, 0x30, 0x89, 0x4f,
	0x9f, 0xe2, 0xb0, 0xde, 0x84, 0x79, 0x35, 0x3c, 0x7a, 0xf0, 0x9a, 0xa5, 0xcb, 0xa5, 0x1b, 0x13,
	0x5b, 0xe5, 0x4f, 0x3e, 0xb5, 0x6a, 0x84, 0x7a, 0x20, 0x31, 0xbb, 0x1e, 0xfb, 0x1e, 0x4c, 0x06,
	0x91, 0x2b, 0x9a, 0xe5, 0xcb, 0x13, 0x37, 0x2a, 0x9b, 0x57, 0x37, 0xf4, 0x8c, 0xc8, 0x2a, 0x37,
	0x1e, 0x45, 0x5d, 0xdf, 0x75, 0x82, 0x27, 0x7d, 0x1e, 0x63, 0xc3, 0xb7, 0x65, 0xdb, 0x2c, 0x2c,
	0xc0, 0xd6, 0x61, 0x2e, 0x89, 0x6c, 0x8f, 0x07, 0x3c, 0xe1, 0xcd, 0x89, 0xcb, 0xa5, 0x1b, 0xb3,
	0xd6, 0x6c, 0x12, 0xed, 0xe0, 0x37, 0x7b, 0x0c, 0x33, 0x31, 0xef, 0xfa, 0x51, 0x28, 0x9a, 0x93,
	0xc8, 0xf8, 0xdb, 0x1b, 0xf9, 0xa9, 0xde, 0xa0, 0xf6, 0xbf, 0xd8, 0xf1, 0xc5, 0xd1, 0x5d, 0xc9,
	0x35, 0xd7, 0x83, 0x0d, 0x0b, 0x0b, 0x5b, 0x9a, 0x49, 0xfb, 0xf7, 0x6f, 0xc2, 0xe5, 0x6c, 0x8f,
	0x55, 0xeb, 0xf3, 0xdd, 0x3e, 0x80, 0x9a, 0x1b, 0x85, 0x49, 0x1c, 0x05, 0x34, 0x69, 0xd8, 0xe9,
	0xca, 0xe6, 0x0f, 0x47, 0x57, 0x3d, 0x9e, 0xd1, 0xc6, 0x36, 0x71, 0xc1, 0x76, 0x59, 0x55, 0x37,
	0xf3, 0xc5, 0x5e, 0xc0, 0x0c, 0x8d, 0x9f, 0x1e, 0xb1, 0xcf, 0x5e, 0x9b, 0x3b, 0xa1, 0xf6, 0x13,
	0x27, 0xe1, 0x96, 0x66, 0xc6, 0xf6, 0x61, 0x5a, 0x04, 0xbe, 0xcb, 0x45, 0x73, 0x02, 0xd9, 0xde,
	0x7e, 0x6d, 0xb6, 0xfb, 0xb2, 0x38, 0x71, 0x55, 0xac, 0x5a, 0xff, 0xa3, 0x0c, 0x90, 0x82, 0xd9,
	0x1a, 0xcc, 0x22, 0x82, 0xd6, 0x43, 0xf9, 0xc6, 0x94, 0x35, 0x83, 0xdf, 0xbb, 0x1e, 0xfb, 0x14,
	0x96, 0x06, 0xa1, 0x59, 0xa4, 0xdc, 0xb3, 0x03, 0x1e, 0x76, 0x93, 0xc3, 0x66, 0xf9, 0x72, 0xe9,
	0xc6, 0x94, 0xb5, 0x98, 0xc3, 0x3d, 0x42, 0x14, 0xdb, 0x80, 0xc5, 0xdc, 0x22, 0x8b, 0x3a, 0x1d,
	0xc1, 0x13, 0x5c, 0x09, 0x53, 0xd6, 0x42, 0x66, 0x91, 0x3d, 0x41, 0x04, 0xfb, 0x04, 0xd8, 0x88,
	0x0a, 0x26, 0x89, 0x7c, 0x98, 0x7d, 0x13, 0x66, 0xdc, 0x81, 0x38, 0xf4, 0xa3, 0xb0, 0x39, 0x85,
	0x34, 0xfa, 0x93, 0xb5, 0x60, 0xd6, 0x3d, 0xe4, 0xee, 0x91, 0x18, 0xf4, 0x9a, 0xd3, 0x97, 0x27,
	0x6e, 0xd4, 0x2c, 0xf3, 0xcd, 0xda, 0x50, 0xed, 0xf8, 0x61, 0x97, 0xc7, 0xfd, 0xd8, 0x97, 0x73,
	0x34, 0x73, 0xb9, 0x74, 0xa3, 0x6a, 0xe5, 0x60, 0xec, 0x23, 0x68, 0x04, 0xb4, 0xae, 0x6d, 0xc3,
	0x67, 0x16, 0xf9, 0xcc, 0x2b, 0xf8, 0xb6, 0x66, 0xb7, 0x01, 0x8b, 0x3d, 0x27, 0x3e, 0xe2, 0x9e,
	0xdd, 0x89, 0x62, 0x5a, 0xeb, 0xb2, 0x41, 0x73, 0xb8, 0xda, 0x17, 0x08, 0x75, 0x3f, 0x8a, 0x77,
	0x14, 0xa2, 0xe5, 0x41, 0x2d, 0x1d, 0xef, 0x17, 0xdc, 0xcd, 0x4c, 0x6b, 0xe9, 0xdd, 0x4d, 0xeb,
	0x7f, 0x2b, 0x43, 0x25, 0xb3, 0x88, 0xd8, 0x16, 0xcc, 0x19, 0x69, 0xa8, 0xd6, 0xfc, 0xc5, 0x62,
	0x3d, 0x5a, 0x50, 0x20, 0x53, 0x6b, 0x96, 0xab, 0x4f, 0xb9, 0x8b, 0xf5, 0x9a, 0xa0, 0x15, 0x3d,
	0x65, 0xcd, 0xaa, 0x45, 0x21, 0xd8, 0xc7, 0xc0, 0x3a, 0x7e, 0x2c, 0x12, 0x9b, 0x48, 0x72, 0x33,
	0xdc, 0x40, 0x0c, 0xb6, 0x4e, 0x4d, 0xf0, 0x45, 0x98, 0x8d, 0x79, 0xc7, 0x8d, 0x06, 0x61, 0x42,
	0xd3, 0xba, 0x55, 0xfa, 0xd4, 0x32, 0x20, 0xb6, 0x05, 0x6b, 0x83, 0xd0, 0x09, 0x82, 0xc8, 0x75,
	0x12, 0xee, 0x11, 0x4b, 0x61, 0x1f, 0xf8, 0x89, 0xe4, 0x29, 0xa7, 0x78, 0xd2, 0x5a, 0xcd, 0x10,
	0x20, 0x67, 0x71, 0x17, 0xd1, 0xec, 0x2a, 0xd4, 0x54, 0x2b, 0x43, 0x0f, 0x47, 0x73, 0x1a, 0x5b,
	0x5a, 0xa5, 0x96, 0x12, 0x2c, 0x2b, 0x73, 0x66, 0xde, 0x81, 0xcc, 0x69, 0x1d, 0x42, 0x3d, 0x33,
	0xca, 0x72, 0x36, 0x33, 0x9b, 0xbf, 0xf4, 0x0e, 0x37, 0x7f, 0xeb, 0x77, 0x01, 0xe6, 0x9f, 0xf1,
	0x30, 0x71, 0x12, 0xff, 0x98, 0x3f, 0xef, 0x7b, 0x72, 0x52, 0x3f, 0x84, 0x79, 0x3f, 0xc4, 0x49,
	0x15, 0xfc, 0xd7, 0x07, 0x3c, 0x74, 0x39, 0xee, 0xd9, 0x09, 0xab, 0x4e, 0xe0, 0x7d, 0x05, 0xcd,
	0xcf, 0x3e, 0xc9, 0xa4, 0x57, 0x9e, 0xfd, 0x56, 0x66, 0xca, 0x26, 0x68, 0xf2, 0xcd, 0x7c, 0xdd,
	0x81, 0x4b, 0xbd, 0xe8, 0x98, 0xdb, 0x9c, 0xb6, 0x77, 0xcf, 0xe9, 0xf7, 0xfd, 0xb0, 0x6b, 0x27,
	0x91, 0xcd, 0x7d, 0x4f, 0x7e, 0xe2, 0x24, 0xcf, 0x5a, 0x6b, 0x92, 0xea, 0x1e, 0x12, 0xed, 0x11,
	0xcd, 0xb3, 0xe8, 0x9e, 0x2f, 0xbb, 0xcd, 0x6e, 0x43, 0x2b, 0xe6, 0xfd, 0xc0, 0x77, 0x49, 0xeb,
	0x89, 0x68, 0x10, 0xbb, 0xdc, 0x46, 0xad, 0xea, 0x7b, 0x38, 0xe7, 0x13, 0xd6, 0x6a, 0x86, 0x62,
	0x1f, 0x09, 0xe4, 0xf4, 0xec, 0x7a, 0xec, 0x3b, 0xb0, 0xca, 0x63, 0x47, 0x0c, 0x62, 0x6e, 0x2b,
	0x12, 0x53, 0x52, 0xce, 0xfe, 0x84, 0xb5, 0xa4, 0xd0, 0x16, 0x61, 0x55, 0xb1, 0x3b, 0x70, 0x31,
	0x5b, 0xcc, 0x71, 0x79, 0x4f, 0x8e, 0x0d, 0x37, 0x9a, 0x70, 0x06, 0xab, 0x6d, 0x65, 0x0a, 0x2b,
	0x1a, 0xea, 0xc3, 0xae, 0xc7, 0xbe, 0x84, 0x8f, 0x46, 0xb1, 0x88, 0x02, 0x4f, 0x2a, 0x7b, 0x3f,
	0x39, 0x4d, 0xb9, 0x09, 0x94, 0x1c, 0x13, 0xd6, 0xb5, 0x61, 0x76, 0x4f, 0x02, 0xef, 0x29, 0x52,
	0x6b, 0xbe, 0x82, 0xfd, 0x0a, 0x5c, 0x18, 0xc5, 0xb8, 0x1f, 0x09, 0xdf, 0xc8, 0x95, 0xa9, 0x51,
	0x4d, 0x7b, 0xaa, 0x28, 0xd8, 0x37, 0x41, 0xf7, 0x5a, 0x69, 0x5e, 0x5b, 0x24, 0xb1, 0xdf, 0x6f,
	0x02, 0x4e, 0x05, 0x53, 0x38, 0x52, 0xc2, 0xfb, 0x12, 0x23, 0xd7, 0x91, 0x2e, 0x31, 0x08, 0x89,
	0xb8, 0x82, 0xc4, 0x75, 0x05, 0x7e, 0x4e, 0x50, 0x76, 0x1d, 0xea, 0x29, 0x6b, 0x37, 0xf2, 0x78,
	0xb3, 0x8a, 0x74, 0x35, 0xc3, 0x54, 0x02, 0xb3, 0x64, 0x31, 0x91, 0xd5, 0x72, 0x64, 0x16, 0x91,
	0x7d, 0x06, 0xeb, 0x21, 0x3f, 0xb1, 0x35, 0x29, 0x56, 0x61, 0x0b, 0xff, 0x2b, 0xb9, 0x85, 0x3b,
	0x51, 0xb3, 0x8e, 0x3d, 0x5d, 0x0d, 0xf9, 0xc9, 0x3d, 0xa2, 0xc0, 0xc6, 0xee, 0xfb, 0x5f, 0xf1,
	0xdd, 0xb0, 0x13, 0xb1, 0x4f, 0x61, 0x59, 0x96, 0x1e, 0x1e, 0xed, 0x79, 0x1c, 0x6d, 0x16, 0xf2,
	0x93, 0xe2, 0xd8, 0xde, 0x86, 0xf5, 0x24, 0xb2, 0x63, 0x8e, 0x6b, 0x36, 0x8a, 0x6d, 0xc7, 0xf3,
	0xb2, 0x05, 0x1b, 0x58, 0x70, 0x25, 0x89, 0x2c, 0xa4, 0x78, 0x12, 0xdf, 0xf1, 0xbc, 0xb4, 0xf0,
	0x1e, 0x5c, 0xcb, 0x77, 0x6a, 0xcc, 0x64, 0x2f, 0x20, 0x97, 0xf7, 0x73, 0x5d, 0x1d, 0x31, 0xcf,
	0x99, 0x35, 0x18, 0x1d, 0xf3, 0xf8, 0x24, 0xf6, 0x13, 0xea, 0xb7, 0xe2, 0xd5, 0x64, 0xb9, 0x35,
	0xf8, 0x44, 0xd3, 0xc8, 0xbe, 0x13, 0x17, 0x76, 0x0f, 0xde, 0x57, 0xf5, 0x7a, 0x5c, 0xf8, 0x31,
	0xf7, 0xec, 0x82, 0x34, 0x10, 0xcd, 0x45, 0x6c, 0xcc, 0x05, 0x22, 0xdb, 0x21, 0xaa, 0xdd, 0x9c,
	0x6c, 0x10, 0x19, 0x36, 0xee, 0x20, 0x8e, 0x51, 0x48, 0x14, 0xd9, 0x2c, 0x65, 0xd9, 0x6c, 0x13,
	0x55, 0x91, 0xcd, 0x67, 0xb0, 0xae, 0xc6, 0x45, 0x0e, 0xab, 0x9c, 0x9a, 0x4c, 0x6f, 0x44, 0x73,
	0x19, 0x57, 0xc0, 0x2a, 0x91, 0xdc, 0xf1, 0xbc, 0xc7, 0xfc, 0x24, 0xed, 0x8a, 0x60, 0x3f, 0x80,
	0x35, 0xde, 0x25, 0x99, 0x61, 0x7b, 0xdc, 0x1b, 0xf4, 0xed, 0x7e, 0x1c, 0xb9, 0x5c, 0x08, 0x3f,
	0xec, 0x36, 0x57, 0xb0, 0xec, 0x8a, 0x24, 0xd8, 0x73, 0xfa, 0x3b, 0x12, 0xfd, 0xd4, 0x60, 0x5b,
	0x7f, 0x6b, 0x12, 0x66, 0xd4, 0xfe, 0x66, 0xdf, 0x18, 0x25, 0x11, 0xb5, 0x55, 0x5b, 0x94, 0x8a,
	0xab, 0x30, 0xa3, 0xa5, 0x45, 0x19, 0xc5, 0xe6, 0xb4, 0x47, 0xf2, 0xa1, 0x07, 0x0b, 0x89, 0x16,
	0xb5, 0xf6, 0x00, 0x65, 0xad, 0xb6, 0xb9, 0x7e, 0xe5, 0xb5, 0xa5, 0x79, 0x41, 0x68, 0x5b, 0x8d,
	0x24, 0x0f, 0x10, 0xec, 0x57, 0xa1, 0xe2, 0xf9, 0x9d, 0x8e, 0x52, 0x77, 0xca, 0x18, 0x7e, 0x2b,
	0x2b, 0x00, 0x24, 0x3f, 0xd2, 0x8e, 0xcc, 0x86, 0x2a, 0x72, 0xd7, 0x5a, 0x69, 0xea, 0x1d, 0x68,
	0x25, 0x6c, 0xef, 0x3d, 0x65, 0x96, 0x3a, 0x30, 0x2d, 0x12, 0x27, 0x19, 0x48, 0x8d, 0x5b, 0xba,
	0x51, 0xdf, 0xfc, 0xd1, 0x6b, 0xb3, 0x56, 0xb3, 0xb7, 0xb1, 0x8f, 0x6c, 0xb6, 0x66, 0x8f, 0x1e,
	0x72, 0x27, 0x48, 0x0e, 0x4f, 0x2d, 0xc5, 0xb8, 0xbd, 0x09, 0xd3, 0x84, 0x63, 0x55, 0x30, 0xd8,
	0xc6, 0x7b, 0xf8, 0xb5, 0x1d, 0xc5, 0xf1, 0xa0, 0x9f, 0x34, 0x4a, 0xf8, 0xb5, 0xe7, 0xe3, 0xa2,
	0x68, 0x94, 0x5b, 0xff, 0x72, 0x1e, 0xaa, 0x59, 0x23, 0x9d, 0x5d, 0x83, 0x7a, 0x74, 0x12, 0xf2,
	0xd8, 0x3e, 0xd6, 0xb3, 0x4e, 0xca, 0xb2, 0x8a, 0xd0, 0x17, 0x6a, 0xee, 0x6f, 0xc1, 0xe2, 0x08,
	0x47, 0x0c, 0x8d, 0xdc, 0x39, 0x8b, 0xe5, 0x51, 0xcf, 0x4e, 0xfb, 0x9c, 0x3d, 0x93, 0xfa, 0x11,
	0xdb, 0xaf, 0xd7, 0xc8, 0xf7, 0xdf, 0x74, 0x00, 0x2c, 0xc3, 0x89, 0x7d, 0x1b, 0x56, 0x02, 0xb9,
	0x38, 0x86, 0x36, 0x63, 0x73, 0x12, 0x1b, 0xbd, 0x44, 0xd8, 0xfc, 0x26, 0x34, 0x8e, 0xda, 0xd4,
	0xeb, 0x3a, 0x6a, 0x77, 0xe0, 0x62, 0x71, 0xc5, 0xdb, 0x6e, 0xd4, 0xeb, 0x47, 0xa1, 0x32, 0x1a,
	0xa6, 0x49, 0x1a, 0x15, 0xd6, 0xee, 0xb6, 0x26, 0xd9, 0xf5, 0xa4, 0x18, 0x19, 0x62, 0xe1, 0x87,
	0xae, 0x13, 0x87, 0x34, 0x8c, 0x46, 0xad, 0x5e, 0x28, 0x30, 0xd9, 0x4d, 0x89, 0x76, 0x3d, 0x76,
	0x04, 0x8d, 0x22, 0x9b, 0xe6, 0x2c, 0xda, 0xab, 0x6f, 0xbf, 0xf5, 0xe6, 0x0b, 0x35, 0xb3, 0xef,
	0x41, 0xd3, 0x0f, 0x7a, 0x76, 0xcf, 0xef, 0xc6, 0x6a, 0xae, 0xfd, 0x1e, 0xb7, 0x07, 0x82, 0xbb,
	0x02, 0x15, 0xed, 0x84, 0xb5, 0xec, 0x07, 0xbd, 0x3d, 0x8d, 0x7e, 0xe6, 0xf7, 0xf8, 0x73, 0x89,
	0x94, 0x56, 0x2f, 0xad, 0x25, 0xe9, 0xf8, 0x39, 0xbe, 0xfc, 0xe5, 0x7b, 0x4d, 0xc0, 0xa9, 0x69,
	0x20, 0x66, 0x5b, 0x23, 0x76, 0x3d, 0xf6, 0x10, 0xae, 0x84, 0xfc, 0xa5, 0x36, 0x91, 0x95, 0xf9,
	0x2a, 0xab, 0x23, 0x6b, 0xd9, 0x3e, 0xf4, 0xc3, 0x04, 0x35, 0xee, 0x94, 0x75, 0x51, 0x12, 0xe2,
	0xce, 0xbd, 0x63, 0xc8, 0xc8, 0x76, 0x7e, 0xe8, 0x87, 0x09, 0xfb, 0x29, 0xdc, 0x3c, 0x38, 0x4d,
	0xb8, 0x90, 0x26, 0x16, 0xa9, 0x8c, 0x03, 0xde, 0x89, 0x50, 0x25, 0x25, 0xf1, 0xa9, 0xb4, 0xbd,
	0xe4, 0xac, 0xc5, 0x52, 0x32, 0x46, 0x21, 0x2a, 0xe7, 0x29, 0xeb, 0x3a, 0x96, 0x78, 0x16, 0x7d,
	0x29, 0xe9, 0xef, 0x22, 0xb9, 0xa5, 0xa8, 0xb7, 0x53, 0x62, 0x39, 0x7f, 0xca, 0x5c, 0x50, 0x2b,
	0x4e, 0x3b, 0x40, 0x72, 0x4c, 0x44, 0xe2, 0xf4, 0xfa, 0xa8, 0xc5, 0x27, 0xac, 0x0b, 0x44, 0x46,
	0x4b, 0x4f, 0x2d, 0xaa, 0x67, 0x9a, 0x86, 0xdd, 0x80, 0x06, 0x35, 0x2c, 0x33, 0x94, 0x75, 0x2c,
	0x57, 0x47, 0x78, 0x3a, 0x86, 0x77, 0xe1, 0x92, 0xd6, 0x80, 0xa8, 0x36, 0xc6, 0x69, 0x72, 0xad,
	0x02, 0xb7, 0x23, 0x8f, 0x17, 0xb5, 0xe8, 0xe7, 0xa9, 0xb5, 0x84, 0x3c, 0x32, 0x2a, 0x27, 0xa3,
	0xd2, 0x9b, 0x19, 0x0e, 0xa9, 0xd2, 0x51, 0xde, 0x8b, 0xc7, 0x3b, 0xce, 0x20, 0xd0, 0x93, 0x23,
	0xcd, 0x8f, 0xe6, 0x02, 0x79, 0x2f, 0x0a, 0x43, 0x72, 0xd5, 0xff, 0x8a, 0x4b, 0xea, 0x7e, 0x1c,
	0xf5, 0x79, 0x9c, 0x9c, 0x4a, 0xa7, 0xc4, 0xee, 0x04, 0x4e, 0x57, 0xa0, 0xa2, 0xae, 0x59, 0x0d,
	0x8d, 0xb9, 0xeb, 0x27, 0xf7, 0x25, 0x9c, 0xfd, 0x0c, 0x9a, 0x23, 0x24, 0x89, 0x1d, 0xf8, 0x22,
	0x41, 0xbd, 0x5c, 0xdf, 0xbc, 0x6c, 0x56, 0xf4, 0x8e, 0x93, 0x38, 0xcf, 0x72, 0xc4, 0x1b, 0x52,
	0xb8, 0x58, 0x2b, 0xc3, 0x02, 0xe7, 0x91, 0x2f, 0x12, 0xf6, 0x57, 0x4b, 0xb0, 0xaa, 0x8d, 0xee,
	0xe8, 0x98, 0x4c, 0xc4, 0x43, 0x5f, 0x24, 0x51, 0x7c, 0x8a, 0xca, 0xba, 0xb2, 0xb9, 0xff, 0x56,
	0x11, 0x8d, 0x0d, 0x65, 0xac, 0x2b, 0xde, 0x0f, 0x89, 0xb5, 0xb5, 0xcc, 0x47, 0x81, 0x59, 0x1b,
	0x6a, 0xae, 0xdf, 0x3f, 0xe4, 0xb1, 0x7d, 0xc4, 0x4f, 0xe5, 0x46, 0x58, 0x46, 0x97, 0xba, 0x42,
	0xc0, 0x2f, 0xf8, 0x29, 0x8a, 0x87, 0x8b, 0xe9, 0x36, 0x73, 0xa3, 0x28, 0xf0, 0xa2, 0x93, 0xd0,
	0xee, 0x0d, 0x82, 0xc4, 0xef, 0x07, 0x3e, 0x8f, 0x51, 0xc9, 0x97, 0xa4, 0x3b, 0xb8, 0x6e, 0xe8,
	0xb6, 0x15, 0xd9, 0x9e, 0xa1, 0x62, 0x9f, 0xc0, 0xa2, 0xf2, 0x0a, 0x65, 0xd5, 0xdc, 0xb3, 0x0f,
	0xb0, 0xc2, 0x55, 0xb4, 0x10, 0x1a, 0x84, 0xda, 0x47, 0xcc, 0x5d, 0x59, 0xeb, 0xc7, 0x40, 0x30,
	0x15, 0x7f, 0xc0, 0xd9, 0x6d, 0xa2, 0xdf, 0x59, 0xfe, 0xd6, 0xa6, 0x55, 0x47, 0x1c, 0x0e, 0x06,
	0xce, 0xef, 0x03, 0xb8, 0xe2, 0x0b, 0x7b, 0xec, 0x82, 0xe2, 0xbd, 0x7e, 0x72, 0xda, 0x5c, 0xbb,
	0x3c, 0x71, 0x63, 0xd6, 0xba, 0xe0, 0x8b, 0x7b, 0xa3, 0x16, 0xd5, 0x3d, 0x49, 0xd3, 0xfa, 0xa3,
	0x12, 0x2c, 0x8f, 0x1c, 0x41, 0xb6, 0x09, 0x6a, 0x0c, 0xd3, 0x6d, 0x65, 0xe3, 0x1e, 0x41, 0x33,
	0xc5, 0x5a, 0x24, 0xa4, 0xd9, 0x4e, 0xfb, 0x72, 0xa3, 0xdc, 0x82, 0xa5, 0x82, 0x77, 0x43, 0x8b,
	0xa8, 0x8c, 0x8b, 0x7b, 0x21, 0xce, 0xfa, 0x36, 0xb8, 0x3a, 0x7e, 0x03, 0x96, 0x30, 0xa2, 0x68,
	0x96, 0x46, 0xcc, 0x1d, 0x11, 0x85, 0xe8, 0x95, 0xd7, 0x37, 0xbf, 0x78, 0x43, 0xd5, 0x8f, 0x28,
	0x23, 0x0b, 0x2d, 0x64, 0x69, 0x31, 0x59, 0x91, 0xee, 0x24, 0xc1, 0xda, 0x5b, 0x30, 0x7f, 0x37,
	0x8a, 0x02, 0xee, 0x84, 0x4f, 0xd5, 0x9e, 0x60, 0x4b, 0xd0, 0x38, 0xa2, 0xbd, 0xbb, 0xef, 0xf4,
	0x38, 0x7a, 0xd7, 0x8d, 0xf7, 0xd8, 0x02, 0xd4, 0x8e, 0xf6, 0x9c, 0xd0, 0xe9, 0xca, 0xd9, 0xba,
	0xc3, 0x45, 0xa3, 0xd4, 0xfa, 0x35, 0x80, 0x3b, 0xae, 0xb4, 0xec, 0xe4, 0x8e, 0x60, 0x37, 0x61,
	0xc1, 0xc1, 0xaf, 0xac, 0x34, 0xa1, 0x91, 0x9a, 0x27, 0x44, 0x2a, 0x4e, 0x86, 0xd5, 0x7b, 0x19,
	0x09, 0x73, 0xea, 0xbd, 0xfd, 0xf3, 0x32, 0xb4, 0xc6, 0x77, 0x87, 0xcd, 0xc2, 0xe4, 0xd1, 0xee,
	0xa3, 0xbd, 0xc6, 0x7b, 0x8c, 0x41, 0xfd, 0x08, 0x83, 0x00, 0x4e, 0xe0, 0x84, 0xae, 0x34, 0x29,
	0x4a, 0xac, 0x05, 0x2b, 0x47, 0xfb, 0xbc, 0xef, 0xc4, 0x52, 0x99, 0x38, 0xee, 0x91, 0x73, 0x10,
	0xf0, 0xe7, 0xa1, 0x9f, 0x88, 0x46, 0x99, 0x6d, 0xc2, 0xc6, 0xd1, 0x0e, 0xef, 0xc7, 0x1c, 0x23,
	0x13, 0xf7, 0x5e, 0xf6, 0x79, 0xec, 0xcb, 0x31, 0x71, 0x82, 0xbb, 0xa7, 0x7d, 0x47, 0x88, 0x2c,
	0x3d, 0xc6, 0x8e, 0x1a, 0x13, 0x38, 0x2a, 0x19, 0xcf, 0xf4, 0xfe, 0x20, 0x08, 0x1a, 0x93, 0x58,
	0x8b, 0xc5, 0x0f, 0x06, 0x7e, 0xe0, 0xdd, 0xcb, 0x79, 0xaf, 0x8d, 0x29, 0x6c, 0x55, 0xb6, 0x05,
	0xa2, 0x31, 0xcd, 0xe6, 0xa1, 0x72, 0xf4, 0x78, 0xd0, 0xa3, 0x1e, 0x88, 0xc6, 0x0c, 0xbb, 0x04,
	0x2d, 0xcd, 0xe0, 0x4e, 0x10, 0xa8, 0xc2, 0x42, 0x5b, 0x46, 0xb3, 0xed, 0x7f, 0x7f, 0x09, 0x2e,
	0x66, 0xc2, 0x1c, 0x4f, 0xfa, 0x41, 0xd4, 0xcd, 0x47, 0x49, 0x7f, 0x02, 0xb3, 0xbc, 0xef, 0x8b,
	0xc8, 0x33, 0x41, 0xa9, 0xef, 0x9c, 0x11, 0x27, 0x19, 0x66, 0xb0, 0x71, 0x8f, 0x4a, 0x5b, 0x86,
	0x0d, 0x3b, 0x1c, 0xa1, 0xd7, 0xcb, 0x67, 0xc5, 0x5e, 0xc7, 0xb1, 0x3e, 0x57, 0xa9, 0x73, 0x98,
	0x57, 0x71, 0x77, 0xee, 0xd9, 0xd2, 0x80, 0xa4, 0xd0, 0xf3, 0x58, 0x9b, 0x77, 0x5c, 0x45, 0xfb,
	0x9a, 0x09, 0xd9, 0xbc, 0x75, 0x91, 0xfb, 0x66, 0x2e, 0xcc, 0x87, 0xdc, 0x89, 0x6d, 0x71, 0x1a,
	0xba, 0xaa, 0x9a, 0x49, 0xac, 0xe6, 0xf6, 0xeb, 0x55, 0xf3, 0x98, 0x3b, 0xf1, 0xfe, 0x69, 0xe8,
	0x52, 0x2d, 0xb5, 0x30, 0xfb, 0xc9, 0x7e, 0x0d, 0x6e, 0x1e, 0xfa, 0xdd, 0x43, 0x69, 0x07, 0xba,
	0x51, 0xaf, 0xe7, 0x27, 0x09, 0xf7, 0xec, 0x6e, 0x10, 0x1d, 0x38, 0xc1, 0x08, 0xfd, 0x3c, 0x65,
	0x5c, 0x9d, 0x0f, 0x54, 0xa9, 0x6d, 0x5d, 0xe8, 0x01, 0x96, 0x19, 0xd2, 0xd6, 0x5f, 0x40, 0xcd,
	0xe9, 0x4b, 0xc9, 0xea, 0xd9, 0x6e, 0x57, 0xdb, 0x79, 0x95, 0xcd, 0x0f, 0x8b, 0x5d, 0xd8, 0x4e,
	0x0f, 0x5b, 0x94, 0x84, 0xa0, 0x30, 0x51, 0x45, 0x95, 0xde, 0xee, 0xee, 0x7a, 0x72, 0x07, 0x6a,
	0x66, 0x74, 0xc2, 0xa2, 0x0c, 0xbe, 0xaa, 0x82, 0x3e, 0x3a, 0x11, 0xbb, 0x1e, 0xfb, 0xf3, 0x25,
	0x68, 0x49, 0xb4, 0x04, 0x9e, 0xda, 0x63, 0x6c, 0xbd, 0x7b, 0xaf, 0x37, 0x86, 0x8f, 0x4e, 0xc4,
	0x1d, 0xc9, 0xae, 0xb8, 0x36, 0x56, 0x83, 0xd1, 0x08, 0xf6, 0x02, 0x3e, 0x38, 0x77, 0x5c, 0xd1,
	0x6c, 0x22, 0x33, 0x10, 0xc7, 0xb4, 0x7d, 0xe6, 0x98, 0xde, 0x95, 0xd4, 0x52, 0xcb, 0x69, 0xbe,
	0x03, 0xc1, 0x3d, 0x5b, 0x2d, 0xff, 0xd4, 0x7a, 0x07, 0xc3, 0xae, 0xa5, 0x08, 0x9f, 0x0b, 0xee,
	0xa9, 0xed, 0xa2, 0xed, 0xf8, 0xd6, 0xa9, 0xf4, 0x77, 0x62, 0xbf, 0xcf, 0xd9, 0xa5, 0x8c, 0x77,
	0x21, 0x77, 0xe2, 0xc4, 0xdd, 0x72, 0xb3, 0x94, 0xf1, 0x13, 0xae, 0x42, 0x2d, 0xab, 0x1b, 0x84,
	0x52, 0x0a, 0xd5, 0x8c, 0x52, 0x10, 0x52, 0x8c, 0x6a, 0xa2, 0x43, 0xcf, 0x53, 0x84, 0x13, 0x48,
	0x38, 0xaf, 0x10, 0x0f, 0x3d, 0x0f, 0x69, 0x5b, 0x3f, 0x9f, 0x87, 0x19, 0xd5, 0x1c, 0xf6, 0x11,
	0x34, 0x86, 0x3a, 0x40, 0x3e, 0xd3, 0x3c, 0xcf, 0xb7, 0x98, 0x5d, 0x80, 0x99, 0x7e, 0xec, 0xf7,
	0x9c, 0xf8, 0x94, 0xc4, 0x2e, 0x36, 0x53, 0x83, 0x98, 0x03, 0x0b, 0x82, 0xbb, 0x51, 0xe8, 0x39,
	0xf1, 0x29, 0xc5, 0x79, 0x8c, 0x43, 0xfd, 0xed, 0xd7, 0xde, 0x94, 0x7e, 0x9f, 0x5b, 0x0d, 0xc3,
	0x8e, 0x00, 0x82, 0xed, 0xc1, 0x15, 0x3d, 0xf2, 0xba, 0xcd, 0xc3, 0x1b, 0x64, 0xd2, 0x8c, 0xfe,
	0x25, 0x45, 0xac, 0xba, 0x3a, 0xb4, 0x31, 0xae, 0x42, 0xcd, 0x95, 0x1a, 0x4c, 0x33, 0xc3, 0xbd,
	0x35, 0x6b, 0x55, 0x11, 0xa8, 0xc7, 0xe7, 0x1b, 0xd9, 0x38, 0x81, 0x26, 0x9c, 0x26, 0x53, 0xc4,
	0x20, 0x34, 0xf1, 0x15, 0xa8, 0xaa, 0xe1, 0xc0, 0x09, 0x50, 0x7b, 0xa3, 0xa2, 0x60, 0xb2, 0xbb,
	0xec, 0x7d, 0xa8, 0xe8, 0xb6, 0x0f, 0x7c, 0x0f, 0xb7, 0xc2, 0x84, 0x05, 0x0a, 0xf4, 0xdc, 0xf7,
	0xd8, 0x6d, 0x68, 0x69, 0x1e, 0xfa, 0xa8, 0xd2, 0xee, 0xf8, 0x81, 0x32, 0x5b, 0xc9, 0x63, 0x59,
	0x55, 0x14, 0x7b, 0x8a, 0xe0, 0xbe, 0x1f, 0x90, 0xf5, 0xfa, 0x2d, 0x58, 0x31, 0x0d, 0xc8, 0x17,
	0x04, 0xb2, 0x3d, 0x74, 0x53, 0xb2, 0x85, 0x42, 0x98, 0x39, 0xe6, 0x31, 0x7a, 0x13, 0x15, 0xb4,
	0x1e, 0x76, 0xde, 0x48, 0x11, 0xe8, 0xff, 0x5f, 0x10, 0xaf, 0xad, 0xfa, 0x91, 0xfa, 0xf5, 0x88,
	0x77, 0x1d, 0xf7, 0xd4, 0xd2, 0x95, 0xb0, 0x1f, 0xc3, 0xe5, 0x20, 0x3a, 0x39, 0x7b, 0x16, 0xab,
	0x38, 0x8b, 0xa5, 0x6f, 0x5a, 0x17, 0x89, 0x74, 0xdc, 0x1c, 0xee, 0x41, 0x5b, 0x24, 0x4e, 0x9c,
	0xd8, 0xa3, 0xc7, 0x4c, 0x1d, 0x55, 0xd4, 0x34, 0xb7, 0x4b, 0x48, 0xfc, 0x74, 0x78, 0xf4, 0xd4,
	0xd9, 0xc5, 0x17, 0x70, 0x55, 0x33, 0x0a, 0x9c, 0xb8, 0xcb, 0xc9, 0x01, 0x13, 0xc5, 0xc1, 0x24,
	0x67, 0xe7, 0x92, 0x22, 0x7d, 0x24, 0x29, 0xd1, 0xf3, 0x12, 0xb9, 0x71, 0xfd, 0x19, 0xdc, 0xd0,
	0xfd, 0x7c, 0xd9, 0xe7, 0xee, 0x99, 0x62, 0x7d, 0xde, 0xac, 0xda, 0x6b, 0xaa, 0xc3, 0xaa, 0xc8,
	0x18, 0xa1, 0xfe, 0xab, 0xf0, 0x91, 0xd9, 0x0a, 0xe7, 0x32, 0x6f, 0x18, 0xe6, 0xd7, 0xf5, 0x96,
	0x38, 0x9b, 0xfb, 0xc7, 0xd0, 0xd0, 0xc3, 0xa0, 0x85, 0x09, 0x3a, 0x4c, 0x2a, 0xc6, 0xa6, 0x70,
	0x4a, 0x9e, 0x48, 0xdb, 0xb5, 0x30, 0xea, 0xa1, 0x2c, 0x86, 0x4e, 0xd3, 0xac, 0xb5, 0xd0, 0xcb,
	0x0e, 0x73, 0xf8, 0xd0, 0xf3, 0xd8, 0x87, 0xd0, 0x18, 0x22, 0x5e, 0xa4, 0xe8, 0x71, 0x9e, 0xf0,
	0x47, 0x70, 0x71, 0xcc, 0x34, 0xa8, 0x52, 0x4b, 0x58, 0xaa, 0x19, 0x0c, 0xcf, 0x00, 0x31, 0xb8,
	0x05, 0x0d, 0xad, 0xae, 0x3a, 0x71, 0xd4, 0x93, 0x3a, 0x8b, 0xa2, 0x94, 0x5b, 0x53, 0x1d, 0x27,
	0x10, 0xdc, 0xd2, 0xda, 0xec, 0x7e, 0x1c, 0xf5, 0x1e, 0x9d, 0x9c, 0xed, 0xd0, 0xad, 0xbc, 0xa5,
	0x43, 0x67, 0xc1, 0xb5, 0x73, 0xd6, 0x03, 0xa9, 0xa3, 0x55, 0x33, 0xd2, 0x97, 0xcf, 0x58, 0x0b,
	0xa4, 0x8c, 0x9e, 0xc1, 0xf5, 0xf3, 0xd6, 0x01, 0x31, 0x6d, 0x1a, 0xa6, 0x57, 0xce, 0x5a, 0x03,
	0xc4, 0xf5, 0x47, 0x85, 0x03, 0x1b, 0x0a, 0x1f, 0x68, 0x8d, 0xbf, 0x66, 0x58, 0xe5, 0x0e, 0x6d,
	0x88, 0x88, 0x0c, 0x80, 0x21, 0x6f, 0xb1, 0x35, 0xec, 0x2d, 0x6e, 0xc0, 0x62, 0x86, 0xc6, 0x1c,
	0xc1, 0xae, 0xa3, 0xab, 0xbd, 0x60, 0x28, 0xcd, 0x21, 0xec, 0x1a, 0x4c, 0xab, 0x06, 0x5c, 0x30,
	0x0d, 0x98, 0x0a, 0xb0, 0xba, 0x6f, 0xc3, 0x92, 0x44, 0x0d, 0x29, 0xb2, 0x8b, 0x86, 0x90, 0x05,
	0x27, 0xa2, 0xa0, 0x81, 0xd9, 0x77, 0x60, 0x71, 0x84, 0x91, 0xd2, 0xbc, 0x94, 0x5d, 0x1f, 0x0b,
	0x43, 0xd6, 0x45, 0x7b, 0x07, 0xea, 0x79, 0x49, 0x87, 0x16, 0x7b, 0x4e, 0xd6, 0x35, 0xde, 0x43,
	0x03, 0x5d, 0xc1, 0xee, 0x07, 0x03, 0x71, 0x68, 0x71, 0x37, 0x8a, 0x3d, 0x41, 0x86, 0x45, 0xa3,
	0xd4, 0xfa, 0xc1, 0xf0, 0x51, 0xdf, 0x07, 0x30, 0xef, 0x1e, 0xfa, 0x81, 0x67, 0xbc, 0x1b, 0x65,
	0x0e, 0x58, 0x35, 0x04, 0x2b, 0xf7, 0x46, 0xb4, 0xfe, 0x68, 0x12, 0xea, 0x79, 0xc3, 0x95, 0xfd,
	0x69, 0xf8, 0x64, 0xd8, 0xd6, 0x49, 0x2d, 0xe4, 0x61, 0x91, 0x40, 0x0e, 0xd6, 0x47, 0x45, 0x73,
	0xc7, 0xb0, 0x1d, 0x12, 0x09, 0x2f, 0xe0, 0x86, 0xae, 0x41, 0x70, 0x1e, 0x9e, 0xc9, 0x9c, 0x9c,
	0xb2, 0x6b, 0x8a, 0x7e, 0x9f, 0xf3, 0x70, 0x3c, 0xdf, 0x8f, 0x81, 0xe9, 0x0c, 0x1a, 0xbd, 0xcc,
	0x7c, 0x0f, 0x8d, 0xf9, 0x09, 0xab, 0xa1, 0x30, 0x6a, 0x69, 0xed, 0x7a, 0xec, 0x1f, 0x97, 0xe0,
	0x7d, 0x2f, 0x76, 0xfc, 0x30, 0x63, 0x77, 0xc5, 0x38, 0xb2, 0x46, 0xf0, 0xab, 0xd8, 0xfa, 0x4f,
	0xdf, 0xc6, 0x11, 0xd8, 0xd8, 0xa1, 0x3a, 0xb4, 0x8b, 0x83, 0x35, 0x68, 0x75, 0x61, 0x5d, 0xf0,
	0xce, 0xc0, 0xb6, 0xfe, 0x73, 0x09, 0x2e, 0x9c, 0x55, 0x7c, 0x8c, 0xc5, 0x55, 0x1a, 0x65, 0x71,
	0x7d, 0x0e, 0xeb, 0xe7, 0x8f, 0xf3, 0x9a, 0x18, 0x3b, 0xb8, 0x57, 0xa0, 0x4a, 0x6b, 0x29, 0x73,
	0x64, 0x3f, 0x61, 0x55, 0x10, 0xa6, 0x34, 0x1e, 0x83, 0x49, 0x54, 0x69, 0x68, 0x36, 0x59, 0xf8,
	0x9b, 0xad, 0xc3, 0xdc, 0x57, 0x3c, 0x8e, 0x50, 0xdc, 0x2a, 0xa3, 0x68, 0x56, 0x02, 0xa4, 0xc0,
	0x6b, 0x1d, 0x40, 0x2d, 0xe7, 0xce, 0x7c, 0x0d, 0x8e, 0x64, 0xeb, 0x17, 0x25, 0x58, 0x1d, 0x63,
	0xef, 0x0f, 0xbb, 0x33, 0xa5, 0x77, 0xea, 0xce, 0x94, 0x87, 0xdd, 0x99, 0xf6, 0x1f, 0x96, 0x61,
	0xf2, 0x51, 0xe4, 0x1e, 0xb1, 0x2d, 0x98, 0xc3, 0xac, 0x2c, 0x3c, 0x2e, 0x28, 0xa1, 0xad, 0x34,
	0x74, 0xc6, 0x2e, 0x09, 0xf1, 0x1f, 0xd4, 0x05, 0xb3, 0x81, 0xfa, 0xc5, 0x7e, 0x04, 0x15, 0x29,
	0x89, 0xed, 0xd8, 0x09, 0xbb, 0x5c, 0x67, 0x0d, 0x5d, 0x1a, 0x59, 0x5a, 0x0a, 0x61, 0x4b, 0x92,
	0x59, 0x70, 0xa0, 0x7f, 0x0a, 0x76, 0x1b, 0x66, 0x28, 0x1b, 0x4c, 0x9b, 0xd5, 0x57, 0x4c, 0xe1,
	0x90, 0x27, 0x58, 0x72, 0x1b, 0xf1, 0xbb, 0x1e, 0x0f, 0x13, 0xbf, 0xe3, 0xf3, 0xd8, 0xd2, 0x25,
	0x5a, 0xb7, 0x61, 0xce, 0x70, 0x65, 0x2b, 0x30, 0xad, 0x16, 0x04, 0xad, 0x3b, 0xf5, 0x25, 0xe1,
	0x99, 0x7c, 0x9f, 0x09, 0x4b, 0x7d, 0xb5, 0x4f, 0x61, 0x56, 0x77, 0x88, 0xcd, 0xc1, 0xd4, 0xd1,
	0xe3, 0x41, 0x10, 0x34, 0xde, 0x63, 0x8b, 0x30, 0x7f, 0xb4, 0x1d, 0x85, 0xea, 0x44, 0xd1, 0xe2,
	0x8e, 0xd7, 0x28, 0x61, 0xbc, 0x23, 0x05, 0xa2, 0x4e, 0x6e, 0x94, 0x51, 0x42, 0xca, 0xe1, 0x47,
	0x85, 0x83, 0x94, 0x13, 0x58, 0xdc, 0xc0, 0x88, 0x70, 0x92, 0xd5, 0x01, 0x8e, 0xee, 0xbd, 0x74,
	0x83, 0x81, 0xf0, 0x8f, 0x79, 0x63, 0xaa, 0xfd, 0xbf, 0x4b, 0x50, 0xdb, 0x15, 0xae, 0xf0, 0xcd,
	0xf6, 0xb9, 0x0a, 0xb5, 0x7e, 0x6c, 0x77, 0x79, 0xa8, 0x8e, 0x38, 0xb0, 0x0f, 0x35, 0xab, 0xda,
	0x8f, 0x1f, 0x18, 0x18, 0x7b, 0x24, 0x5d, 0xa6, 0xae, 0x2f, 0x12, 0xfa, 0xd6, 0xc3, 0xfd, 0x41,
	0x6e, 0xc4, 0x90, 0xef, 0xc8, 0x61, 0xcb, 0x17, 0x66, 0x1b, 0x30, 0xef, 0x04, 0x81, 0xad, 0x81,
	0x34, 0x03, 0x39, 0x23, 0x22, 0x08, 0xac, 0x14, 0xc9, 0xee, 0xc3, 0x52, 0x81, 0xde, 0xc6, 0x3c,
	0x34, 0x8a, 0x1d, 0x2c, 0x8d, 0x9a, 0x73, 0x8b, 0xe5, 0x79, 0x48, 0x58, 0xfb, 0x37, 0xa0, 0xb2,
	0xdf, 0x3b, 0x30, 0x3d, 0xbf, 0x01, 0x0d, 0x6f, 0x10, 0x3b, 0x07, 0x01, 0x27, 0x1b, 0x48, 0x2b,
	0x88, 0x49, 0xab, 0xae, 0xe0, 0xd2, 0xf0, 0xd9, 0xf5, 0x04, 0xbb, 0x0e, 0x75, 0x7d, 0x5c, 0x4c,
	0x21, 0x34, 0x9c, 0xd0, 0x9a, 0x55, 0x53, 0x50, 0x0a, 0xbf, 0xb1, 0x8b, 0x00, 0xe2, 0xd0, 0x89,
	0xb9, 0xdd, 0x93, 0x4e, 0xcd, 0x04, 0x92, 0xcc, 0x21, 0x64, 0x2f, 0xf2, 0x78, 0xfb, 0xff, 0x30,
	0x60, 0xb4, 0x73, 0x1f, 0xdf, 0xdf, 0xbf, 0x93, 0x24, 0x31, 0x05, 0x8e, 0x96, 0x60, 0xaa, 0xa3,
	0x36, 0x40, 0xf9, 0xc6, 0x94, 0x45, 0x1f, 0x52, 0x8e, 0x20, 0x97, 0xf2, 0xe5, 0xf2, 0x8d, 0x9a,
	0x85, 0xbf, 0xd9, 0x03, 0x98, 0xef, 0x3b, 0xea, 0xb4, 0x99, 0x32, 0x2b, 0xd5, 0xca, 0x7d, 0xbf,
	0x38, 0x04, 0x8f, 0x3b, 0x62, 0x57, 0x92, 0xe8, 0x4d, 0x5a, 0xa3, 0x72, 0x0a, 0xc6, 0x1a, 0x30,
	0x21, 0x9d, 0xa5, 0x49, 0xe4, 0x2d, 0x7f, 0x4a, 0x48, 0x17, 0x73, 0x47, 0x10, 0xd2, 0xf5, 0x3d,
	0x6c, 0x16, 0x4a, 0xb2, 0x69, 0xcc, 0x21, 0xa2, 0x0f, 0x29, 0x01, 0x7b, 0xce, 0x9f, 0xc1, 0xa4,
	0xad, 0x63, 0xdf, 0xe5, 0xe8, 0x91, 0x4d, 0x59, 0x15, 0x84, 0xed, 0x20, 0x08, 0x49, 0xfc, 0x30,
	0x25, 0x99, 0x55, 0x24, 0x12, 0xa6, 0x48, 0xb6, 0x60, 0xd6, 0xf4, 0x60, 0xee, 0x72, 0xf9, 0x55,
	0x7a, 0x30, 0xe3, 0xab, 0xb6, 0x2f, 0xc1, 0x54, 0x4f, 0x8a, 0x6c, 0x75, 0x72, 0x44, 0x1f, 0x12,
	0xea, 0x22, 0xb4, 0x42, 0x50, 0xfc, 0x30, 0x67, 0x7b, 0xd5, 0xd7, 0x3d, 0xdb, 0xfb, 0x00, 0xe6,
	0xc3, 0x41, 0x8f, 0xec, 0x63, 0x39, 0x81, 0x9e, 0x40, 0x9f, 0x67, 0xca, 0xaa, 0x85, 0x83, 0x9e,
	0x14, 0xdb, 0xfb, 0x08, 0x64, 0xdf, 0x83, 0x66, 0x12, 0x25, 0x4e, 0x90, 0xa1, 0xb4, 0x79, 0x98,
	0xc4, 0x3e, 0x17, 0x2a, 0x17, 0x63, 0x19, 0xf1, 0xa6, 0xc8, 0x3d, 0x42, 0xca, 0xa5, 0x42, 0x9a,
	0x24, 0x74, 0x7a, 0x1c, 0xbd, 0x95, 0x39, 0x6b, 0x0e, 0x21, 0x8f, 0x9d, 0x1e, 0x6a, 0x0c, 0x5c,
	0x92, 0x88, 0x6d, 0x20, 0x76, 0x56, 0x02, 0x10, 0x79, 0x05, 0xaa, 0xb9, 0x23, 0xb4, 0x05, 0xd2,
	0x42, 0x6e, 0xe6, 0xf4, 0x6c, 0x07, 0xea, 0xbe, 0xdc, 0x8d, 0xa9, 0x16, 0x67, 0xa3, 0xf3, 0xd7,
	0x72, 0xb2, 0xc0, 0xaa, 0xf9, 0x39, 0xd1, 0x70, 0x13, 0xa6, 0xe4, 0x98, 0x50, 0x4a, 0xc4, 0xb8,
	0x8d, 0x46, 0x24, 0x6c, 0x0f, 0x58, 0xcc, 0x3b, 0x3c, 0x96, 0x7a, 0x36, 0x5d, 0x9e, 0x4b, 0x58,
	0xeb, 0xb9, 0x93, 0xdb, 0x30, 0x45, 0xf5, 0x0a, 0x5d, 0x83, 0xe9, 0x13, 0x27, 0xd0, 0xe7, 0x22,
	0xca, 0x38, 0x3d, 0x71, 0x02, 0xb4, 0x85, 0x2b, 0xfd, 0x98, 0x1f, 0xdb, 0x0a, 0xbf, 0x62, 0xf0,
	0x73, 0x12, 0xfc, 0x25, 0xd2, 0x5c, 0x85, 0xb9, 0x24, 0xea, 0x1d, 0x88, 0x24, 0x0a, 0x39, 0x1d,
	0x74, 0x68, 0xd9, 0x92, 0xc2, 0xd9, 0xe7, 0x50, 0x15, 0xbd, 0x83, 0x74, 0x88, 0x9a, 0xd8, 0xd8,
	0xf5, 0x62, 0x63, 0x33, 0x22, 0xc3, 0xaa, 0x88, 0x8c, 0xfc, 0xf8, 0xd4, 0x18, 0xd0, 0x6b, 0x58,
	0xb2, 0x35, 0x34, 0x3e, 0x5f, 0xee, 0xeb, 0x1e, 0x2a, 0xc3, 0x5a, 0xee, 0x8d, 0x63, 0x27, 0x18,
	0x70, 0x9b, 0xf7, 0x23, 0xf7, 0x10, 0xcd, 0xf8, 0x09, 0xab, 0x42, 0xb0, 0x7b, 0x12, 0x24, 0xcd,
	0x19, 0x45, 0x92, 0x1a, 0x26, 0xeb, 0x64, 0xce, 0x10, 0x3c, 0x35, 0x47, 0x2e, 0x43, 0xd5, 0x17,
	0xb6, 0xb1, 0xb9, 0xd1, 0x8e, 0x9f, 0xb5, 0xc0, 0x17, 0x5a, 0xd7, 0xb3, 0xe7, 0x50, 0x97, 0x5d,
	0x8c, 0xfa, 0x68, 0x61, 0x3a, 0x09, 0x99, 0xf0, 0x95, 0xcd, 0x5b, 0xa3, 0x2d, 0x8a, 0xac, 0x5c,
	0x92, 0xfd, 0x7e, 0xd2, 0x97, 0xa6, 0xa6, 0x93, 0x70, 0x4b, 0x8e, 0x94, 0xf9, 0x62, 0x0f, 0xe0,
	0x82, 0x38, 0x0d, 0xdd, 0xc3, 0x38, 0x0a, 0xa3, 0x41, 0x9a, 0x02, 0x6e, 0xf2, 0x3e, 0x72, 0x26,
	0x7f, 0x2b, 0x43, 0xaa, 0xc7, 0x4e, 0xa7, 0x71, 0x5c, 0x81, 0x2a, 0x16, 0xd4, 0xf1, 0x92, 0xf7,
	0x69, 0x3c, 0x24, 0x4c, 0x3b, 0x03, 0xd7, 0xa0, 0xda, 0x77, 0x92, 0x43, 0x43, 0x72, 0x59, 0xc7,
	0x1e, 0x2a, 0x12, 0xac, 0xa9, 0x9e, 0xc3, 0x42, 0x3e, 0x71, 0x5c, 0x4e, 0xcb, 0x15, 0xec, 0xeb,
	0x47, 0xa6, 0xaf, 0x94, 0x61, 0xae, 0x6d, 0xd3, 0xa7, 0x94, 0x60, 0xfe, 0x3c, 0xf4, 0x25, 0x6b,
	0xb9, 0x6c, 0x2c, 0x1d, 0x04, 0x27, 0xd4, 0xae, 0xc7, 0xbe, 0x01, 0x75, 0x3f, 0x94, 0x16, 0xf1,
	0xa9, 0x1b, 0x70, 0xfb, 0xc0, 0x0f, 0x9b, 0xed, 0x6c, 0xd7, 0xaa, 0x7e, 0x68, 0x11, 0xee, 0xae,
	0x1f, 0xd2, 0x99, 0x93, 0xa1, 0xb4, 0x93, 0x24, 0xa0, 0x63, 0xaa, 0xab, 0x94, 0x8b, 0x1b, 0x1b,
	0xca, 0x67, 0x49, 0xb0, 0xcf, 0x5d, 0xd1, 0xfa, 0x83, 0x69, 0xa8, 0x66, 0x47, 0x99, 0x05, 0x34,
	0x5d, 0x14, 0x18, 0xc1, 0xe9, 0x22, 0xa3, 0xe8, 0xb3, 0xd7, 0x9c, 0x2e, 0xf9, 0x81, 0x61, 0x13,
	0xf9, 0xb1, 0x35, 0x7b, 0xa4, 0x70, 0x38, 0x8b, 0x06, 0xce, 0x6c, 0xa8, 0x99, 0xc5, 0x81, 0x1b,
	0xa0, 0x7c, 0x56, 0x16, 0xcd, 0x99, 0x95, 0xc9, 0x8f, 0x1d, 0xbd, 0x41, 0xf4, 0x07, 0x9e, 0x14,
	0x47, 0x81, 0x6b, 0x87, 0x51, 0x62, 0x8b, 0x41, 0xbf, 0x1f, 0xc5, 0x09, 0xf7, 0x54, 0x4e, 0x7b,
	0x43, 0x62, 0x1e, 0x47, 0xc9, 0xbe, 0x86, 0xb7, 0xfe, 0xc6, 0x24, 0xaa, 0x67, 0x53, 0x7a, 0x15,
	0x66, 0x94, 0x5a, 0xc6, 0x51, 0x98, 0xb4, 0xa6, 0x3b, 0xa8, 0x8e, 0xdf, 0x8d, 0x36, 0x96, 0x5c,
	0xdc, 0x98, 0x3b, 0x09, 0xb7, 0xa3, 0x7e, 0xa2, 0x32, 0xea, 0x91, 0x0b, 0x41, 0x9f, 0x10, 0x90,
	0x2d, 0xc3, 0xb4, 0x38, 0xee, 0xa5, 0x79, 0x95, 0x53, 0xe2, 0xb8, 0xb7, 0xeb, 0xb1, 0xef, 0xc2,
	0xaa, 0x48, 0x9c, 0xb8, 0x3b, 0x22, 0x63, 0x83, 0xd2, 0x3e, 0x96, 0x35, 0x3a, 0x9f, 0xaa, 0x71,
	0x15, 0x6a, 0x72, 0x5b, 0x47, 0x83, 0xc4, 0xee, 0xe1, 0xe2, 0x50, 0xe1, 0x7e, 0x05, 0xdc, 0xc3,
	0x63, 0xb9, 0xef, 0xc3, 0x9a, 0xd3, 0xef, 0xdb, 0x7e, 0x28, 0x12, 0x07, 0xc5, 0xa9, 0x74, 0x56,
	0x4e, 0x54, 0xe0, 0x81, 0x22, 0x9c, 0xcb, 0x4e, 0xbf, 0xbf, 0xab, 0xf0, 0xbb, 0xde, 0xa3, 0xe8,
	0x84, 0x02, 0x0d, 0x5b, 0xd0, 0x2a, 0x96, 0x94, 0x5e, 0x63, 0x36, 0x2e, 0x6f, 0xad, 0xe4, 0x8a,
	0x3e, 0xf4, 0xbb, 0x87, 0x54, 0xf6, 0x53, 0x58, 0x26, 0xeb, 0xd6, 0xee, 0x0e, 0x72, 0x35, 0x52,
	0xa8, 0x93, 0x11, 0xf2, 0xc1, 0xc0, 0x4f, 0xab, 0xfb, 0x16, 0xac, 0x64, 0x8b, 0x64, 0xaa, 0xaa,
	0x50, 0x78, 0x34, 0x2d, 0x93, 0xd6, 0x73, 0x13, 0x16, 0x70, 0x16, 0xb4, 0x5f, 0x2e, 0xd7, 0x9f,
	0xca, 0x89, 0x9c, 0x27, 0x04, 0x7a, 0xe6, 0x72, 0x1d, 0xb4, 0x7f, 0x8c, 0x1b, 0x24, 0x5d, 0xb2,
	0x55, 0x30, 0x8b, 0xb9, 0xf1, 0x1e, 0x5b, 0x86, 0x05, 0xf9, 0x45, 0x69, 0x99, 0x4f, 0xa4, 0x02,
	0x17, 0xbc, 0x51, 0xca, 0x83, 0x9f, 0xf2, 0xd0, 0xc3, 0xe4, 0xa6, 0xf6, 0xdf, 0x2d, 0xc1, 0xaa,
	0x59, 0xca, 0x46, 0x21, 0x93, 0x0d, 0x76, 0x11, 0x40, 0xaa, 0xed, 0x53, 0x52, 0xb8, 0xd2, 0x08,
	0x9c, 0xb3, 0xe6, 0x10, 0x82, 0x1a, 0xf7, 0x1e, 0xd4, 0x09, 0x6d, 0x14, 0x5b, 0xf9, 0xd5, 0xec,
	0xae, 0x2a, 0x16, 0xd3, 0x4a, 0xad, 0x09, 0x33, 0x52, 0x49, 0xf3, 0x90, 0x3c, 0xc7, 0xaa, 0xa5,
	0x3f, 0xdb, 0xbf, 0x57, 0x82, 0x15, 0xd3, 0xb6, 0xfc, 0xb9, 0xe2, 0x0f, 0x61, 0x36, 0xec, 0x08,
	0xdb, 0x49, 0x92, 0x18, 0x2d, 0xc4, 0xca, 0x66, 0xfb, 0xfc, 0x0d, 0x6a, 0xcd, 0x84, 0x1d, 0x21,
	0xbf, 0xd8, 0x43, 0xa8, 0x64, 0xad, 0x18, 0x6a, 0xf7, 0x87, 0x63, 0x39, 0xe4, 0xc7, 0xc5, 0x02,
	0xcf, 0xd8, 0x3a, 0xed, 0x7f, 0x51, 0x81, 0x0b, 0x44, 0xa7, 0xa6, 0xa4, 0x78, 0x4f, 0xe4, 0x22,
	0x80, 0xb6, 0xa7, 0xf5, 0xcd, 0x18, 0x6b, 0x4e, 0x41, 0xde, 0xe6, 0x46, 0x4c, 0xd6, 0x5a, 0x9c,
	0x78, 0x35, 0x83, 0xc2, 0x58, 0x8b, 0x45, 0x5b, 0x69, 0x72, 0xd8, 0x56, 0x1a, 0x61, 0x55, 0x4f,
	0xbd, 0x5a, 0x2d, 0x05, 0xab, 0xba, 0x05, 0x68, 0xa3, 0xe1, 0x12, 0x9a, 0x4e, 0x6d, 0x36, 0xf9,
	0x2d, 0xa5, 0x4d, 0x57, 0x3a, 0x22, 0xa9, 0xcc, 0x22, 0xcb, 0xb9, 0xa6, 0xa0, 0x4a, 0x66, 0x5d,
	0x81, 0x6a, 0xd4, 0x47, 0x97, 0x38, 0xe0, 0xc7, 0x3c, 0xd0, 0xb6, 0x33, 0xc1, 0x1e, 0x49, 0x50,
	0x86, 0x84, 0x34, 0xc4, 0x5c, 0x96, 0x84, 0x76, 0xc9, 0x6d, 0x68, 0xe9, 0x89, 0x40, 0xe1, 0x9e,
	0x97, 0x38, 0xb4, 0x9d, 0x57, 0x15, 0x85, 0xdc, 0x4a, 0xcf, 0xb2, 0xc2, 0x47, 0x8a, 0x01, 0x92,
	0x8b, 0x05, 0x31, 0x50, 0x51, 0x62, 0x00, 0x91, 0x43, 0x62, 0x20, 0x53, 0x24, 0x23, 0x06, 0xaa,
	0x4a, 0x0c, 0x98, 0x32, 0xa9, 0x18, 0x38, 0x53, 0xc8, 0xd5, 0xde, 0x5c, 0xc8, 0xd5, 0xcf, 0x14,
	0x72, 0xc3, 0xba, 0x63, 0x9e, 0xe6, 0xe1, 0x2c, 0xdd, 0xd1, 0x40, 0x92, 0x33, 0x75, 0x07, 0xa5,
	0x3f, 0x15, 0x74, 0xc7, 0x87, 0x30, 0x8f, 0x1a, 0x4c, 0xee, 0x5d, 0xff, 0x60, 0x20, 0x5b, 0xc7,
	0x90, 0xae, 0x2e, 0xc1, 0x77, 0x0c, 0x94, 0x7d, 0x02, 0x6a, 0x58, 0x6d, 0xcf, 0x17, 0x26, 0x6d,
	0x7d, 0x91, 0xec, 0x06, 0xc2, 0xec, 0xa4, 0x08, 0x3c, 0x68, 0x23, 0x72, 0xc7, 0x45, 0xca, 0x25,
	0xa4, 0xac, 0x12, 0xf0, 0x8e, 0xab, 0x89, 0x7c, 0x61, 0xf7, 0xa5, 0x7d, 0x24, 0x50, 0xe4, 0x50,
	0x36, 0x71, 0xd5, 0x17, 0x4f, 0x0d, 0xcc, 0x24, 0xb0, 0xa1, 0xea, 0xa2, 0x14, 0xb6, 0x34, 0xc7,
	0x86, 0x96, 0xcb, 0x0a, 0xf2, 0xbe, 0xa0, 0xc9, 0x28, 0x85, 0xcd, 0xd8, 0xa0, 0xb4, 0x66, 0xda,
	0x50, 0x13, 0x3c, 0x96, 0xae, 0x9d, 0x4d, 0xba, 0x72, 0x95, 0xb6, 0x99, 0x02, 0xbe, 0x90, 0x1a,
	0x73, 0x19, 0xa6, 0xa5, 0x1c, 0xeb, 0x1c, 0xa2, 0x9d, 0x5d, 0xb5, 0xa6, 0xc2, 0x8e, 0xb8, 0x7f,
	0x28, 0x8b, 0xaa, 0xdd, 0xa7, 0xb0, 0x6b, 0x14, 0xd9, 0x26, 0xe0, 0x63, 0xa4, 0x09, 0x47, 0x69,
	0x8c, 0x16, 0xee, 0xd1, 0xbb, 0xa3, 0x25, 0xd9, 0x68, 0x09, 0xb5, 0xb1, 0x4f, 0xea, 0xc5, 0x8f,
	0x93, 0x81, 0x13, 0xec, 0x28, 0x25, 0x33, 0xa4, 0x75, 0xa4, 0x86, 0xf2, 0x85, 0x8d, 0xa6, 0x4b,
	0x6a, 0xb6, 0xac, 0x93, 0x86, 0xf2, 0xc5, 0x4e, 0x14, 0xb8, 0xc6, 0x6a, 0x61, 0xdf, 0x84, 0xa5,
	0xdc, 0x62, 0xd4, 0x66, 0xea, 0x05, 0xec, 0x06, 0xcb, 0x2c, 0x43, 0x6d, 0xaa, 0x6e, 0xc0, 0x22,
	0xee, 0xca, 0x82, 0xd9, 0x80, 0xb1, 0x75, 0x6b, 0x41, 0xa2, 0x72, 0x26, 0x43, 0x6b, 0x0b, 0x96,
	0x47, 0xb6, 0x5b, 0x4a, 0x02, 0x3f, 0xf4, 0x13, 0xdf, 0x49, 0xa2, 0x58, 0x4b, 0xdc, 0xaa, 0x55,
	0x31, 0xb0, 0x5d, 0xaf, 0xfd, 0x5f, 0x4a, 0xb0, 0xb6, 0x1f, 0x3a, 0x7d, 0x71, 0x18, 0x25, 0x16,
	0xff, 0xf5, 0x01, 0x17, 0x99, 0xb0, 0x0c, 0x7b, 0x1f, 0x2a, 0x42, 0x21, 0x75, 0xf9, 0x39, 0x0b,
	0x34, 0x68, 0x17, 0x3b, 0x67, 0x08, 0xd0, 0x08, 0xef, 0xc7, 0xbc, 0xe3, 0xbf, 0xd4, 0x99, 0xbd,
	0x1a, 0xf7, 0xd4, 0x49, 0x0e, 0x9f, 0x22, 0x46, 0x1a, 0x6d, 0x7d, 0x8f, 0xb4, 0xe8, 0x04, 0x12,
	0x4d, 0xf7, 0x3d, 0x54, 0xa1, 0xab, 0x30, 0xe3, 0x76, 0x09, 0x31, 0x49, 0x08, 0xb7, 0x8b, 0x88,
	0xcf, 0x60, 0x8a, 0xe2, 0x8e, 0x53, 0xaf, 0x17, 0x77, 0x9c, 0x74, 0xbb, 0xbb, 0x5e, 0xfb, 0x3f,
	0x94, 0xa1, 0xaa, 0x3b, 0x88, 0x57, 0x1c, 0x7e, 0x3c, 0xdc, 0xa7, 0xac, 0x0b, 0xa0, 0x7d, 0xba,
	0x71, 0x63, 0x92, 0xeb, 0xfe, 0x15, 0xa8, 0xf2, 0x38, 0x8e, 0x62, 0x5b, 0xe5, 0x6a, 0xd3, 0xad,
	0xbd, 0x0a, 0xc2, 0x54, 0x6e, 0xf5, 0x2e, 0xd4, 0xc8, 0x48, 0x0d, 0x3b, 0x91, 0x7d, 0xcc, 0x5d,
	0x15, 0x90, 0xb9, 0x3e, 0xae, 0x42, 0xd9, 0xc6, 0x0d, 0x5c, 0x9a, 0x61, 0x27, 0xb2, 0x2a, 0x1d,
	0xf5, 0xeb, 0x05, 0x77, 0xa5, 0xcc, 0xf1, 0x85, 0xed, 0x1c, 0xd0, 0x72, 0xa3, 0x4b, 0x40, 0x73,
	0xbe, 0xb8, 0x43, 0x80, 0x16, 0x87, 0x59, 0x5d, 0xce, 0x84, 0x07, 0xe4, 0x9c, 0xa8, 0x69, 0x43,
	0x55, 0x23, 0x27, 0x42, 0xf2, 0x41, 0x24, 0x89, 0x43, 0x8a, 0x3c, 0x22, 0x39, 0x49, 0xc0, 0x8b,
	0x00, 0x03, 0xc1, 0x63, 0x85, 0xa6, 0x08, 0xf6, 0x9c, 0x84, 0x20, 0xba, 0xfd, 0xaf, 0xbe, 0x05,
	0xdf, 0x50, 0xd6, 0x80, 0x8a, 0x4a, 0x17, 0x27, 0xa0, 0x78, 0x27, 0x76, 0x41, 0x4e, 0x5f, 0x7e,
	0x2d, 0xab, 0xf0, 0xbb, 0xdb, 0xcd, 0x1b, 0xbf, 0xb7, 0xa1, 0xa9, 0xee, 0x2a, 0x0d, 0x17, 0x29,
	0x1b, 0x37, 0x7e, 0x99, 0x68, 0xb6, 0x0b, 0x85, 0x6f, 0xc2, 0x42, 0xc7, 0x0f, 0x9d, 0xc0, 0xff,
	0xca, 0x04, 0x97, 0x4d, 0x42, 0x86, 0x41, 0x60, 0x7c, 0x19, 0xc3, 0x37, 0x94, 0x70, 0x9b, 0x52,
	0x4e, 0xd2, 0xc9, 0x8f, 0x02, 0x2b, 0xba, 0x5f, 0x94, 0xa0, 0x19, 0xf3, 0x5e, 0x94, 0x98, 0xbb,
	0x50, 0x89, 0x9a, 0x6d, 0xae, 0x13, 0xc2, 0xad, 0x31, 0xa6, 0xd2, 0xab, 0x0c, 0xce, 0x86, 0x85,
	0xbc, 0xad, 0xcc, 0xa1, 0x1e, 0x3a, 0xd3, 0x2b, 0x71, 0x0e, 0x4e, 0x8b, 0x89, 0x2c, 0x63, 0xa9,
	0xc6, 0xbb, 0xb6, 0xe0, 0xdd, 0x1e, 0x25, 0x91, 0x0b, 0x75, 0x29, 0x6b, 0x1e, 0x11, 0xfb, 0x04,
	0x97, 0x4d, 0xff, 0x01, 0xac, 0xe9, 0x2e, 0x0e, 0x97, 0x99, 0xa1, 0x5b, 0x39, 0x8a, 0xe0, 0x49,
	0xa1, 0xe8, 0x5f, 0x2b, 0xc1, 0xba, 0x16, 0xa4, 0xb2, 0x24, 0x1d, 0xaf, 0x72, 0xd3, 0xf1, 0x59,
	0xec, 0xf8, 0xe3, 0xb7, 0xe9, 0x38, 0x56, 0xf9, 0x4c, 0xf1, 0xa5, 0x4e, 0x37, 0xe9, 0x94, 0x64,
	0x08, 0x21, 0xd8, 0xef, 0x94, 0xe0, 0x52, 0xb6, 0x3d, 0xb9, 0xa3, 0x52, 0x6a, 0xd2, 0x1c, 0x36,
	0xe9, 0x27, 0x6f, 0xdd, 0xa4, 0xa1, 0xa9, 0x58, 0x4f, 0x5b, 0x55, 0xc4, 0x09, 0xf6, 0x43, 0x58,
	0xd3, 0x67, 0x74, 0xba, 0x4d, 0xe9, 0xc1, 0x46, 0x9a, 0x95, 0xb4, 0xa2, 0x88, 0x2c, 0x43, 0x43,
	0x87, 0xb6, 0xbb, 0x30, 0xeb, 0x76, 0x95, 0x95, 0x46, 0x89, 0x20, 0xd7, 0xcf, 0x13, 0x6e, 0xe4,
	0xb0, 0xcf, 0x1c, 0x49, 0x1d, 0x7e, 0xcc, 0xad, 0x19, 0xb7, 0x4b, 0x16, 0xdd, 0x07, 0x30, 0x8f,
	0xd9, 0xf0, 0xbe, 0x67, 0xe3, 0x2d, 0x42, 0x1e, 0x2b, 0xd3, 0xaa, 0x26, 0xc1, 0xbb, 0xde, 0x36,
	0x01, 0x8d, 0x8d, 0x5d, 0x7b, 0x5d, 0x1b, 0xfb, 0xfb, 0xb0, 0x4a, 0xe9, 0xf6, 0x6a, 0x15, 0x09,
	0xd7, 0x91, 0x1a, 0xca, 0xe3, 0x2f, 0x29, 0x8e, 0xb9, 0x55, 0xfa, 0xa6, 0xb5, 0x84, 0x79, 0xf6,
	0x44, 0xb0, 0xef, 0x3a, 0xe1, 0xae, 0x44, 0xe3, 0x1e, 0x1a, 0x7e, 0x57, 0xc0, 0x8d, 0xc2, 0x8e,
	0xdf, 0x45, 0xe3, 0xea, 0x2d, 0xf7, 0x50, 0x11, 0xbb, 0x8d, 0x9c, 0xad, 0x15, 0x77, 0x24, 0x9c,
	0xfd, 0xfd, 0x12, 0x5c, 0xd2, 0xb7, 0xd5, 0xfb, 0x81, 0x13, 0x72, 0xdb, 0xa8, 0x03, 0x75, 0xd5,
	0x12, 0x13, 0xdc, 0x2b, 0x9b, 0x5f, 0xbe, 0x65, 0xa3, 0x64, 0x0d, 0x4f, 0x65, 0x05, 0x5a, 0xb4,
	0xab, 0x5b, 0x9a, 0xd6, 0xba, 0x3b, 0x1e, 0xc9, 0x7e, 0xbb, 0x04, 0x6a, 0xf7, 0xdb, 0x6e, 0x12,
	0x9b, 0xdb, 0x9f, 0x52, 0x73, 0x2c, 0xbc, 0x2b, 0x79, 0x63, 0xae, 0x51, 0xe8, 0x16, 0x2d, 0x52,
	0x8d, 0xdb, 0x89, 0x86, 0x48, 0x75, 0xf3, 0x39, 0xac, 0x85, 0xdc, 0x89, 0x31, 0x15, 0x53, 0x85,
	0xcc, 0xd2, 0x80, 0x23, 0x4b, 0x53, 0x12, 0x34, 0x11, 0xc5, 0xc4, 0xd2, 0xe0, 0xe3, 0x67, 0xe9,
	0xe6, 0x70, 0xbb, 0x2a, 0xf2, 0x67, 0x36, 0xc7, 0x62, 0x2a, 0xcd, 0xf5, 0x91, 0x78, 0x97, 0x62,
	0x7e, 0x6a, 0x6f, 0x08, 0x00, 0x25, 0x7c, 0x4e, 0xfb, 0x1c, 0xed, 0xd7, 0xfa, 0xe6, 0x83, 0xb7,
	0x9a, 0x91, 0x07, 0x24, 0x5a, 0x4e, 0xfb, 0x7c, 0xab, 0x72, 0x94, 0x1e, 0x8d, 0x5a, 0x73, 0x91,
	0x86, 0xb3, 0xdf, 0x94, 0x96, 0x17, 0x49, 0x98, 0xec, 0x59, 0xd6, 0x32, 0x0e, 0xfc, 0xde, 0x3b,
	0x10, 0x2e, 0x29, 0x57, 0x8b, 0x45, 0x45, 0x90, 0x68, 0xfd, 0xa7, 0x39, 0x58, 0x19, 0xad, 0x12,
	0xd8, 0x0d, 0x68, 0xa8, 0x65, 0x21, 0xfc, 0x84, 0xdb, 0x83, 0x81, 0xb1, 0xe7, 0xea, 0x04, 0xdf,
	0xf7, 0x13, 0xfe, 0x7c, 0xe0, 0x7b, 0xec, 0x1f, 0x95, 0x60, 0x15, 0xf5, 0xfb, 0x08, 0x31, 0x49,
	0xae, 0x75, 0xf7, 0xdd, 0xab, 0x2c, 0x34, 0x59, 0x86, 0x84, 0xe7, 0x72, 0x67, 0x04, 0x54, 0xb0,
	0xef, 0xc0, 0xaa, 0x5c, 0x06, 0x78, 0x30, 0x6b, 0x53, 0x36, 0x99, 0xbe, 0x5f, 0x4e, 0x97, 0xa1,
	0x97, 0x82, 0x13, 0x81, 0x27, 0xa7, 0xfb, 0x12, 0xa9, 0xef, 0x99, 0x7f, 0x0a, 0xcb, 0x69, 0x31,
	0x1e, 0x7a, 0xa6, 0xd0, 0x24, 0x16, 0x62, 0xba, 0xd0, 0xbd, 0xd0, 0xd3, 0x45, 0x7e, 0x66, 0x92,
	0x34, 0xd3, 0x51, 0x40, 0x3b, 0x32, 0x9b, 0x56, 0xa4, 0x06, 0xa1, 0xd8, 0xce, 0xad, 0xca, 0xd1,
	0x6e, 0xf8, 0x34, 0x8e, 0xba, 0x31, 0x17, 0xc2, 0x6a, 0xc4, 0xc5, 0x19, 0xf9, 0x36, 0xac, 0xd0,
	0xd1, 0x4e, 0x46, 0xf4, 0x93, 0xcd, 0x44, 0x01, 0xbe, 0x25, 0xc4, 0xa6, 0x32, 0x9f, 0xac, 0xab,
	0xc7, 0xa0, 0xe6, 0xcb, 0x38, 0x02, 0x33, 0xaf, 0x67, 0xd6, 0xd6, 0xa8, 0xb8, 0x72, 0x16, 0x5a,
	0xff, 0x74, 0x0a, 0x96, 0x46, 0x8d, 0x7d, 0xe1, 0x00, 0xa9, 0x54, 0x3c, 0x40, 0x5a, 0x83, 0xd9,
	0x42, 0x4e, 0xff, 0xcc, 0xb1, 0x67, 0x6e, 0x72, 0xd3, 0xa4, 0xd0, 0x5e, 0x50, 0xd9, 0x4d, 0x66,
	0xef, 0x6b, 0xa3, 0xaa, 0x85, 0x44, 0xb8, 0xb0, 0x29, 0xa3, 0xc9, 0x6c, 0x7d, 0xa9, 0x18, 0xd7,
	0xe5, 0x04, 0x8d, 0x63, 0x30, 0xa9, 0x6e, 0x10, 0x85, 0xde, 0xe8, 0xe2, 0xdf, 0x83, 0xe6, 0x88,
	0x16, 0xd0, 0xe0, 0x4e, 0x61, 0xd9, 0xe5, 0x62, 0xe5, 0x26, 0xd0, 0x30, 0x54, 0xaf, 0x9e, 0x93,
	0x09, 0xbc, 0x0a, 0x92, 0xab, 0x92, 0x0a, 0xfd, 0x10, 0xd6, 0xc7, 0x27, 0x5f, 0x69, 0x5b, 0xa9,
	0x39, 0x26, 0xf3, 0x2a, 0x97, 0x24, 0x9b, 0x59, 0x09, 0xf4, 0xfa, 0x8c, 0x91, 0x97, 0xb3, 0x43,
	0x49, 0xb2, 0xe9, 0xc2, 0xc0, 0xb4, 0x36, 0x23, 0x36, 0xb7, 0x60, 0x75, 0x04, 0x3b, 0xd9, 0x89,
	0x4c, 0xda, 0xf4, 0xf2, 0x10, 0x13, 0xd9, 0x15, 0x59, 0x56, 0x2d, 0xae, 0x33, 0x72, 0xa4, 0x97,
	0x89, 0xa4, 0x98, 0x9c, 0xf5, 0x03, 0x58, 0x2b, 0x94, 0x35, 0xe9, 0x97, 0xa2, 0x59, 0x21, 0x7b,
	0x31, 0x57, 0x52, 0xa7, 0x5d, 0x0a, 0x76, 0xbd, 0x10, 0x43, 0xab, 0x9a, 0xba, 0xb2, 0x71, 0xb4,
	0xd6, 0x7f, 0x2c, 0x01, 0x1b, 0x36, 0xef, 0xce, 0x5b, 0xa8, 0x3f, 0x82, 0x0b, 0x67, 0xad, 0xc6,
	0x34, 0x27, 0x67, 0xcc, 0x62, 0x64, 0xb7, 0xa1, 0x35, 0x7e, 0x2d, 0x2a, 0xff, 0x66, 0x75, 0xcc,
	0x52, 0x64, 0x6d, 0x98, 0xf3, 0x85, 0xed, 0x06, 0x91, 0xd0, 0x2e, 0x97, 0x3e, 0xda, 0x99, 0xf5,
	0x05, 0xc6, 0x93, 0xbd, 0xd6, 0x6f, 0xc1, 0xf2, 0x48, 0xfb, 0xf0, 0xbc, 0x9e, 0x3d, 0x80, 0xcb,
	0x63, 0xac, 0xc7, 0x62, 0xef, 0x2e, 0x8e, 0x32, 0x20, 0x4d, 0x23, 0x5b, 0xff, 0x76, 0x01, 0x56,
	0x46, 0x5b, 0x41, 0xc6, 0xd7, 0x93, 0x8e, 0xa0, 0xd0, 0x71, 0x6b, 0xed, 0x09, 0x0a, 0xf6, 0xbb,
	0x25, 0x58, 0x3a, 0x76, 0x02, 0xdf, 0xa3, 0xa5, 0x6f, 0x3c, 0x55, 0xa5, 0x28, 0xf8, 0xbb, 0xb7,
	0xcb, 0x36, 0x5e, 0x98, 0xea, 0x8c, 0x97, 0xcb, 0x8e, 0x87, 0x60, 0xec, 0x6f, 0x97, 0x60, 0xde,
	0x19, 0x24, 0x51, 0x18, 0xf5, 0xf0, 0x04, 0x51, 0x1f, 0xd1, 0xd4, 0x37, 0x9d, 0xaf, 0xa1, 0x51,
	0x77, 0x4c, 0x4d, 0x7b, 0x91, 0xc7, 0xb7, 0xe6, 0x8e, 0x76, 0x7c, 0xe1, 0x1c, 0x04, 0xdc, 0xb3,
	0xea, 0x4e, 0x0e, 0x45, 0x69, 0xff, 0x79, 0x3d, 0x4c, 0xf2, 0xac, 0x6a, 0xcd, 0xe7, 0x15, 0x31,
	0xde, 0x37, 0x4e, 0x43, 0x0d, 0xd2, 0xfc, 0x3e, 0x76, 0xd4, 0x89, 0x1f, 0xbd, 0xac, 0x63, 0x62,
	0x27, 0xbb, 0x0a, 0x89, 0x37, 0xd3, 0x36, 0x61, 0x39, 0xe6, 0x09, 0x0f, 0x71, 0x46, 0xfa, 0x3c,
	0xf6, 0x23, 0x8f, 0x0a, 0x4d, 0xd3, 0x9b, 0x40, 0x06, 0xf9, 0x14, 0x71, 0x58, 0xe6, 0x17, 0x25,
	0x68, 0x1c, 0x9e, 0x7a, 0x71, 0x4e, 0xd9, 0xd3, 0x63, 0x2c, 0x5f, 0xc7, 0x70, 0x3d, 0xd4, 0x55,
	0x91, 0x9a, 0x9f, 0x3f, 0xcc, 0x7d, 0x4b, 0x67, 0xa1, 0x29, 0x8e, 0xfc, 0xbe, 0x1d, 0x46, 0x21,
	0x7f, 0x49, 0x91, 0x44, 0xf5, 0x08, 0x09, 0x1d, 0x4f, 0xcd, 0x5a, 0x2b, 0x12, 0xff, 0x38, 0x45,
	0xd3, 0x0b, 0x24, 0xa8, 0xe3, 0x3b, 0x83, 0x20, 0x48, 0x6d, 0x72, 0x2d, 0x85, 0xe7, 0xe8, 0x01,
	0x0a, 0x89, 0xd4, 0x26, 0x33, 0xc9, 0xdf, 0xd6, 0x3f, 0x28, 0x01, 0x1b, 0x5e, 0x54, 0xec, 0x23,
	0x68, 0x64, 0x56, 0x36, 0x79, 0x2a, 0x2a, 0xec, 0x90, 0xc2, 0xc9, 0x43, 0xc9, 0x93, 0xd2, 0xc1,
	0x7b, 0xb9, 0x48, 0x4a, 0x87, 0xef, 0x9f, 0xe6, 0xf6, 0x4b, 0x51, 0x8c, 0x2c, 0xa6, 0xb8, 0x74,
	0x77, 0xfe, 0xf7, 0x39, 0xa8, 0xe7, 0x07, 0x8c, 0x6d, 0xc0, 0xa2, 0x48, 0x9c, 0xae, 0x34, 0xec,
	0x9d, 0x98, 0x3b, 0x3a, 0x6a, 0x46, 0x12, 0x62, 0x41, 0xa1, 0xee, 0xc4, 0xdc, 0x51, 0x41, 0xb3,
	0xcb, 0x50, 0x25, 0x19, 0x98, 0xcb, 0x99, 0x03, 0x84, 0x91, 0xb9, 0xfc, 0x01, 0xd4, 0x12, 0x27,
	0xee, 0x72, 0x43, 0x32, 0x91, 0xca, 0x60, 0x42, 0x10, 0xdd, 0x6d, 0x68, 0x45, 0xa1, 0xc7, 0x7b,
	0x4e, 0xe8, 0xd9, 0xaa, 0x80, 0xe7, 0xc7, 0xba, 0x01, 0x14, 0x78, 0x5b, 0xd5, 0x14, 0xcf, 0x90,
	0x60, 0xc7, 0x8f, 0x55, 0x33, 0x8a, 0xe1, 0xae, 0xa9, 0xe1, 0x70, 0xd7, 0x43, 0x58, 0xc8, 0x2c,
	0x79, 0x15, 0xf2, 0x9a, 0xc6, 0x85, 0x78, 0xe1, 0xac, 0x90, 0x97, 0x35, 0x2f, 0x32, 0x5f, 0xd2,
	0xfd, 0xf8, 0xbd, 0x12, 0x98, 0xf8, 0x21, 0xad, 0x68, 0xe4, 0x45, 0x8b, 0x5a, 0x7c, 0xed, 0x8b,
	0xda, 0xb4, 0x0e, 0xbf, 0xb0, 0x89, 0x0d, 0x91, 0x05, 0xc9, 0x36, 0xfe, 0xf3, 0x12, 0xac, 0xa5,
	0x6d, 0xe4, 0xdc, 0x93, 0x33, 0x6a, 0xba, 0x4d, 0x61, 0x92, 0xc1, 0x1f, 0x63, 0x53, 0xa9, 0x05,
	0xd8, 0x58, 0x23, 0x79, 0x32, 0xc0, 0x17, 0xdc, 0x6d, 0xfd, 0x95, 0x32, 0x2c, 0x0c, 0x75, 0x8d,
	0xfd, 0xc3, 0x12, 0xd4, 0xf3, 0x83, 0xad, 0x12, 0x0b, 0xa2, 0x3f, 0xe6, 0x81, 0xde, 0x9a, 0x3e,
	0xb2, 0xb8, 0xe3, 0x9d, 0x5a, 0xb5, 0xdc, 0x60, 0xb3, 0x8f, 0x81, 0x39, 0xa1, 0xcb, 0x45, 0x12,
	0xc5, 0x99, 0x6c, 0x6d, 0xba, 0x97, 0xd5, 0xd0, 0x18, 0x9d, 0xb0, 0x3d, 0x2a, 0xb1, 0x7b, 0x62,
	0x54, 0x62, 0xf7, 0xdf, 0x2c, 0xc3, 0xe2, 0x88, 0xc1, 0xa3, 0xe1, 0x50, 0xd3, 0xa9, 0xd6, 0xfa,
	0xff, 0xf7, 0xe1, 0xa0, 0xe6, 0xa8, 0x6d, 0x76, 0x13, 0x16, 0x74, 0xfb, 0x8a, 0xa3, 0x31, 0xaf,
	0x10, 0x66, 0x30, 0x36, 0x60, 0xd1, 0xe3, 0x7d, 0x1e, 0x7a, 0x52, 0x0a, 0x17, 0x07, 0x64, 0xc1,
	0xa0, 0x34, 0x7d, 0xfb, 0x36, 0xd4, 0x72, 0x6d, 0x60, 0x00, 0xaa, 0x15, 0xea, 0x71, 0x10, 0x35,
	0x52, 0x8d, 0x12, 0x6b, 0x40, 0xf5, 0xe8, 0x31, 0xe7, 0x9e, 0xb8, 0xef, 0xbf, 0xa4, 0x33, 0xf4,
	0xcf, 0xa0, 0x9e, 0xd7, 0xa5, 0xac, 0x06, 0xa9, 0x36, 0x55, 0x0c, 0xee, 0x85, 0xf4, 0x55, 0x22,
	0x24, 0xef, 0xc6, 0x8e, 0xc7, 0xbd, 0x46, 0xb9, 0xf5, 0x04, 0xd6, 0xcf, 0x08, 0x9c, 0x48, 0x9f,
	0x25, 0x70, 0x45, 0xea, 0xfb, 0xce, 0x59, 0x33, 0x81, 0x2b, 0xd0, 0xe9, 0x5d, 0x36, 0xa9, 0x56,
	0x24, 0x1b, 0x29, 0x9d, 0xaa, 0xf5, 0x7f, 0x27, 0xb5, 0x43, 0x5d, 0x8c, 0x79, 0xbc, 0x86, 0x43,
	0xfd, 0x09, 0x2c, 0x66, 0x22, 0x32, 0xd2, 0x96, 0xc3, 0xed, 0x5d, 0x46, 0x63, 0xaa, 0x61, 0x42,
	0x27, 0xd2, 0xa6, 0x93, 0x42, 0xe1, 0xef, 0x94, 0x60, 0x09, 0x0d, 0xa9, 0x62, 0xfc, 0x66, 0xe2,
	0x5d, 0x39, 0xdf, 0xc5, 0xbe, 0xa0, 0xf3, 0x3d, 0x14, 0xd4, 0x59, 0x90, 0x8d, 0xc8, 0x87, 0x74,
	0xfe, 0x5e, 0x09, 0x96, 0x69, 0x05, 0x14, 0xdb, 0x46, 0x39, 0xfc, 0x87, 0x5f, 0x43, 0xdb, 0x30,
	0xd2, 0x32, 0xd4, 0x38, 0x86, 0xcd, 0xc8, 0xb5, 0xae, 0xd5, 0x21, 0x4f, 0x76, 0x68, 0xa6, 0xce,
	0x3c, 0xcc, 0xf8, 0x14, 0x96, 0x8b, 0x93, 0x43, 0xba, 0x9e, 0xce, 0x62, 0x58, 0x6e, 0x7a, 0x50,
	0xdd, 0xb7, 0x7c, 0x58, 0x1e, 0xd9, 0xa8, 0xf3, 0xec, 0xf5, 0x37, 0xa8, 0xca, 0x82, 0x85, 0xa1,
	0xc8, 0xcf, 0x79, 0xd5, 0x5c, 0x52, 0x09, 0x19, 0xd2, 0x5d, 0x31, 0xeb, 0x79, 0x4e, 0x82, 0x1e,
	0x45, 0xdd, 0x5d, 0xaf, 0xfd, 0x1d, 0xa8, 0x64, 0x62, 0x59, 0x78, 0x53, 0x3d, 0x8d, 0x66, 0xa9,
	0xa4, 0x97, 0x1d, 0x59, 0x1b, 0x9e, 0x1d, 0x93, 0x5b, 0xd3, 0x28, 0xb5, 0x7f, 0x39, 0xad, 0x5f,
	0xf2, 0xd4, 0xd3, 0x39, 0xe2, 0x8e, 0xfa, 0x4f, 0xcd, 0xfd, 0x05, 0x89, 0xd3, 0xd7, 0x0b, 0xbe,
	0x7b, 0xf6, 0xb2, 0x18, 0x71, 0xc3, 0x80, 0x3a, 0x5d, 0x49, 0x63, 0xe7, 0xa2, 0xf5, 0xcb, 0x29,
	0x98, 0xc2, 0x9f, 0x7f, 0xb2, 0x1d, 0xbe, 0xec, 0xe5, 0x8a, 0xc9, 0x77, 0x73, 0x4b, 0xff, 0xe7,
	0x25, 0x58, 0x49, 0xaf, 0xb4, 0xf6, 0xe3, 0x41, 0x68, 0x2e, 0x66, 0xd3, 0x91, 0xe6, 0x17, 0x6f,
	0x36, 0xbe, 0xe9, 0xad, 0xfd, 0xa7, 0x92, 0xa7, 0xba, 0x9e, 0xbd, 0x94, 0x8c, 0x80, 0x0e, 0xb9,
	0xe8, 0xd3, 0x23, 0x5d, 0x74, 0xb6, 0x03, 0xef, 0x9b, 0x4b, 0x47, 0xa7, 0xa1, 0xab, 0xe3, 0x18,
	0x99, 0x68, 0x82, 0xca, 0x47, 0x5b, 0xd7, 0x77, 0x8d, 0x90, 0x6a, 0xc7, 0x49, 0x9c, 0x34, 0x9e,
	0xc0, 0x5c, 0x60, 0x81, 0x83, 0x5e, 0xad, 0x7b, 0x6c, 0xae, 0x0d, 0xa9, 0x4b, 0xe8, 0x6f, 0x38,
	0x9a, 0x0d, 0xc9, 0xd0, 0x92, 0xfc, 0x14, 0xa4, 0xe5, 0xc3, 0xd2, 0xa8, 0xfe, 0xe7, 0x26, 0x70,
	0xe2, 0x9d, 0x4c, 0x60, 0xfb, 0xbf, 0x4e, 0xc2, 0xa5, 0xfc, 0x94, 0x3c, 0xfa, 0xb2, 0x90, 0x84,
	0xb5, 0x0d, 0xd5, 0xec, 0x5b, 0xc7, 0xea, 0x58, 0xf9, 0xf2, 0x88, 0x84, 0x5f, 0x9d, 0xe1, 0xaa,
	0x2e, 0xc7, 0x04, 0x27, 0x26, 0xe7, 0x95, 0xbd, 0x0f, 0x95, 0x74, 0x63, 0x08, 0xa5, 0x60, 0xc0,
	0xec, 0x0c, 0xc1, 0xba, 0xf0, 0xbe, 0x4e, 0xf5, 0xc2, 0x87, 0x51, 0xd5, 0x43, 0xc9, 0x8e, 0x8b,
	0x2f, 0xa5, 0xfa, 0x81, 0xe9, 0xf2, 0xab, 0x64, 0x80, 0xb5, 0x54, 0x06, 0xd8, 0x7d, 0x65, 0x38,
	0xdd, 0x45, 0x36, 0x52, 0x02, 0x8b, 0xf3, 0x43, 0x80, 0x93, 0x6f, 0x1b, 0x02, 0x9c, 0x7a, 0x8b,
	0x10, 0xe0, 0xf4, 0x9b, 0x85, 0x00, 0x67, 0xc6, 0x87, 0x00, 0x77, 0xa1, 0x21, 0x0e, 0x1d, 0x2f,
	0x3a, 0x31, 0x29, 0x5e, 0xfa, 0x94, 0xf3, 0xdc, 0x1c, 0xaf, 0x3a, 0x15, 0x54, 0x30, 0x61, 0x4e,
	0xd8, 0xe6, 0x5e, 0xf3, 0x84, 0xad, 0xfd, 0x6f, 0x00, 0x3e, 0xc8, 0xaf, 0xb2, 0xfd, 0xd4, 0x11,
	0xcc, 0xaf, 0xb6, 0x63, 0x98, 0x77, 0x07, 0x71, 0x6c, 0x47, 0x7d, 0xdb, 0x0f, 0xed, 0x7e, 0x1c,
	0x75, 0x95, 0x7d, 0xfa, 0xf0, 0x6c, 0x49, 0x32, 0x8e, 0xa1, 0x5c, 0x97, 0x19, 0xdc, 0x93, 0xbe,
	0xd8, 0x9a, 0x3a, 0xda, 0xf5, 0x02, 0x6e, 0x55, 0x65, 0x3d, 0x4f, 0xfa, 0x14, 0x08, 0x67, 0x7f,
	0x99, 0x8e, 0xf2, 0x94, 0x18, 0x41, 0x0d, 0x98, 0x44, 0xb6, 0xef, 0x19, 0x7b, 0xe8, 0xdc, 0x23,
	0xd8, 0xb1, 0x2d, 0x30, 0xca, 0x58, 0xae, 0xf4, 0x67, 0x51, 0xe6, 0xa5, 0x2f, 0x6b, 0xc9, 0xcd,
	0xe3, 0x76, 0x3d, 0x69, 0xcb, 0x98, 0xb4, 0x90, 0x89, 0x37, 0x48, 0x0b, 0x91, 0xba, 0x3c, 0xe7,
	0x81, 0xa3, 0x13, 0xec, 0xa8, 0x77, 0x91, 0xe7, 0x2c, 0x96, 0xf1, 0xc1, 0xa5, 0xff, 0x2b, 0x2d,
	0x8d, 0x13, 0x58, 0x91, 0x9b, 0x2f, 0xbd, 0xc1, 0x1a, 0xf5, 0x33, 0x07, 0x0a, 0x95, 0xcd, 0xed,
	0x37, 0xec, 0x39, 0x26, 0xe2, 0x3f, 0xa1, 0x93, 0x5d, 0x8b, 0x85, 0x1d, 0x93, 0x9c, 0xaf, 0x60,
	0xad, 0x0e, 0xb4, 0xc6, 0x8f, 0x0e, 0xa6, 0x9a, 0xe5, 0xa6, 0x44, 0x69, 0xd4, 0x5a, 0x6e, 0xd4,
	0x86, 0xf2, 0x1c, 0xcb, 0x43, 0x79, 0x8e, 0xad, 0xff, 0x35, 0x09, 0xd5, 0x6c, 0xc5, 0xec, 0xcf,
	0x95, 0x60, 0x3e, 0xed, 0xae, 0x1c, 0x12, 0xed, 0x16, 0xfe, 0xe4, 0x1d, 0xf4, 0x55, 0x2e, 0x3a,
	0xfc, 0x96, 0xd4, 0x5c, 0x2f, 0xb8, 0x9a, 0xbe, 0xff, 0x8b, 0x50, 0xf6, 0x17, 0x4a, 0xb0, 0xa8,
	0x0e, 0xb3, 0x70, 0xb9, 0xd1, 0xdd, 0x53, 0x7d, 0x90, 0xb5, 0xff, 0x2e, 0x9a, 0x41, 0xa7, 0x27,
	0x92, 0x3b, 0x4d, 0xc1, 0x42, 0xc7, 0x00, 0xd4, 0x1d, 0x62, 0x69, 0x92, 0xe1, 0x7e, 0xcb, 0xc6,
	0x56, 0xac, 0x39, 0x09, 0xa2, 0xa8, 0xca, 0x27, 0xb0, 0x88, 0x0a, 0xaf, 0x70, 0xb5, 0x91, 0x12,
	0xc2, 0x51, 0x75, 0xdd, 0xc9, 0x5c, 0x6f, 0x6c, 0xfd, 0x59, 0x98, 0x2f, 0x54, 0x9a, 0x4b, 0x61,
	0x2d, 0xbd, 0x66, 0x0a, 0xeb, 0xc7, 0xc0, 0x30, 0x35, 0xcf, 0x53, 0x4a, 0x80, 0x16, 0x32, 0xa5,
	0x60, 0x35, 0x34, 0xe6, 0xbe, 0x32, 0x98, 0xdb, 0x7f, 0xbd, 0x04, 0xb5, 0xdc, 0xc8, 0xe3, 0x0d,
	0x43, 0x39, 0xf6, 0x8d, 0xf7, 0xd0, 0xa1, 0xa3, 0xb4, 0x68, 0xd4, 0x03, 0xca, 0xc5, 0xa3, 0x86,
	0x12, 0xa4, 0x8c, 0x0f, 0x4c, 0x6d, 0x47, 0xe1, 0x31, 0x8f, 0x13, 0x02, 0x4d, 0x20, 0x11, 0x3d,
	0x3f, 0x4a, 0x90, 0x49, 0xbc, 0x7f, 0x88, 0x55, 0x3c, 0x26, 0x25, 0x23, 0x1a, 0x53, 0x6c, 0x05,
	0x18, 0xc1, 0xf6, 0x53, 0x89, 0x29, 0x1a, 0xd3, 0xed, 0x87, 0xb0, 0x30, 0x24, 0x7f, 0xb2, 0x8d,
	0x92, 0x16, 0x2e, 0x96, 0x7b, 0x74, 0x22, 0x9e, 0xf4, 0x1b, 0x25, 0xb6, 0x0a, 0x8b, 0x47, 0xdb,
	0x81, 0x9c, 0xe4, 0x6c, 0x99, 0x46, 0xb9, 0xfd, 0xef, 0x26, 0x8b, 0x22, 0x54, 0x3f, 0x63, 0xe1,
	0x87, 0xf9, 0x47, 0xa7, 0x53, 0xf1, 0x51, 0x7a, 0x13, 0xf1, 0x11, 0xc3, 0x92, 0x79, 0x4a, 0xc3,
	0x0f, 0x8f, 0xcc, 0x95, 0xae, 0xf2, 0x59, 0xef, 0x99, 0x9e, 0xd7, 0xa6, 0x0d, 0x09, 0xc1, 0x4f,
	0x8b, 0xf1, 0x94, 0x46, 0xdd, 0x08, 0x6b, 0xfd, 0x41, 0x19, 0xe6, 0x0c, 0x45, 0xee, 0xfc, 0xae,
	0x94, 0x3f, 0xbf, 0xcb, 0xdb, 0xd7, 0xe5, 0xa2, 0x7d, 0xfd, 0x5d, 0x58, 0x55, 0x49, 0x56, 0x43,
	0x87, 0x44, 0x13, 0xea, 0x66, 0x02, 0xa2, 0x8b, 0x07, 0x44, 0xdf, 0x85, 0x55, 0x15, 0x31, 0x1c,
	0x2a, 0x47, 0x49, 0xd3, 0xcb, 0x84, 0x2e, 0x96, 0xdb, 0x56, 0x47, 0x10, 0xc9, 0x69, 0x5f, 0x1d,
	0xdf, 0xd5, 0x37, 0xaf, 0x15, 0x47, 0x08, 0x35, 0x72, 0xe6, 0x60, 0x09, 0xef, 0xf2, 0xa2, 0xdb,
	0x27, 0x7f, 0x09, 0x73, 0x8e, 0x41, 0xc7, 0x51, 0x64, 0x00, 0x20, 0x9a, 0x4e, 0xa0, 0x9e, 0x02,
	0xe0, 0xd3, 0x75, 0x94, 0x2d, 0x30, 0x83, 0x32, 0x6a, 0xa8, 0x8e, 0xcc, 0xb8, 0xe3, 0x6b, 0x76,
	0x2a, 0x15, 0x80, 0x5c, 0xa9, 0xe8, 0xd1, 0x89, 0xb0, 0xe6, 0x84, 0x86, 0xb7, 0xff, 0xc9, 0x14,
	0xdc, 0x1a, 0x7a, 0xc3, 0xed, 0xe9, 0xe1, 0xa9, 0x90, 0xfa, 0x1b, 0xf7, 0xec, 0x53, 0xe7, 0x34,
	0x88, 0x1c, 0x6f, 0x87, 0x0b, 0x37, 0xf6, 0xfb, 0x49, 0x14, 0x4b, 0xcf, 0x25, 0xf7, 0x77, 0x10,
	0xec, 0x3e, 0x91, 0xe8, 0x37, 0xf7, 0x4b, 0xe8, 0x27, 0xae, 0x65, 0xff, 0xae, 0x81, 0x62, 0xa2,
	0xde, 0xde, 0xff, 0x8b, 0xa5, 0xfc, 0xd3, 0x7a, 0xe6, 0x45, 0xba, 0xca, 0xe6, 0x9f, 0x3a, 0xf7,
	0x81, 0xb9, 0xb3, 0x1b, 0x47, 0x2f, 0xd9, 0x12, 0x61, 0x11, 0x97, 0x7d, 0xb3, 0x0f, 0x1f, 0xce,
	0xf8, 0x2d, 0xa8, 0x9b, 0xa7, 0xcd, 0xa9, 0x11, 0x13, 0x67, 0xdd, 0xf1, 0x7f, 0xf5, 0x46, 0x98,
	0xf7, 0xd0, 0x87, 0x9a, 0x50, 0xd5, 0x6f, 0xa3, 0xcb, 0x06, 0xb4, 0x7e, 0xbf, 0x04, 0xeb, 0x67,
	0x34, 0xf8, 0xad, 0x5e, 0xde, 0xbf, 0x06, 0xf5, 0xec, 0x18, 0x2b, 0x5d, 0x58, 0x53, 0x8f, 0xda,
	0xeb, 0x3f, 0xcf, 0x71, 0x1d, 0xea, 0x85, 0xd9, 0xa3, 0xe7, 0xf7, 0x6b, 0xfd, 0xec, 0x8c, 0xb5,
	0x7e, 0x13, 0xd6, 0xc6, 0xf6, 0xe9, 0xad, 0x5a, 0x39, 0x5c, 0x7f, 0x79, 0x44, 0xfd, 0xed, 0x7f,
	0x56, 0x82, 0xab, 0x34, 0x09, 0x77, 0xfd, 0xd0, 0x89, 0x4f, 0x1f, 0x45, 0x5d, 0xf5, 0xfa, 0xc1,
	0x0b, 0x27, 0x18, 0x70, 0xe3, 0x5a, 0xd4, 0xa1, 0x6c, 0x04, 0x45, 0x99, 0x2e, 0xef, 0x66, 0xcf,
	0x39, 0xe8, 0x83, 0x5d, 0x80, 0xb9, 0xa2, 0xa3, 0x9c, 0x02, 0x86, 0xc2, 0xff, 0x93, 0xc3, 0xe1,
	0x7f, 0xb9, 0x4d, 0xe3, 0xa8, 0x67, 0xbb, 0x8e, 0x7b, 0xa8, 0x9f, 0x77, 0x9a, 0x93, 0x90, 0x6d,
	0x09, 0x68, 0xff, 0x76, 0x59, 0x3f, 0x92, 0x57, 0x6c, 0xad, 0x6e, 0x27, 0x83, 0x49, 0x73, 0xd5,
	0x79, 0xce, 0xc2, 0xdf, 0x6c, 0x11, 0xa6, 0xa2, 0x7e, 0xfa, 0xa0, 0xf4, 0x64, 0xd4, 0xa7, 0xbf,
	0x9f, 0xa0, 0xec, 0xaf, 0x81, 0xd0, 0x7f, 0x05, 0x25, 0xea, 0xab, 0x66, 0xec, 0xc1, 0x0c, 0x5d,
	0x85, 0xd4, 0x3e, 0xfc, 0xb7, 0x46, 0x2f, 0xdc, 0x33, 0xc7, 0xcc, 0xd2, 0x3c, 0xe8, 0xc9, 0x0c,
	0xe9, 0x8b, 0xd0, 0xae, 0x0e, 0x07, 0xbd, 0x03, 0x1e, 0x6b, 0xed, 0x8e, 0x18, 0xdc, 0xcb, 0x8f,
	0x11, 0xce, 0xae, 0x42, 0x2d, 0x4b, 0xa7, 0xa5, 0x55, 0xf5, 0x20, 0xa5, 0x11, 0xed, 0x5f, 0x96,
	0xe0, 0x62, 0x31, 0x48, 0xa3, 0x6f, 0xc5, 0x93, 0x82, 0xfa, 0xdc, 0x8c, 0x84, 0x14, 0x66, 0x37,
	0x8b, 0x1d, 0x18, 0x5d, 0x18, 0xc5, 0x26, 0x8d, 0xda, 0x19, 0x09, 0x1e, 0x6f, 0x65, 0x3a, 0xb7,
	0x7f, 0xa7, 0xaa, 0x97, 0x5c, 0xb1, 0x0d, 0x79, 0x0d, 0xbb, 0x0c, 0xd3, 0x2a, 0x84, 0x55, 0x52,
	0x21, 0xd9, 0xa8, 0x8b, 0x89, 0x5d, 0x8c, 0xb2, 0xab, 0x78, 0xcc, 0x3d, 0x5b, 0x3f, 0xb0, 0x40,
	0x42, 0x6e, 0xcc, 0x3b, 0x58, 0x67, 0xd6, 0xb3, 0x61, 0x19, 0x6e, 0x34, 0x06, 0xd6, 0x42, 0x5c,
	0x80, 0x08, 0xf6, 0xe5, 0x50, 0x50, 0xe0, 0xf6, 0x9b, 0x54, 0x35, 0x1c, 0xdb, 0x39, 0xf7, 0x6d,
	0xba, 0xc9, 0x57, 0x7a, 0x9b, 0xee, 0x5f, 0x4f, 0x40, 0xa3, 0xd8, 0x0f, 0xf6, 0x63, 0x98, 0x53,
	0x97, 0xe7, 0x8c, 0xf8, 0xf8, 0xe4, 0xd5, 0x96, 0x81, 0x11, 0x27, 0xae, 0xfa, 0x64, 0x0f, 0xcc,
	0x13, 0x60, 0x49, 0x4c, 0xe1, 0x82, 0x51, 0xaf, 0x9b, 0xc8, 0x75, 0xaa, 0xde, 0xff, 0x7a, 0x46,
	0x64, 0x43, 0x2f, 0x9c, 0xec, 0xa6, 0xd9, 0x2e, 0xe3, 0x39, 0xd1, 0xd9, 0x82, 0xce, 0x74, 0x19,
	0xc7, 0xea, 0x0b, 0x68, 0xab, 0x36, 0x99, 0xdb, 0xdd, 0x23, 0x07, 0x10, 0x9f, 0xfe, 0x27, 0x4a,
	0xcb, 0x10, 0x16, 0xad, 0x8c, 0x3d, 0xb8, 0x9a, 0x26, 0x53, 0x8c, 0xe7, 0x46, 0x61, 0x87, 0xcb,
	0x26, 0x9f, 0x62, 0x1c, 0xbb, 0x0f, 0x61, 0x5e, 0x8d, 0xbd, 0x09, 0xe9, 0x4c, 0xd3, 0xe1, 0x00,
	0x81, 0xcd, 0xeb, 0x33, 0x7f, 0x69, 0xfa, 0xbc, 0xa7, 0xfd, 0x46, 0x3e, 0x34, 0x53, 0x78, 0x95,
	0xae, 0x3c, 0xf4, 0x2a, 0xdd, 0x20, 0x7d, 0x23, 0x8e, 0xd2, 0x1e, 0x7e, 0xfc, 0x16, 0x0b, 0xb6,
	0xf8, 0x52, 0xdc, 0xbc, 0x7e, 0x29, 0x69, 0x17, 0xaf, 0x82, 0x04, 0xe9, 0x53, 0x71, 0x43, 0x4f,
	0x1f, 0x4e, 0x8e, 0x78, 0xfa, 0xf0, 0x95, 0x9e, 0x05, 0x9c, 0x7a, 0xe5, 0x67, 0x01, 0xbf, 0x78,
	0x85, 0xe7, 0xe9, 0xd2, 0x78, 0xe5, 0x39, 0xef, 0xd3, 0x8d, 0x7c, 0x3e, 0x70, 0x66, 0xcc, 0xf3,
	0x81, 0x1f, 0x03, 0x1b, 0xf1, 0xe4, 0x1f, 0x5d, 0xa0, 0x6d, 0xf4, 0x8a, 0x6f, 0xfd, 0x5d, 0x83,
	0xfa, 0xc8, 0xc7, 0x01, 0xab, 0x39, 0xaa, 0x2b, 0x50, 0x55, 0x0f, 0x24, 0xd1, 0x9f, 0x77, 0xa1,
	0xdb, 0x74, 0x15, 0x82, 0x61, 0x1a, 0xf6, 0x99, 0x6f, 0x9e, 0x55, 0xde, 0xf2, 0xcd, 0xb3, 0xa1,
	0x87, 0xc0, 0xaa, 0xaf, 0xfc, 0x10, 0x58, 0x6d, 0xcc, 0x43, 0x60, 0xed, 0xeb, 0x43, 0x0f, 0x70,
	0x2d, 0x42, 0x71, 0x09, 0x35, 0xde, 0xbb, 0x79, 0x1f, 0x96, 0x46, 0x99, 0xf1, 0xe8, 0xca, 0xc9,
	0xfd, 0xd2, 0x78, 0x0f, 0x7f, 0xca, 0x1e, 0x35, 0x4a, 0xf8, 0xf0, 0x0c, 0x3e, 0xe4, 0x87, 0xdf,
	0x65, 0x7c, 0x25, 0x78, 0xcf, 0x79, 0xd9, 0x98, 0xb8, 0x79, 0x07, 0x96, 0x47, 0xa6, 0xbd, 0xb3,
	0x0a, 0xe8, 0xc4, 0xf7, 0xc6, 0x7b, 0xf9, 0x73, 0x45, 0xfa, 0x3b, 0x05, 0xe4, 0xb9, 0x7a, 0x8d,
	0xf2, 0xcd, 0xcf, 0xa5, 0x38, 0x2d, 0x64, 0x63, 0x49, 0x37, 0x32, 0x4d, 0xe8, 0x54, 0x47, 0x91,
	0xea, 0xf2, 0x4c, 0xa3, 0x84, 0xcc, 0x9f, 0x3a, 0x52, 0x88, 0x37, 0xca, 0x37, 0x1f, 0xc0, 0xd2,
	0x28, 0x6f, 0x01, 0x79, 0xa4, 0xfe, 0x82, 0xf2, 0x4d, 0x1f, 0x9d, 0x88, 0x67, 0x91, 0x3a, 0x66,
	0xc1, 0x66, 0xed, 0x39, 0x2f, 0xb1, 0x48, 0xa3, 0x7c, 0xf3, 0x09, 0xb4, 0xc6, 0x6b, 0x6a, 0x3c,
	0x59, 0xcd, 0xbe, 0xdb, 0xbc, 0xfd, 0x40, 0x1d, 0x7f, 0x06, 0x3c, 0x6e, 0x94, 0xd0, 0x89, 0x4e,
	0xa9, 0xe5, 0xe0, 0x94, 0xef, 0x7e, 0x0c, 0xcc, 0x8d, 0x7a, 0x05, 0x59, 0x70, 0xb7, 0x42, 0xc2,
	0x00, 0x37, 0xfd, 0xcf, 0xa6, 0x09, 0xf8, 0x87, 0xa5, 0xd2, 0xff, 0x0b, 0x00, 0x00, 0xff, 0xff,
	0x8f, 0x11, 0xeb, 0xee, 0xfd, 0x6f, 0x00, 0x00,
}
